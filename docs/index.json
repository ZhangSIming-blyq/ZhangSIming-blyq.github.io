[{"body":"","link":"https://zhangsiming-blyq.github.io/","section":"","tags":null,"title":""},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/kubernetes/","section":"tags","tags":null,"title":"kubernetes"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/kubernetes/","section":"categories","tags":null,"title":"kubernetes"},{"body":"1. Cilium 和 Cilium-Operator 的网络架构 在 Kubernetes 集群中，我们使用 Cilium 作为网络插件，基于 eBPF 提供高效的网络功能，如流量控制、负载均衡、网络安全策略等。同时，Cilium-Operator 负责管理集群范围的 Cilium 操作，包括 IP 地址管理、服务发现、BGP 宣告和配置同步等。\n2. IP 分配与 Cilium-Host 的作用 2.1 Cilium 如何分配 IP 地址 Pod 创建时的 IP 分配：当 Kubernetes 中创建一个新的 Pod 时，Cilium 的 CNI 插件 负责为该 Pod 分配 IP 地址。这与 Kubernetes Controller Manager 协同完成。在我们公司的场景中，Cilium 使用的是公司内部的物理 IP 地址，这些地址是从公司内部的一个专门的 IP 地址池中分配的，以确保 Pod 在公司内部的网络中能够被识别和访问。\n通过 Cilium CNI 插件将 IP 分配到 Pod：Cilium 作为 Kubernetes 的 CNI 插件，负责为新创建的 Pod 分配 IP 地址，并将该 IP 绑定到 Pod 的虚拟网络接口（veth）。Cilium 通过 CNI 接口向 Kubernetes 报告这些信息，确保 Kubernetes 的网络配置与 Cilium 的 eBPF 配置一致。\nCilium eBPF 的配置：分配 IP 地址后，Cilium 使用 eBPF 在内核中创建高效的路由规则，确保 Pod 可以与其他节点或外部网络通信。eBPF 程序还可以用来监控和过滤数据流，提供安全和网络策略支持。\n2.2 Cilium-Host 的角色 Pod 内部的网络接口：每个 Pod 通过一个虚拟网络接口（veth）连接到 Cilium-host（宿主节点的虚拟网络设备）。Cilium-host 负责 Pod 的网络流量出入，并作为与外部网络的网关。Pod 发出的数据首先经过 Cilium-host，然后再根据路由规则通过物理网络传输到目标位置。\n物理网络通信：Cilium-host 通过物理节点的网络接口将流量发送到外部网络或其他节点上的 Pod。Cilium 使用 eBPF 程序处理这个过程中所有的路由和安全规则，确保数据包能快速高效地传输。\n3. Cilium-Operator 的作用 监控和控制 Cilium 行为：Cilium-Operator 负责监控 Cilium 的状态，并执行一些集群级别的配置和管理任务。它处理如 IPAM（IP 地址管理）功能和集群状态同步。它不会直接参与每个 Pod 的 IP 分配，但会通过 IPAM 管理整个集群中 IP 地址的动态分配情况。控制的还是cilium的状态！\nBGP 宣告与外部网络通信：Cilium-Operator 还管理 BGP 配置，负责将 Kubernetes 集群中的 Pod IP 宣告给外部网络（如物理交换机）。通过 BGP 宣告，外部网络设备能够知道如何路由到集群中的 Pod。(其实是cilium-bird的作用)\n4. 数据包的传输路径 4.1 数据包从 Pod 发出 Pod 内部数据流出：当 Pod 内的应用需要访问外部服务或其他 Pod 时，数据通过虚拟网络接口（veth）传递到 Cilium-host。 eBPF 路由和策略检查：Cilium-host 使用 eBPF 技术处理该数据包，执行流量控制、安全策略检查，并确定数据的转发路径。 通过物理网络传输：经过处理的数据包通过物理网络设备（如交换机或路由器）传输到目标节点或外部网络。 4.2 数据包从外部到达 Pod 外部服务发起请求：外部服务或设备发起的请求首先通过物理网络路由到 Kubernetes 集群的物理节点。 BGP 宣告与路由选择：BGP 协议帮助外部设备找到集群内目标 Pod 的 IP 地址。通过 Cilium-host，数据包会被路由到目标 Pod。 Cilium-host 传递数据包：Cilium-host 使用 eBPF 程序对进入的数据包进行策略检查，然后将数据通过虚拟接口（veth）传递给目标 Pod。 5. 收包发包的完整路径 发包（Pod 向外部发送数据的流程） Pod 发起请求：Pod 内的应用发起网络请求。 流量经过 Cilium-host：请求通过虚拟接口（veth）传递到 Cilium-host，并由 Cilium 的 eBPF 程序处理。 数据包进入物理网络：经过处理后，数据包通过物理网络设备（交换机、路由器）传输到目标位置。 收包（外部向 Pod 发送数据的流程） 外部服务发起请求：外部网络向 Pod 的 IP 地址发起请求。 通过物理网络路由：请求根据 BGP 宣告的路由信息传递到集群内的 Cilium-host。 流量通过 Cilium-host 进入 Pod：Cilium-host 使用 eBPF 程序对数据包进行检查，随后将数据通过虚拟接口传递到目标 Pod。 总结 IP 分配：Cilium 的 CNI 插件负责为每个新创建的 Pod 分配 IP 地址，并通过虚拟接口将 IP 绑定到 Pod。 Cilium-Operator 的作用：Cilium-Operator 负责监控 Cilium 的状态并管理集群范围的 IP 地址和 BGP 配置，不直接参与 IP 分配。 数据包处理流程：通过 Cilium 的 eBPF 程序进行高效的路由和策略执行，确保 Pod 间和外部网络间的通信顺畅。 ","link":"https://zhangsiming-blyq.github.io/post/kubernetes/cilium/","section":"post","tags":["kubernetes","中文"],"title":"Kubernetes 中 Cilium 网络架构详解与流量处理流程"},{"body":"","link":"https://zhangsiming-blyq.github.io/post/","section":"post","tags":null,"title":"Posts"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/%E4%B8%AD%E6%96%87/","section":"tags","tags":null,"title":"中文"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/algorithm/","section":"tags","tags":null,"title":"algorithm"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/algorithm/","section":"categories","tags":null,"title":"algorithm"},{"body":"双指针法的解决思路： 初始化两个指针：分别指向两个有序集合的起始位置。 比较当前指针指向的元素： 如果集合1的元素小于集合2的元素，将集合1的元素放入结果集中，并将集合1的指针向后移动。 如果集合2的元素小于集合1的元素，将集合2的元素放入结果集中，并将集合2的指针向后移动。 如果两个集合的元素相等，则可以选择将其中一个元素加入结果集，然后两个指针都向后移动。 处理剩余元素：当其中一个集合的所有元素都已合并到结果集中，另一集合可能还有剩余元素。此时直接将剩余元素加入结果集中。 返回结果集：所有元素被合并后返回结果。 代码： 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func mergeSet(set1, set2 []int) []int { 6 result := []int{} 7 8 i, j := 0, 0 9 10 for i \u0026lt; len(set1) \u0026amp;\u0026amp; j \u0026lt; len(set2) { 11 // 1. 比较大小，小的先走 12 if set1[i] \u0026lt; set2[j] { 13 result = append(result, set1[i]) 14 i++ 15 } else if set1[i] \u0026gt; set2[j] { 16 // 2. 大的后走 17 result = append(result, set2[j]) 18 j++ 19 } else { 20 // 3. 相等时候插入一个，指针都走一步 21 result = append(result, set1[i]) 22 result = append(result, set2[j]) 23 i++ 24 j++ 25 } 26 } 27 28 // 如果有剩下的 29 for i \u0026lt; len(set1) { 30 result = append(result, set1[i]) 31 i++ 32 } 33 34 for j \u0026lt; len(set2) { 35 result = append(result, set2[j]) 36 j++ 37 } 38 39 40 return result 41} 42 43 44func main() { 45 // 集合1 46 a := []int{1,2,3,4,5} 47 48 // 集合2 49 b := []int{3,4,5,6,7} 50 51 result := mergeSet(a, b) 52 53 fmt.Println(result) 54 55} 时间复杂度： 双指针法的时间复杂度为O(n+m)，其中n和m分别为两个集合的长度。因为每个集合的每个元素只会被遍历一次，所以整体时间复杂度是线性级别的。 合并逻辑调整：一轮for循环实现方式 我们可以将双指针逻辑合并为一个更简洁的单个for循环，进一步简化代码。通过调整循环条件，可以避免使用两个单独的for循环处理剩余元素的逻辑。\n优化后的代码： 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func mergeSetOneLoop(set1, set2 []int) []int { 6 result := []int{} 7 8 i, j := 0, 0 9 10 // 一个循环内处理合并 11 for i \u0026lt; len(set1) || j \u0026lt; len(set2) { 12 if i \u0026lt; len(set1) \u0026amp;\u0026amp; (j \u0026gt;= len(set2) || set1[i] \u0026lt; set2[j]) { 13 result = append(result, set1[i]) 14 i++ 15 } else if j \u0026lt; len(set2) \u0026amp;\u0026amp; (i \u0026gt;= len(set1) || set1[i] \u0026gt; set2[j]) { 16 result = append(result, set2[j]) 17 j++ 18 } else { 19 result = append(result, set1[i]) 20 i++ 21 j++ 22 } 23 } 24 25 return result 26} 27 28func main() { 29 // 集合1 30 a := []int{1,2,3,4,5} 31 32 // 集合2 33 b := []int{3,4,5,6,7} 34 35 result := mergeSetOneLoop(a, b) 36 37 fmt.Println(result) // [1 2 3 3 4 4 5 5 6 7] 38} 代码解释： 使用一个for循环控制流程，条件为i \u0026lt; len(set1) || j \u0026lt; len(set2)，即当任意一个集合没有遍历完时，继续合并。 在循环中判断： 当i没有超出set1的长度且j已经超出set2的长度，或者set1[i]小于set2[j]时，将set1[i]添加到结果中，并移动i。 同理，处理set2中的元素。 当set1[i]和set2[j]相等时，将set1[i]或set2[j]（二者相等）添加到结果集中，并同时移动两个指针。 时间复杂度： 单循环法的时间复杂度依然是O(n+m)，因为每个元素只被处理一次，整体算法的时间复杂度是线性的。 两种实现方式的对比 解决方法 时间复杂度 优点 缺点 双指针法（两个for循环） O(n + m) 逻辑清晰、代码结构分明，容易理解 使用多个for循环，代码稍微冗长 单循环法 O(n + m) 代码简洁，合并剩余元素时不需要额外的循环 条件判断稍显复杂，理解门槛较高 ","link":"https://zhangsiming-blyq.github.io/post/algorithm/mergeset/","section":"post","tags":["algorithm","中文"],"title":"两个有序集合的合并"},{"body":"Go语言中的map是一种哈希表（hash table）数据结构，支持键值对的高效存取。通过键（key）计算哈希值并将其映射到对应的存储桶（bucket）中，map可以在平均O(1)的时间复杂度下进行插入、查找和删除操作。Go的map底层实现非常精巧，结合了哈希表的基本思想，同时针对冲突和内存管理做了很多优化。\n1. Go map 的基本结构 在Go中，map通过哈希表实现，其底层结构主要由以下几个部分组成：\n1.1 Bucket（存储桶） 1Bucket 2+--------------------+---------------------+---------------------+ 3| keys (k1, k2, ...) | values (v1, v2, ...) | overflow bucket ptr | 4+--------------------+---------------------+---------------------+ 存储桶: 是一个固定长度的数组，用于存储键值对。每个桶中包含了多个键（key）和值（value）对，以及一个指向溢出桶（overflow bucket）的指针。 存储桶：map中的数据被存储在 bucket（存储桶） 中，Go的map默认使用2^B个桶（B是map的大小参数），每个桶可以存储多个键值对。 每个 bucket 是一个存储单元，可以存放多个键值对。多个 bucket 组成了整个哈希表的存储空间。bucket 是哈希表的基本存储单位 每个桶包含若干个键值对和一个溢出链表（overflow bucket），用于解决哈希冲突。桶中的元素通过链表或线性探测等方式处理冲突。 1.2 哈希函数 map通过哈希函数将键映射到一个哈希值，然后通过哈希值找到对应的bucket。 哈希值的前几位决定了元素应该放入的桶。 1.3 扩容机制 当map中的桶负载因子超过一定阈值时，Go会触发扩容（rehash），扩展哈希表的大小。扩容过程中会将旧桶中的数据重新分配到新的桶中，以减少哈希冲突。 Go map 存储和查找的完整流程（结合 bucket 结构） Go 中的 map 是通过哈希表实现的，使用 bucket（桶） 作为核心数据结构存储键值对。以下是 map 在存储和查找一个 key 时的完整流程，以及如何处理哈希冲突。\n2. Go map 查找和存储流程 Go map 的核心结构包含：\nbucket：存储键值对的单元。每个 bucket 能存储多个键值对（默认 8 个）。 tophash：存储每个键哈希值的高 8 位，用于快速定位键。 overflow 指针：当 bucket 满了时，指向一个额外的 overflow bucket。 1type bmap struct { 2 tophash [8]uint8 // 哈希值的高 8 位 3 keys [8]KeyType // 键数组，最多 8 个键 4 values [8]ValueType // 值数组，最多 8 个值 5 overflow *bmap // 指向溢出 bucket 6} 存储一个 key 的流程 步骤 1：计算哈希值\n首先对要插入的 key 进行哈希计算，生成哈希值。\n1hash := hashFunction(key) 步骤 2：找到 bucket\n根据哈希值，通过 hash \u0026amp; (2^B - 1) 找到对应的 bucket 索引。B 是 map 当前的位宽，用来控制 bucket 的数量。\n1bucketIndex := hash \u0026amp; (2^B - 1) 2bucket := buckets[bucketIndex] 步骤 3：在 bucket 中存储 key\n空位存储：找到 bucket 后，首先会在 bucket 中检查是否有空位。如果有，存入键值对，同时将哈希值的高 8 位存入 tophash 数组中。 哈希冲突：如果 bucket 已满或存在冲突（多个键被哈希到同一 bucket），Go 会使用 overflow bucket。将溢出的键值对存储到下一个 overflow bucket。 1if bucket has space { 2 bucket.keys[i] = key 3 bucket.values[i] = value 4 bucket.tophash[i] = hashTop8 5} else { 6 if no overflow bucket { 7 allocate new overflow bucket 8 } 9 store key-value in overflow bucket 10} 冲突处理：\n同 bucket 存储：如果多个键被哈希到同一个 bucket，且 bucket 还有空间，直接存入该 bucket。 overflow bucket：如果 bucket 已满，分配一个新的 overflow bucket，并将新键值对存入 overflow bucket。 查找一个 key 的流程 步骤 1：计算哈希值\n对要查找的 key 进行哈希计算，得到其哈希值。\n1hash := hashFunction(key) 步骤 2：找到 bucket\n通过 hash \u0026amp; (2^B - 1) 计算出 bucket 索引，找到目标 bucket。\n1bucketIndex := hash \u0026amp; (2^B - 1) 2bucket := buckets[bucketIndex] 步骤 3：查找 key\n检查 tophash：首先查看 tophash 数组，比较哈希值的高 8 位。如果匹配，继续比较 key 本身。 找到 key：如果找到相匹配的 key，返回对应的 value。 哈希冲突处理：如果 tophash 匹配但 key 不同，或 bucket 没有找到 key，Go 会查找 overflow bucket，继续寻找目标 key。 1for i := 0; i \u0026lt; 8; i++ { 2 if bucket.tophash[i] == hashTop8 \u0026amp;\u0026amp; bucket.keys[i] == key { 3 return bucket.values[i] 4 } 5} 6if overflow bucket exists { 7 search in overflow bucket 8} 冲突处理：\n同 bucket 查找：在同一个 bucket 内，使用 tophash 和 key 进行比较，匹配后返回值。 overflow bucket 查找：如果未找到目标键且存在 overflow bucket，继续沿 overflow 链查找，直到找到键或确认键不存在。 3. map 的内存布局 3.1 hmap 数据结构 Go map的底层实现主要依赖于hmap结构，它定义了map的基本数据结构和管理逻辑。\n简化后的hmap结构如下：\n1type hmap struct { 2 count int // 当前map中的键值对数量 3 flags uint8 // 记录map状态的标志 4 B uint8 // 2^B 是当前桶的数量 5 buckets unsafe.Pointer // 指向bucket数组 6 oldbuckets unsafe.Pointer // 扩容时，指向旧的bucket数组 7 nevacuate uintptr // 扩容时记录已经移动的bucket数量 8 extra *mapextra // 存储一些额外信息（如溢出桶等） 9} buckets：这是一个指向所有桶的指针，包含了所有存储键值对的桶。 oldbuckets：当map进行扩容时，oldbuckets存储指向旧桶的指针。 extra：用于存储溢出桶信息，避免主桶存储溢出数据。 3.2 扩容机制 当map的负载因子（load factor，即count/buckets）超过一定阈值时，map会自动扩容。扩容的方式是将桶的数量加倍，并重新计算每个键值对的哈希值，将它们放入新的桶中。\n在 Go 中，map 采用**渐进式扩容（incremental resizing）**策略。当 map 需要扩容时，桶的数量通常会增加为原来的 2 倍，但扩容不会一次性完成。每次对 map 进行的插入、删除或查找操作时，Go 会逐步将旧桶中的数据迁移到新的桶中。这种方式避免了一次性扩容带来的性能开销，使扩容过程更加平滑，用户操作不会受到明显影响。\n当 map 的桶数量小于 1024时，扩容按 2 倍的方式进行；但当桶数量达到或超过 1024时，扩容不再直接倍增，而是逐步增加桶的数量。这种方式既控制了内存使用，又保证了性能不会因为扩容而突然下降，从而保持了哈希表的高效性能。\n4. map 实现的线程不安全性 Go的map并不是线程安全的。如果在多个goroutine中并发读写map，会出现数据竞争，导致未定义行为。因此，如果要在多个goroutine中安全地使用map，需要使用同步机制，如sync.Mutex或sync.Map。\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;sync\u0026#34; 6) 7 8func main() { 9 var mu sync.Mutex 10 m := make(map[int]int) 11 12 // 启动多个goroutine并发写map 13 for i := 0; i \u0026lt; 10; i++ { 14 go func(i int) { 15 mu.Lock() 16 m[i] = i 17 mu.Unlock() 18 }(i) 19 } 20 21 // 读取map时加锁 22 mu.Lock() 23 fmt.Println(m) 24 mu.Unlock() 25} 在上述代码中，通过sync.Mutex锁保证了对map的并发访问是安全的。\n5. Go sync.Map Go标准库提供了sync.Map来解决并发访问map时的线程安全问题。sync.Map是线程安全的，并且具有特殊的优化机制，使其适用于高并发的场景。\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;sync\u0026#34; 6) 7 8func main() { 9 var sm sync.Map 10 11 // 并发写入sync.Map 12 for i := 0; i \u0026lt; 10; i++ { 13 go func(i int) { 14 sm.Store(i, i*10) 15 }(i) 16 } 17 18 // 并发读取sync.Map 19 sm.Range(func(key, value interface{}) bool { 20 fmt.Printf(\u0026#34;Key: %v, Value: %v\\n\u0026#34;, key, value) 21 return true 22 }) 23} sync.Map提供了Store、Load、Delete等线程安全的操作方法，并且内部通过某种分段锁机制优化了并发读写性能。\n6. 总结 Go的map底层通过哈希表实现，通过哈希函数将键映射到不同的存储桶（bucket）中。 哈希冲突处理：当多个键哈希值相同时，Go使用开放地址法和溢出桶来处理冲突问题。每个桶可以存储多个键值对，且当一个桶满时会将数据存储在溢出桶中。 扩容机制：当map的负载因子过高时，会触发扩容机制，通过渐进式扩容来避免一次性重分配带来的性能问题。 线程不安全性：Go的map在并发读写时不是线程安全的，推荐使用sync.Mutex或者sync.Map来确保线程安全。 ","link":"https://zhangsiming-blyq.github.io/post/golang/map/","section":"post","tags":["Golang","中文"],"title":"Go `map` 底层实现与冲突处理"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/golang/","section":"tags","tags":null,"title":"Golang"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/golang/","section":"categories","tags":null,"title":"Golang"},{"body":"是的，Go的channel是线程安全的。\nGo中的channel是一种用于不同goroutine之间通信的原语，它可以在多个goroutine之间安全地传递数据，而不需要显式地使用锁机制（如mutex）来同步访问。Go语言的设计确保了channel在并发场景下是安全的，这使得它非常适合在多goroutine环境中用于数据传递和同步。\nGo Channel 的底层实现 Go语言的channel底层实现非常精巧，通过Go runtime（运行时）和调度器（scheduler）来保证其线程安全性。其主要的实现机制依赖于goroutine调度、队列和锁来保证数据的安全传递。下面我们详细解析channel的底层实现：\n1. Channel 的数据结构与机制 Go 的 channel 本质上是一个复杂的结构，主要由几个部分组成：\n发送队列（sendq）：用于存放等待发送数据的 goroutine。 接收队列（recvq）：用于存放等待接收数据的 goroutine。 缓冲区（buf）：如果是有缓冲的 channel，缓冲区用于存放已发送但还未被接收的数据。 锁（mutex）：每个 channel 都有一个锁，用于保护其状态，防止多个 goroutine 并发访问时发生数据竞争。 1type hchan struct { 2 qcount uint // 缓冲区中数据个数 3 dataqsiz uint // 缓冲区大小 4 buf unsafe.Pointer // 缓冲区的指针（有缓冲channel） 5 sendx uint // 下一个发送位置 6 recvx uint // 下一个接收位置 7 sendq waitq // 发送goroutine的等待队列 8 recvq waitq // 接收goroutine的等待队列 9 lock mutex // 保证线程安全的锁 10 closed uint32 // channel是否关闭 11} 2. 发送与接收的过程 在 channel 里，所有的操作都需要通过加锁和队列机制来保证线程安全。当 goroutine 调用发送或接收操作时，Go runtime 会加锁并检查 channel 的状态来决定如何操作。\n2.1 无缓冲 Channel 无缓冲 channel 没有缓冲区，数据必须立即从发送方传递到接收方。因此，如果发送方尝试发送数据，而没有接收方在等待，则发送方会阻塞并被挂起，反之亦然。\n发送方流程：\n加锁：发送方调用 ch \u0026lt;- value，Go runtime 会对 channel 加锁，防止其他 goroutine 同时操作 channel。 检查接收队列（recvq）：Go runtime 会首先检查 recvq（接收队列）是否有等待的接收方。 如果 recvq 中有等待接收的 goroutine，发送方会直接将数据传递给接收方，并将接收方从队列中移除，唤醒接收方继续运行。 如果 recvq 中没有接收方，发送方会将自己挂起，并排入 sendq 队列，等待接收方到来。 解锁：发送操作结束后，Go runtime 会解锁 channel。 接收方流程：\n加锁：接收方调用 value := \u0026lt;-ch，Go runtime 会加锁。 检查发送队列（sendq）：Go runtime 会检查 sendq 中是否有等待发送的 goroutine。 如果有，接收方会立即从 sendq 中取出数据，并将发送方从队列中移除，唤醒发送方继续运行。 如果没有，接收方会将自己挂起，并排入 recvq，等待发送方到来。 解锁：接收操作结束后，Go runtime 会解锁 channel。 无缓冲 channel 操作的总结：\n如果发送方先到，且没有接收方，发送方阻塞并进入 sendq。 如果接收方先到，且没有发送方，接收方阻塞并进入 recvq。 当发送方和接收方匹配成功后，Go runtime 会进行数据交换，并唤醒被阻塞的 goroutine。 2.2 有缓冲 Channel 有缓冲的 channel 不需要发送和接收操作严格同步，发送方可以在缓冲区未满时发送数据，而不阻塞。接收方可以在缓冲区中有数据时接收数据，而不等待。\n发送方流程：\n加锁：发送方调用 ch \u0026lt;- value，Go runtime 加锁，防止其他 goroutine 并发操作 channel。 检查缓冲区： 如果缓冲区未满，数据直接放入缓冲区，sendx（发送索引）递增。 如果缓冲区已满，发送方会阻塞并进入 sendq 队列，等待缓冲区有空间。 解锁：操作完成后解锁。 接收方流程：\n加锁：接收方调用 value := \u0026lt;-ch，Go runtime 加锁，防止数据竞争。 检查缓冲区： 如果缓冲区中有数据，接收方直接从缓冲区获取数据，recvx（接收索引）递增。 如果缓冲区为空，接收方会阻塞并进入 recvq 队列，等待有数据到来。 解锁：操作完成后解锁。 有缓冲 channel 操作的总结：\n如果缓冲区未满，发送方可以直接发送数据而不阻塞。 如果缓冲区已满，发送方阻塞并进入 sendq。 如果缓冲区有数据，接收方可以直接接收数据而不阻塞。 如果缓冲区为空，接收方阻塞并进入 recvq。 3. Channel 的线程安全性 Go语言通过以下机制确保channel的线程安全性：\n3.1 锁机制（mutex）： 在channel的底层实现中，所有对channel的操作（包括发送、接收、关闭等）都会被加锁，以防止多个goroutine同时操作channel时出现数据竞争。Go runtime为每个channel分配了一个mutex锁来保护channel的状态，从而保证了在多goroutine并发操作时的线程安全性。\n3.2 Goroutine调度与阻塞： 当一个goroutine因为channel满了（发送方）或channel空了（接收方）而被阻塞时，Go的调度器会将该goroutine挂起，放入对应的队列（sendq或recvq）。一旦条件满足（比如有接收者准备好接收数据），被阻塞的goroutine会被唤醒继续执行。\n3.3 关闭channel的安全性： 关闭一个channel时，所有在等待接收该channel的goroutine都会被立即唤醒，并且它们会收到零值，从而安全退出。此外，尝试向已关闭的channel发送数据会引发panic，这是Go语言的一种安全机制，避免意外的并发问题。\n4. Channel 的底层实现总结： Channel 使用 锁（mutex） 来确保线程安全，防止数据竞争。 Channel 通过 goroutine调度和队列 实现阻塞和唤醒机制，使得多个goroutine可以安全地发送和接收数据。 无缓冲的channel是同步的，而有缓冲的channel是异步的，二者在实现机制上有所不同。 Go的调度器负责管理阻塞的goroutine，使得程序不会因为某个操作阻塞而死锁。 示例：Channel 实现并发的线程安全通信 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;sync\u0026#34; 6) 7 8// 并发安全计数器 9type Counter struct { 10 value int 11 mu sync.Mutex 12} 13 14// 递增计数器 15func (c *Counter) Increment() { 16 c.mu.Lock() 17 c.value++ 18 c.mu.Unlock() 19} 20 21// 获取计数器值 22func (c *Counter) Value() int { 23 c.mu.Lock() 24 defer c.mu.Unlock() 25 return c.value 26} 27 28func main() { 29 var wg sync.WaitGroup 30 counter := Counter{} 31 ch := make(chan struct{}, 10) // 使用channel控制并发 32 33 for i := 0; i \u0026lt; 100; i++ { 34 wg.Add(1) 35 go func() { 36 defer wg.Done() 37 counter.Increment() 38 ch \u0026lt;- struct{}{} // 发送信号到channel 39 }() 40 } 41 42 wg.Wait() 43 close(ch) 44 45 fmt.Printf(\u0026#34;Counter: %d\\n\u0026#34;, counter.Value()) // 输出计数器的最终值 46} 在这个示例中，使用sync.Mutex实现了对计数器的并发安全访问，同时通过channel控制并发goroutine的执行。channel用于在多个goroutine之间安全地传递信号。\n总结： Go的channel是线程安全的，底层通过加锁机制和goroutine调度来保证不同goroutine之间的安全通信。 无缓冲的channel要求发送和接收操作同步进行，适合用作goroutine之间的同步工具。 有缓冲的channel允许异步传递数据，适合用于需要存储中间数据的场景。 Channel在Go语言的并发模型中是非常重要的原语，它避免了手动使用锁来管理并发操作，使得并发编程更加简洁和安全。 原子操作依赖于CPU指令，由硬件保证操作不可中断，适合简单的并发操作，速度快，无需操作系统调度。锁机制依赖于操作系统调度器，用于保护复杂的多线程操作，确保线程间的排他性访问，但会引入性能开销，如上下文切换和线程阻塞。\n","link":"https://zhangsiming-blyq.github.io/post/golang/channel/","section":"post","tags":["Golang","中文"],"title":"Go Channel 是线程安全的吗？"},{"body":"1. 栈与堆内存分配 在Go语言中，栈和堆是两种主要的内存分配区域。理解它们的区别和作用，是理解内存逃逸的关键。\n栈（Stack）： 作用：栈是一种连续的内存区域，主要用于存储函数调用中的局部变量。栈的特点是后进先出（LIFO），当函数执行时，局部变量在栈上分配，函数执行结束后，栈上的内存会自动回收。 特点：栈上的内存分配非常快，分配和释放都是由系统自动完成的，空间占用小，适合短生命周期的局部变量。 局限：栈的大小是有限的，当变量的生命周期超出栈帧，或变量的大小超过栈的限制时，栈上的变量就会转移到堆上，这就是内存逃逸。 堆（Heap）： 作用：堆是一个动态内存区域，大小不受限制。Go的**垃圾回收器（GC）**负责自动管理堆内存，分配和释放变量。 特点：堆上的变量可以在程序的不同部分间共享，适用于生命周期较长的对象。 局限：堆的内存分配和释放开销较大。由于堆上的变量需要通过GC回收，因此频繁的堆分配会增加垃圾回收器的负担，影响性能。 总结：\n栈和堆因为内存管理方式不同，堆需要垃圾回收等机制，所以堆的分配和释放速度较慢。栈就是单纯的指针移动，速度快。 栈内存适合短期的、局部的变量，分配速度快，但容量有限。 堆内存适合长期存在的对象，尽管容量大，但垃圾回收的代价较高。 2. Go内存逃逸 内存逃逸是指Go语言中的局部变量从栈转移到堆的现象。当编译器发现某个变量的生命周期超出了当前函数的作用域时，它会将变量从栈转移到堆上分配。\n内存逃逸分析工具： 使用Go语言编译器的逃逸分析工具，可以检测代码中哪些变量发生了内存逃逸。\n1go build -gcflags=\u0026#34;-m\u0026#34; 该命令会在编译时显示哪些变量发生了内存逃逸。\n常见的内存逃逸场景： 简单来说，逃逸发生的原因是：数据在函数结束后还需要存在，无法继续保存在栈中，所以必须移到堆里去。\n2.1 闭包逃逸： 当变量被闭包捕获并在函数结束后继续使用时，编译器会将该变量分配到堆中，因为它的生命周期超出了函数的范围。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func closureEscape() func() int { 6 x := 10 7 return func() int { 8 return x // x 逃逸到堆中 9 } 10} 11 12func main() { 13 f := closureEscape() 14 fmt.Println(f()) // 输出 10 15} 在这个例子中，变量x被闭包捕获，虽然x是局部变量，但由于闭包需要在函数返回后继续使用x，所以x被分配到堆中。\n2.2 返回局部变量的指针： 当一个函数返回局部变量的指针时，Go编译器无法确保这个变量在函数结束后仍然有效，因此会将该变量分配到堆上。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func pointerEscape() *int { 6 x := 10 7 return \u0026amp;x // x 逃逸到堆，因为返回了其地址 8} 9 10func main() { 11 p := pointerEscape() 12 fmt.Println(*p) // 输出 10 13} 由于x的地址被返回到函数外部，编译器必须将其分配到堆上，以确保变量在函数结束后仍然有效。\n2.3 使用接口时的逃逸： 当一个具体类型的变量被赋值给接口类型时，编译器可能无法确定这个变量的具体类型，因此可能会发生内存逃逸。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func interfaceEscape() interface{} { 6 x := 10 7 return x // x 逃逸到堆，因为它被赋值给接口 8} 9 10func main() { 11 fmt.Println(interfaceEscape()) // 输出 10 12} 在这个例子中，x被赋值给interface{}类型，编译器将无法推断x的生命周期，因此会将其分配到堆中。\n2.4 变量在slice中引发的逃逸： 当slice的容量不足以容纳新元素时，Go语言会在堆上重新分配更大的内存空间。此时，原来存储在栈上的元素可能被复制到堆上。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func sliceEscape() []int { 6 s := []int{1, 2} 7 s = append(s, 3) // 容量不足，重新分配，s 可能逃逸到堆 8 return s 9} 10 11func main() { 12 fmt.Println(sliceEscape()) // 输出 [1 2 3] 13} 当slice重新分配内存时，新的slice可能会被分配到堆中，原有的栈上内存也可能被转移到堆中。\n2.5 使用反射引发的逃逸： 当你使用反射来获取变量的地址时，Go 编译器无法确定这个变量是否只会在局部栈中使用。为了安全起见，编译器会选择将该变量分配到堆上，\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;reflect\u0026#34; 6) 7 8func reflectEscape() { 9 x := 10 10 v := reflect.ValueOf(\u0026amp;x) 11 fmt.Println(v) // x 逃逸到堆 12} 13 14func main() { 15 reflectEscape() 16} 在这个例子中，由于反射需要动态获取变量的信息，编译器会将变量分配到堆上。\n3. Go内存泄露 内存泄露是指程序在不再需要某些内存时，未能正确释放这部分内存，导致内存占用不断增加。尽管Go语言的垃圾回收机制能够自动回收不再使用的内存，但某些错误的代码设计仍可能导致内存泄露。\n内存泄露的常见情况： 3.1 持有长时间的引用： 如果对象的引用被不必要地长时间持有，GC无法回收该对象，导致内存泄露。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func leakExample() { 6 s := make([]int, 1e6) // 创建一个大slice 7 global = \u0026amp;s // 将slice的指针保存到全局变量 8} 9 10var global *[]int 11 12func main() { 13 leakExample() 14 fmt.Println(\u0026#34;内存泄露，s无法被GC回收\u0026#34;) 15} 在这个例子中，局部变量s的地址被保存到了全局变量global中，GC无法回收s所占用的内存，导致内存泄露。\n3.2 goroutine泄露： 如果一个goroutine未正确退出，并且一直占用资源，它会导致内存泄露。\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func goroutineLeak() { 9 ch := make(chan int) 10 go func() { 11 for { 12 select { 13 case \u0026lt;-ch: 14 return 15 } 16 } 17 }() 18} 19 20func main() { 21 goroutineLeak() 22 time.Sleep(1 * time.Second) 23 fmt.Println(\u0026#34;goroutine泄露，因为ch通道没有关闭\u0026#34;) 24} 在这个例子中，通道ch未被关闭，导致goroutine无法退出，形成泄露。\n4. 如何避免内存逃逸与内存泄露？ 4.1 避免内存逃逸： 避免返回局部变量的指针：返回局部变量的地址时，会导致该变量从栈逃逸到堆上。 减少闭包的使用：避免将局部变量捕获到闭包中。 尽量使用具体类型而非接口：使用接口时，编译器无法推断具体类型，容易发生逃逸。 控制slice的容量：预先分配足够的slice容量，以减少重新分配的情况。 4.2 避免内存泄露： 确保goroutine正确退出：避免阻塞的goroutine，确保通道关闭或信号机制正常。 及时清理不必要的引用：及时释放不再需要的数据结构，防止GC无法回收。 管理缓存：缓存设计应包括清理机制，以防止长时间占用大量内存。 5. 总结对比：内存逃逸 vs 内存泄露 特性 内存逃逸 内存泄露 定义 局部变量从栈分配转移到堆分配 无法回收的内存，导致内存占用不断增加 原因 返回局部变量地址、闭包、接口赋值、slice扩容等 持有不必要的引用、阻塞的goroutine等 是否是问题 不一定是问题，通常由GC管理，但可能影响性能 是问题，导致内存占用过多，影响系统性能 优化措施 尽量使用栈内存，减少指针返回、控制闭包使用 确保goroutine正确退出，及时清理长生命周期引用 ","link":"https://zhangsiming-blyq.github.io/post/golang/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/","section":"post","tags":["Golang","中文"],"title":"Go内存逃逸与内存泄露详解"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/algoiithm/","section":"categories","tags":null,"title":"algoiithm"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/prometheus/","section":"tags","tags":null,"title":"prometheus"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/prometheus/","section":"categories","tags":null,"title":"prometheus"},{"body":" Grafana通过Thanos Query从所有Prometheus实例中获取数据。 Thanos Query聚合来自两个集群（每个集群包含4个Prometheus实例）的监控数据。 每个Prometheus实例都有一个与之相连的Thanos Sidecar，Thanos Sidecar将Prometheus数据暴露给Thanos Query。 两个Thanos Sidecar组件分别处理不同集群中的Prometheus实例。 1 +-------------+ 2 | Grafana | 3 +------+------+ 4 | 5 v 6 +-------------+ 7 | Thanos Query| 8 +------+------+ 9 | 10 +----------------+----------------+ 11 | | 12 +-------+-------+ +-------+-------+ 13 | Thanos Sidecar| | Thanos Sidecar| 14 +-------+-------+ +-------+-------+ 15 | | 16+---------------+---------------+ +-------------+-------------+ 17| | | | 18v v v v 19Prometheus1 Prometheus2 Prometheus3 Prometheus4 (Cluster 1) 20 21+---------------+---------------+ +-------------+-------------+ 22| | | | 23v v v v 24Prometheus5 Prometheus6 Prometheus7 Prometheus8 (Cluster 2) 1. 监控体系概述 在现代分布式系统中，监控与可观测性至关重要。通过使用Prometheus、Thanos和Grafana，可以构建一个高效、可扩展的监控解决方案：\nPrometheus：负责从被监控服务中拉取（scrape）指标数据，并将其存储为时序数据库（TSDB）。Prometheus支持灵活的查询语言（PromQL）来分析这些数据。 Thanos：扩展Prometheus，提供长期存储、高可用性和水平扩展功能，并解决了Prometheus在大规模集群中的局限性。 Grafana：提供可视化界面，通过展示来自Prometheus和Thanos的数据，帮助用户直观查看监控信息，并支持自定义仪表盘和告警功能。 2. Prometheus：原理与架构 2.1 Prometheus数据抓取原理 Prometheus通过拉取（pull model）模式从被监控服务的端点抓取指标数据。它会周期性地从指定的目标（target endpoints）中获取指标，通常这些端点会暴露一个HTTP接口，遵循Prometheus标准格式。\n核心组件包括：\n时序数据库（TSDB）：存储抓取到的时间序列数据。 PromQL：Prometheus特有的查询语言，允许用户基于时间序列数据进行灵活的分析查询。 服务发现（Service Discovery）：支持自动发现目标，Prometheus通过Kubernetes、Consul、静态配置等方式动态发现监控的服务。 2.2 Prometheus的架构组成 Prometheus Server：核心组件，负责抓取、存储和查询数据。 Alertmanager：处理Prometheus中的告警规则，发送告警通知到邮件、Slack等。 Pushgateway：允许短生命周期的任务将指标数据推送到Prometheus。 3. Prometheus的多实例部署与高可用性 3.1 如何实现Prometheus的高可用？ 为了确保高可用性，多个Prometheus实例可以同时抓取相同的数据。这样当一个Prometheus实例宕机时，其他实例仍然可以继续获取目标的数据。Thanos通过其Thanos Querier组件提供数据去重功能：\nPrometheus实例标签配置：每个Prometheus实例可配置唯一的标签（如replica=\u0026quot;A\u0026quot;）来区分不同的实例。 Thanos Querier去重：Thanos Querier识别不同Prometheus实例的标签，确保当多个Prometheus实例抓取相同数据时，最终查询结果中只返回一份去重后的数据。 3.2 Prometheus实例如何进行分片以避免重复收集？ 在大规模监控系统中，可以通过**分片（Sharding）**策略来分配监控目标，避免重复抓取：\n基于Job的分片：每个Prometheus实例通过配置不同的抓取目标来避免重复抓取。可以通过prometheus.yml文件配置不同的服务、命名空间或集群。 示例：\n1scrape_configs: 2 - job_name: \u0026#39;shard-1\u0026#39; 3 static_configs: 4 - targets: [\u0026#39;node-1:9100\u0026#39;, \u0026#39;node-2:9100\u0026#39;] 5 - job_name: \u0026#39;shard-2\u0026#39; 6 static_configs: 7 - targets: [\u0026#39;node-3:9100\u0026#39;, \u0026#39;node-4:9100\u0026#39;] 基于哈希分片（Hashmod）：通过hashmod机制可以为目标分配唯一ID并均匀分布到不同的Prometheus实例中。此方法在Prometheus 2.26+版本支持的服务发现中实现。 示例配置：\n1relabel_configs: 2 - source_labels: [__address__] 3 modulus: 3 4 target_label: __tmp_hash 3.3 Rule应配置在Prometheus侧而非聚合侧 Prometheus的**告警规则（Alerting Rules）和记录规则（Recording Rules）**应在本地的Prometheus实例上运行，而不是在Thanos的聚合层上运行。这是因为：\n本地Prometheus实例具备实时性，可以更快速地评估规则并触发告警。 在本地执行复杂的规则可以减少聚合层的查询负载，提高整体的系统性能。 4. Prometheus的存储与查询优化策略 4.1 存储策略 Prometheus默认使用本地磁盘存储，但在大规模监控场景中需要进行存储优化：\n短期存储本地化：将最近的数据（例如7天内）存储在本地磁盘上，保证快速查询。 长期存储外部化：使用Thanos将数据上传到对象存储（如S3或GCS）以节省本地存储空间。 4.2 提高查询效率策略 降采样（Downsampling）：Thanos对历史数据进行降采样，降低数据的分辨率，从而减少存储空间并加速查询。 记录规则（Recording Rules）：预先计算常用查询结果并存储在Prometheus中，减少实时查询时的复杂计算。 索引优化：优化Prometheus的索引，减少查询时的扫描量，提升查询效率。 5. Prometheus的服务发现原理 Prometheus可以通过多种方式实现动态的服务发现，尤其是在Kubernetes环境下表现出色。\n5.1 Kubernetes中的服务发现 Prometheus通过Kubernetes API来动态发现服务和Pod。kubernetes_sd_configs用于配置Kubernetes的服务发现，Prometheus通过拉取方式获取Kubernetes集群中的Pod的监控指标。\n示例配置：\n1scrape_configs: 2 - job_name: \u0026#39;kubernetes-pods\u0026#39; 3 kubernetes_sd_configs: 4 - role: pod 此配置将指示Prometheus抓取所有Kubernetes Pod的监控数据。\n5.2 使用Endpoints进行发现 Prometheus还可以抓取Kubernetes的Endpoints对象，Endpoints对象用于发现服务的具体实例（Pod IP）。通过role: endpoints配置即可实现。\n1scrape_configs: 2 - job_name: \u0026#39;kubernetes-endpoints\u0026#39; 3 kubernetes_sd_configs: 4 - role: endpoints 5.3 Kubernetes服务发现的底层实现原理 Prometheus通过kubernetes_sd_configs使用Kubernetes的API进行服务发现。内部实现中，Prometheus利用Kubernetes的Informer机制，通过API服务器持续监听Kubernetes服务、Pod等资源的变化。一旦Kubernetes集群中的服务或Pod发生变动，Prometheus会自动更新其抓取目标列表。\n6. Prometheus的部署与WAL机制 6.1 Prometheus的部署项目结构 典型的Prometheus部署目录结构：\n1├── prometheus.yml # Prometheus配置文件 2├── rules # 规则文件（Recording Rules和Alerting Rules） 3├── data # 数据目录，存储WAL和TSDB 4└── logs # 日志文件 6.2 WAL（Write-Ahead Log）原理 Prometheus使用WAL（预写日志） 来确保数据在写入TSDB前\n不会丢失。工作原理如下：\n当Prometheus抓取到新的数据时，首先将其写入WAL文件中。 数据被持久化到WAL后，Prometheus会定期将这些数据批量写入磁盘的TSDB块。 如果Prometheus意外宕机或崩溃，系统会通过WAL文件恢复未持久化的数据，确保数据一致性。 7. Thanos：Prometheus的扩展与优化 7.1 Thanos的架构组成 Thanos通过Thanos Sidecar与每个Prometheus实例协同工作，提供以下功能：\n长期存储：将Prometheus的数据定期上传到外部对象存储（如S3、GCS等）。 高可用性与水平扩展：Thanos的Store API可以聚合多个Prometheus实例的数据，并通过Thanos Querier提供统一的查询接口。 7.2 Thanos的优化策略 降采样：通过降低历史数据的分辨率，减少存储空间并提高查询性能。 对象存储：通过与S3、GCS等外部存储集成，解决Prometheus本地存储空间的限制。 8. Grafana：数据可视化与告警 8.1 Grafana的作用 Grafana是一款可视化工具，支持集成Prometheus和Thanos数据源。通过自定义的仪表盘，用户可以直观展示各类监控数据，设置告警规则，并在监控指标达到阈值时触发告警通知。\n8.2 Grafana的关键功能 自定义仪表盘：支持用户构建灵活的仪表盘，展示多维度监控数据。 告警集成：支持与邮件、Slack等多种通知渠道集成，帮助运维人员及时处理异常。 9. 生产环境中的Prometheus + Thanos + Grafana 部署 9.1 Prometheus的生产环境部署 端口配置：确保Prometheus实例的监听端口配置正确，尤其在集成Thanos Sidecar时，需避免端口冲突。 挂载存储：确保Prometheus的数据目录、配置文件和规则文件挂载在持久化存储中，以防数据丢失或权限问题。 9.2 Thanos的生产环境部署 部署每个Prometheus实例并配置Thanos Sidecar。 部署Thanos Querier，从多个Prometheus实例聚合数据并统一查询。 使用对象存储（如S3、GCS）配置Thanos的Store Gateway，以便实现长期数据存储。 9.3 Grafana的配置 在Grafana中添加Prometheus和Thanos作为数据源。 创建自定义的仪表盘，配置告警规则，以便在异常发生时及时通知。 10. 其他底层原理 10.1 Prometheus的底层实现 Prometheus通过WAL机制保证数据持久性。每个数据点由时间戳、标签和值组成。抓取到的数据首先被写入WAL文件，然后定期写入TSDB块。如果Prometheus宕机，可以通过WAL文件进行数据恢复，确保数据一致性。\n10.2 Thanos的底层实现 Thanos-Sidecar通过gRPC协议与Thanos-Query进行通信，并通过块上传机制，定期将Prometheus的数据上传到远程对象存储，提供持久化存储和历史数据查询功能。 Thanos-Sidecar和Prometheus共享相同的数据目录，确保数据一致性。\n11. 结论 通过本文的详细阐述，我们已经了解了如何利用Prometheus、Thanos和Grafana构建一个高效、可扩展的监控系统。Prometheus负责数据抓取和存储，Thanos通过提供长期存储和高可用性扩展，确保了数据的持久性和查询效率，Grafana则提供丰富的可视化和告警功能。\n这种监控方案不仅适用于开发环境，也能在生产环境中有效保证系统的可观测性，并在出现问题时及时作出响应。\n","link":"https://zhangsiming-blyq.github.io/post/linux/prometheus/","section":"post","tags":["prometheus","中文"],"title":"基于Prometheus、Thanos与Grafana的监控体系详解"},{"body":"树形结构是计算机科学中重要的数据结构，广泛用于存储、检索和排序数据。以下是常见的树结构：二叉树、红黑树、AVL树、B树和B+树。\n1. 二叉树（Binary Tree） 定义： 二叉树是每个节点最多有两个子节点的树结构，通常称为左子树和右子树。\n插入、查询和删除的操作逻辑： 插入：从根节点开始，按照二叉搜索树的性质，插入较小的值到左子树，较大的值到右子树，递归进行。 查询：按照与插入相同的逻辑，递归查找对应的值。 删除：删除时有三种情况：删除叶子节点、删除有一个子节点的节点、删除有两个子节点的节点。对于有两个子节点的情况，需找到右子树中的最小值来替代被删除的节点。 形态图示： 1 10 2 / \\ 3 5 15 4 / \\ \\ 5 2 7 20 应用场景： 表达式树：在编译器或解释器中，二叉树常用于解析复杂的算术表达式。每个操作符（如 +, *）是树中的内部节点，而操作数（如 3, 5）是叶子节点。编译器利用表达式树来解析并执行复杂表达式。例如表达式 (3 + (5 * 2)) 会被解析成一棵树，先执行乘法，再执行加法。通过二叉树，编译器能够确保按照正确的优先级顺序执行运算，方便表达式的解析与求值。\n决策树：在机器学习中，决策树用于分类和回归模型。每个内部节点表示一个决策条件（如 \u0026quot;是否年龄\u0026gt;30\u0026quot;），叶子节点表示决策的结果（如 \u0026quot;是\u0026quot; 或 \u0026quot;否\u0026quot;）。通过这种结构，机器学习模型能够递归地通过多个决策条件，得出最终分类或预测结果。\n2. 红黑树（Red-Black Tree） 定义： 红黑树是一种自平衡二叉搜索树，通过颜色（红色和黑色）标记来保持平衡。\n插入、查询和删除的操作逻辑： 插入：红黑树首先按二叉搜索树的方式插入节点，之后会根据颜色调整和旋转操作来维持树的平衡。红色节点不能连续存在，且路径中的黑色节点数量相同。 查询：与普通二叉树一样，根据值递归查找左右子树。 删除：删除后根据颜色规则调整，通过旋转和重新着色确保红黑树保持平衡。 形态图示： 1 10(B) 2 / \\ 3 5(R) 15(B) 4 / \\ 5 12(R) 20(R) 应用场景： 操作系统调度器（CFS）：在 Linux 操作系统中，完全公平调度器（CFS）是调度器子系统，用来管理多个正在运行的任务。CFS 使用红黑树存储所有等待运行的任务，以任务的虚拟运行时间为关键字。调度器每次会选择虚拟运行时间最短的任务来执行，并且在执行过程中，会定期更新任务的运行时间。红黑树通过自平衡保证在众多任务中高效查找和调度任务。通过红黑树，CFS 能够在 O(log n) 时间内找到虚拟运行时间最短的任务，确保多任务系统中的公平调度和高效运行。\n字典数据结构（Java TreeMap、C++ std::map 和 std::set）：红黑树被广泛用于字典（Map）和集合（Set）数据结构中，来存储有序的键值对。在 Java 中，TreeMap 的实现基于红黑树，能够在 O(log n) 的时间内完成查找、插入和删除操作。每次插入新的键值对时，TreeMap 会按键的顺序将它插入到红黑树中，并且在插入后会自动平衡树。通过这种方式，TreeMap 能够高效地存储和查询有序数据。例如，在电子商务系统中，TreeMap 可以用于存储商品的价格和商品名称，支持快速查找某个价格范围内的商品。\n3. AVL树（AVL Tree） 定义： AVL 树是一种严格自平衡的二叉搜索树，通过旋转操作保持平衡。\n插入、查询和删除的操作逻辑： 插入：按照二叉搜索树的插入逻辑插入值，之后根据节点的高度调整，保持左右子树高度差不超过 1。 查询：与普通二叉搜索树相同，按值递归查找左右子树。 删除：删除后进行旋转操作，保持树的平衡性。 形态图示： 1 30 2 / \\ 3 20 40 4 / \\ 5 10 25 应用场景： 数据库索引（如 PostgreSQL）：AVL 树用于数据库系统的索引管理。在 PostgreSQL 中，部分索引是基于 AVL 树实现的。数据库系统需要频繁对大规模数据进行查找、插入和删除操作，AVL 树的严格平衡性使其非常适合于这种场景，能够确保索引始终平衡，从而提高查询效率。在数据库查询中，当用户进行 SELECT 查询时，系统可以快速地通过 AVL 树定位到相关数据。此外，AVL 树还用于某些非聚簇索引中，确保数据库的大量查询能够在 O(log n) 时间内完成。\n字典结构：AVL 树适用于需要频繁查询和快速查找的字典结构，特别是在查询密集型场景中。与红黑树相比，AVL 树的平衡性更加严格，查找效率也略高。它能保证每个操作都在 O(log n) 时间内完成，适合用作缓存系统中的高效数据结构。\n4. B树（B-Tree） 定义： B 树是一种多路自平衡搜索树，每个节点可以存储多个键，并且具有多个子节点。\n多路：每个节点可以有多个子节点，而不仅仅是两个。 自平衡：通过旋转和分裂操作，保持树的平衡性。每次插入或删除后，树的高度会保持在一个较小的范围内。\n插入、查询和删除的操作逻辑： 插入：当一个节点达到最大容量时，它会分裂成两个节点，父节点会存储分裂键。 查询：通过节点的键值，递归找到需要查找的子节点或叶子节点。 删除：删除时如果节点变得过小，可能需要合并或借用相邻节点的键。 形态图示： 1 [10 | 20] 2 / | \\ 3 [5] [15] [25] 应用场景： 数据库索引（如 MySQL InnoDB）：B 树是关系型数据库系统中常用的索引结构，特别是用于实现 MySQL InnoDB 存储引擎中的聚簇索引。B 树的节点能够存储多个键值，减少了树的高度，这在处理大数据时尤为重要。聚簇索引将实际数据存储在 B 树的叶子节点中，当用户执行查询时，数据库引擎能够快速通过索引定位数据。B 树的自平衡特性确保了即使在插入大量数据后，索引仍然能够高效工作，极大地减少了磁盘 I/O 次数，从而提升数据库的查询效率。\n文件系统（如 NTFS）：在文件系统中，B 树用于管理文件的目录和文件块索引。例如，NTFS 文件系统使用 B 树来存储文件目录，当用户查找某个文件时，系统通过 B 树结构快速找到文件在磁盘中的存储位置。B 树的多路结构能够高效地管理和组织大量的文件目录，减少文件查找的时间，尤其适用于大规模存储设备。\n5. B+树（B+ Tree） 定义： B+\n树是 B 树的变体，所有数据存储在叶子节点，且叶子节点通过链表相连，内部节点只存储索引。\n插入、查询和删除的操作逻辑： 插入：新数据总是插入到叶子节点。如果叶子节点满，则会进行分裂，分裂的索引提升到父节点。 查询：通过索引找到叶子节点进行查询，链表连接的叶子节点支持顺序遍历和范围查询。 删除：在叶子节点进行删除，如果节点变得太小，会合并或借用相邻节点的键。 形态图示： 1 [10 | 20] 2 / | \\ 3 [5-7] [12-15] [21-25] 4 (链表连接所有叶子节点) 应用场景： 数据库索引（如 MySQL InnoDB）：B+ 树广泛应用于 MySQL 的 InnoDB 存储引擎中，用于构建聚簇索引。与 B 树不同，B+ 树中的数据全部存储在叶子节点，叶子节点之间通过链表连接。这样的结构允许对范围查询和顺序查询进行高效处理。例如，MySQL 中执行 SELECT * FROM table WHERE id BETWEEN 10 AND 20 这样的查询时，B+ 树能够快速找到起始和结束节点，通过链表遍历中间的节点，高效完成范围查询操作。\n文件系统（如 XFS）：B+ 树用于文件系统中的目录索引和数据块管理。在 XFS 文件系统中，B+ 树用于高效地管理大规模文件路径和文件数据块的位置。通过 B+ 树，文件系统能够支持高效的文件顺序查找和访问，同时链表连接的叶子节点允许快速执行顺序读取操作，适合大数据量文件的读写管理。\nB+树相比B树的主要特色在于：所有数据都存储在叶子节点，内部节点只存储索引；叶子节点通过链表连接，便于顺序遍历和范围查询。这使得 B+ 树在执行顺序访问和范围查询时更高效，同时由于索引更紧凑，树的高度更低，空间利用率更高，适用于数据库索引（如 MySQL InnoDB）和文件系统（如 XFS）。\n总结与对比表 树结构 特点与用途 主要应用场景 二叉树 简单的递归结构，易于实现 表达式树、决策树等，用于编译器和机器学习中的数据处理 红黑树 自平衡结构，适合频繁插入和删除 操作系统调度器（Linux CFS）、字典结构（TreeMap、std::map） AVL树 严格平衡，查找速度快 数据库索引（如 PostgreSQL），适用于频繁查询的场景 B树 多路自平衡，减少磁盘 I/O 数据库索引（如 MySQL）、文件系统（如 NTFS） B+树 数据存储在叶子节点，链表连接叶子节点 数据库聚簇索引（如 MySQL InnoDB）、文件系统（如 XFS） ","link":"https://zhangsiming-blyq.github.io/post/algorithm/tree/","section":"post","tags":["algorithm","中文"],"title":"树形结构详解及实际用途"},{"body":"概述 Kubernetes Operator 简介 Kubernetes Operator 是一类 Kubernetes 控制器，它能够自动化管理复杂的应用程序和其生命周期，通常被用来管理有状态应用（如数据库、缓存等）。通过扩展 Kubernetes API，Operator 可以将日常操作流程（如安装、升级、扩展、备份等）转换为 Kubernetes 原生对象，从而实现自动化和声明式管理。\n为什么使用 Operator Operator 通过将 DevOps 团队日常管理应用的运维知识和流程编码化，使复杂的应用程序管理变得简单和自动化。在 Kubernetes 中，Operator 可以持续监控自定义资源，并自动进行相应操作，确保应用程序的状态与用户期望一致。\nOperator 与 Controller 的关系 Operator 实际上是一个高级 Controller，它不仅负责监控和管理 Kubernetes 中的自定义资源 (CR)，还可以执行特定的业务逻辑。Controller 是 Kubernetes 架构中管理资源状态的核心组件，Operator 是对 Controller 的封装和扩展，专门用于复杂应用的生命周期管理。\n核心概念 自定义资源 (CR) 和自定义资源定义 (CRD) 什么是 CR 自定义资源 (Custom Resource, CR) 是 Kubernetes 用户可以定义的扩展对象，用于描述某个具体的应用或资源的期望状态。每个 CR 对象的结构基于其相应的 CRD (Custom Resource Definition)，通过 CR，用户可以声明他们希望 Kubernetes 管理的特定应用或服务。\n什么是 CRD CRD（自定义资源定义）是 Kubernetes 的一种扩展机制，允许用户向 Kubernetes API 添加新的对象类型。通过 CRD，用户可以定义新的资源种类（类似于内置的 Pod、Service 等），并指定这些资源的结构和行为。\nCRD 的结构与定义详解 apiVersion: 指定 API 组和版本，例如 apps/v1。 kind: 定义资源的类型，比如 MySQL、Redis 等。 metadata: 描述 CR 对象的元数据信息，如名称、命名空间等。 spec: 用于描述资源的期望状态，包含资源的配置项，如副本数、存储大小、版本等。 status: 系统生成，用于记录资源的当前状态，如运行中的副本数、最后备份时间等。 控制器 (Controller) Controller 的工作原理 Controller 是 Kubernetes 中的核心组件之一，用于确保集群中的资源状态与用户的期望状态一致。Controller 通过监听资源对象的变化事件（如创建、更新、删除等），并根据这些事件采取行动来调整实际状态。例如，当用户期望创建一个 MySQL 实例时，Controller 监听到 MySQL CR 的创建事件，并根据该 CR 的 spec 定义自动创建相应的 Kubernetes 资源（如 Deployment、Service）。\nController 的生命周期管理 Controller 通过一个无限循环的 \u0026quot;控制循环\u0026quot;（Control Loop）来工作，它会不断地获取资源的当前状态，并与期望状态进行对比。如果发现不一致，Controller 会采取相应的操作来修正状态。Controller 的生命周期管理包括以下几个阶段：\n监听事件：Controller 通过 Informer 监听自定义资源的增删改等事件。 执行 Reconcile：每当资源的状态发生变化时，Controller 会调用 Reconcile 函数来同步状态。 更新状态：Controller 操作 Kubernetes 资源（如创建 Pod、删除 Service 等），确保资源状态符合期望，并更新状态信息。 核心控制循环解释 (Control Loop) 控制循环（Control Loop）是 Controller 实现资源管理的核心机制。它的工作原理是：\n获取资源的实际状态：通过 Kubernetes API 监听或查询资源的当前状态。 对比期望状态和实际状态：根据 CR 中定义的 spec 与资源的当前状态 (status) 进行对比。 采取行动：如果发现状态不一致，Controller 会采取相应的操作（如创建、删除、更新资源），确保资源的实际状态与用户期望一致。 重复此过程：控制循环是持续运行的，确保资源状态始终与期望一致。 Informer Informer 的原理 在 Kubernetes 中，Informer 是一个核心组件，它负责监听 Kubernetes API 资源的变化事件（如增、删、改等），并将这些事件通知给相应的 Controller。Informer 是基于 缓存（Cache） 的机制，通过减少直接与 API Server 的交互来提升系统的性能和效率。\nInformer 的主要工作流程包括：\nList：启动时，Informer 会从 API Server 中获取资源的当前状态列表，并将其缓存。 Watch：Informer 监听资源的变化（创建、更新、删除等），并将变化事件发送给对应的 Controller。 同步数据：Informer 将变化的资源同步到本地缓存，避免每次都向 API Server 请求资源，减少了对 API Server 的压力。 这种机制保证了 Kubernetes 系统的高可用性和高性能。\nSharedInformer 与 Controller 的配合 SharedInformer 是 Informer 的高级版本，允许多个 Controller 共享同一个资源的缓存数据。由于 Kubernetes 集群中的资源可能会被多个 Controller 监控，如果每个 Controller 都独立与 API Server 交互，这会增加系统的负载。通过 SharedInformer，不同的 Controller 可以共享同一个数据源，避免重复查询，提升效率。\nSharedInformer 的主要特点：\n共享缓存：多个 Controller 可以通过一个 SharedInformer 来访问相同的缓存数据，避免每个 Controller 独立维护缓存。 事件广播：SharedInformer 会将监听到的事件广播给所有监听该资源的 Controller，每个 Controller 可以根据业务逻辑处理相应事件。 SharedInformer 的典型工作流程如下：\n启动时，SharedInformer 获取资源的列表并缓存。 监听资源的变化，并更新缓存。 将变化事件通知给所有订阅该资源的 Controller。 Informer 的缓存机制及事件处理流程 Informer 依赖本地缓存来加速数据访问。每当 API Server 中的资源发生变化时，Informer 会将变化事件存储在本地缓存中，并通过事件处理机制通知 Controller。缓存的机制允许 Controller 可以快速访问已经监听的资源，而无需频繁与 API Server 通信。\nInformer 的事件处理流程：\nList 阶段：Informer 启动时，通过 List 操作获取当前所有资源的完整状态，并将这些资源存储到本地缓存中。 Watch 阶段：Informer 通过 Watch 机制持续监听资源的变化事件，如资源的 Add（增加）、Update（更新）和 Delete（删除）。 本地缓存更新：每当有资源变化时，Informer 会更新本地缓存，并根据不同的事件类型（添加、更新、删除）触发不同的事件处理函数。 事件通知：Informer 会将资源变化事件传递给 Controller，Controller 再根据业务逻辑对事件进行处理。 通过这种机制，Informer 可以有效地减少 API Server 的压力，并加速 Controller 的事件处理过程。\n下图展示了 Informer 的事件处理机制：\n1+-------------------+ +-----------------------+ 2| API Server | | Controller | 3| | | | 4| (Add/Update/Delete)-----------\u0026gt; (Reconcile function) | 5| (List/Watch) | | Handles resource | 6+-------------------+ +-----------------------+ 7 ^ ^ 8 | | 9 | +------------------+ | 10 +----+ SharedInformer +------+ 11 | (Cache + Event) | 12 +------------------+ 核心组件介绍：ClientSet、Indexer、Lister Informer 的工作依赖于以下几个关键组件：\nClientSet：\nClientSet 是与 Kubernetes API Server 交互的客户端工具，负责发出请求来获取资源的列表（List）并监听资源的变化（Watch）。Informer 依赖 ClientSet 来与 API Server 通信。 每种资源类型都有一个对应的 ClientSet，例如 PodsClient、ServicesClient 等。 Indexer：\nIndexer 是 Kubernetes 缓存中的一种数据结构，用来根据特定的键（如对象的名称或标签）索引和检索资源对象。它可以高效地从缓存中获取指定资源的信息。 Indexer 提供了一种高效的资源查找方式，特别是在需要从大规模资源列表中查找特定对象时。 Lister：\nLister 是一个用于从本地缓存中快速获取资源的工具，通常结合 Indexer 使用。与直接查询 API Server 不同，Lister 可以从缓存中快速读取资源，提升查询效率。 Lister 允许控制器以类似于直接调用 Kubernetes API 的方式访问缓存数据。 RBAC (Role-Based Access Control) 什么是 RBAC RBAC（基于角色的访问控制）是 Kubernetes 中用于管理用户和服务对集群中资源的访问权限的机制。通过 RBAC，集群管理员可以定义哪些用户或服务账户有权访问哪些资源，以及能够执行哪些操作。\nRBAC 的四个核心概念：\nRole：定义一组对资源的访问权限，如对 Pods 的读取权限或对 Deployments 的修改权限。 RoleBinding：将 Role 分配给一个或多个用户或服务账户，授权他们执行 Role 中定义的操作。 ClusterRole：类似于 Role，但 ClusterRole 可以跨命名空间作用，通常用于管理全局资源或集群级别的访问权限。 ClusterRoleBinding：将 ClusterRole 绑定到用户或服务账户，使其在整个集群范围内具备相应的权限。 创建 RBAC 规则与权限控制 当部署 Kubernetes Operator 时，通常需要为 Operator 定义一系列 RBAC 规则，确保 Operator 能够访问和管理特定资源。为了确保 Operator 拥有必要的权限，必须创建相关的 Role 和 RoleBinding，或者 ClusterRole 和 ClusterRoleBinding。\n创建一个简单的 ClusterRole，例如允许 Operator 访问和管理 Deployment 资源：\n1apiVersion: rbac.authorization.k8s.io/v1 2kind: ClusterRole 3metadata: 4 name: operator-role 5rules: 6 - apiGroups: [\u0026#34;\u0026#34;] 7 resources: [\u0026#34;pods\u0026#34;, \u0026#34;services\u0026#34;] 8 verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;create\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;patch\u0026#34;, \u0026#34;delete\u0026#34;] 9 - apiGroups: [\u0026#34;apps\u0026#34;] 10 resources: [\u0026#34;deployments\u0026#34;] 11 verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;create\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;patch\u0026#34;, \u0026#34;delete\u0026#34;] 然后，创建 ClusterRoleBinding，将该 ClusterRole 绑定到 Operator 的 ServiceAccount：\n1apiVersion: rbac.authorization.k8s.io/v1 2kind: ClusterRoleBinding 3metadata: 4 name: operator-role-binding 5subjects: 6 - kind: ServiceAccount 7 name: operator-sa 8 namespace: default 9roleRef: 10 kind: ClusterRole 11 name: operator-role 12 apiGroup: rbac.authorization.k8s.io Operator 中的 RBAC 规则应用 Operator 作为 Kubernetes 控制器的一部分，需要管理集群中的各种资源。因此，正确配置 RBAC 对 Operator 的安全性和功能至关重要。如果 Operator 需要管理多种资源（如 CRD、Deployment、Service 等），则需要为 Operator 创建适当的 ClusterRole 和 ClusterRoleBinding，确保它具备足够的权限去执行任务。\n在 Operator 项目中，RBAC 通常通过注解的方式生成。例如，Kubebuilder 会自动根据控制器中的注解生成 RBAC 清单：\n1// +kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete 这些注解会在 make manifests 或 make install 时生成对应的 RBAC 文件，确保 Operator 有足够的权限管理 Kubernetes 资源。\nKubebuilder 快速入门 什么是 Kubebuilder Kubebuilder 是一个用于快速构建 Kubernetes Operator 的开发框架，它简化了 Operator 的开发流程，并自动生成所需的代码和配置文件。Kubebuilder 基于 controller-runtime，为开发者提供了一套完整的工具链，帮助他们轻松构建、测试和部署 Kubernetes 控制器和自定义资源。\nKubebuilder 的功能概述 项目结构初始化：Kubebuilder 提供了项目初始化工具，能够自动生成符合最佳实践的项目结构。开发者可以专注于业务逻辑，而不需要手动设置复杂的项目配置。\n自动生成 CRD：开发者可以通过简单的命令定义自定义资源 (CRD) 的 API 结构，Kubebuilder 会自动生成对应的 CRD 定义文件以及与 Kubernetes API 交互的 Go 代码。\n自动生成控制器：通过 Kubebuilder，开发者可以快速生成控制器 (Controller) 的基础代码，控制器负责管理自定义资源的生命周期和状态变化。\nRBAC 配置管理：Kubebuilder 支持通过代码注解自动生成 Kubernetes RBAC (基于角色的访问控制) 配置文件，确保 Operator 拥有正确的权限。\n测试支持：Kubebuilder 提供了内置的测试框架，支持单元测试、集成测试和端到端测试，帮助开发者在本地和 CI 管道中验证 Operator 的行为。\nKustomize 集成：Kubebuilder 使用 Kustomize 进行配置管理，简化了 Kubernetes 清单的定制和部署。开发者可以轻松管理 CRD、RBAC 和 Operator 的部署配置。\n与 Operator SDK 的区别 虽然 Kubebuilder 和 Operator SDK 都是用于开发 Kubernetes Operator 的框架，但它们有一些区别：\n框架基础：\nKubebuilder 是基于 controller-runtime 构建的，从底层开始就提供了对 Kubernetes 控制器的更细粒度控制。 Operator SDK 最初是基于 Kubebuilder 的，也采用了 controller-runtime，但它集成了更多高级工具，如 Ansible、Helm，用于简化非 Go 语言开发者的 Operator 开发。 开发语言支持：\nKubebuilder 主要支持 Go 语言开发，专注于 Go 原生的 Operator 开发体验。 Operator SDK 不仅支持 Go，还支持通过 Ansible 和 Helm 开发 Operator，适合不熟悉 Go 语言的开发者。 项目结构和生成工具：\nKubebuilder 注重生成符合最佳实践的 Go 代码，项目结构清晰且与 Kubernetes 社区的标准紧密一致。 Operator SDK 提供更广泛的工具和命令，允许开发者通过不同的方式生成 Operator，但在生成 Go 项目时与 Kubebuilder 的结构较为相似。 社区和支持：\nKubebuilder 是 Kubernetes 官方提供的 Operator 开发框架，紧密与 Kubernetes 社区保持一致，跟随 Kubernetes 的更新而更新。 Operator SDK 起源于 Red Hat，并在 Ansible 和 Helm Operator 生态系统中有着强大的支持，尤其适合 Red Hat 的 OpenShift 平台。 安装 Kubebuilder github地址：https://github.com/kubernetes-sigs/kubebuilder\n安装步骤 1wget -c https://github.com/kubernetes-sigs/kubebuilder/releases/download/v4.2.0/kubebuilder_darwin_amd64 2mv kubebuilder_darwin_amd64 /usr/local/bin/kubebuilder 3chmod +x /usr/local/bin/kubebuilder 4 5kubebuilder version 6Version: main.version{KubeBuilderVersion:\u0026#34;4.2.0\u0026#34;, KubernetesVendor:\u0026#34;1.31.0\u0026#34;, GitCommit:\u0026#34;c7cde5172dc8271267dbf2899e65ef6f9d30f91e\u0026#34;, BuildDate:\u0026#34;2024-08-17T09:41:45Z\u0026#34;, GoOs:\u0026#34;darwin\u0026#34;, GoArch:\u0026#34;amd64\u0026#34;} Kubebuilder 的项目结构 初始化 Kubebuilder 项目 1kubebuilder init --domain siming.com --repo github.com/ZhangSIming-blyq/mysql-operator 2INFO Writing kustomize manifests for you to edit... 3INFO Writing scaffold for you to edit... 4INFO Get controller runtime: 5$ go get sigs.k8s.io/controller-runtime@v0.19.0 6... 7... 8INFO Update dependencies: 9$ go mod tidy 10... 11... 12Next: define a resource with: 13$ kubebuilder create api 生成自定义资源 (CRD) 的 API 和控制器代码, 这里因为我下面要创建的是MySQL资源，所以这里的group是apps，version是v1，kind是MySQL。\n1kubebuilder create api --group apps --version v1 --kind MySQL 项目文件结构详解 1├── Dockerfile # 用于构建 Operator 的容器镜像 2├── Makefile # 定义了常用的构建、测试、部署命令，简化操作流程 3├── PROJECT # Kubebuilder 项目元数据文件，记录项目配置和版本信息 4├── README.md # 项目介绍文件，记录项目的目标、安装步骤、功能等信息 5├── api 6│ └── v1 7│ ├── groupversion_info.go # 定义了 API 版本信息和资源组信息 8│ ├── mysql_types.go # 自定义资源 (CRD) 的结构定义，包含 CRD 的字段和序列化逻辑 9│ └── zz_generated.deepcopy.go # 自动生成的代码，用于深度拷贝自定义资源对象 10├── bin 11│ ├── controller-gen # Kubebuilder 用于生成控制器的工具，提供 CRD、RBAC 等生成功能的二进制文件 12│ └── controller-gen-v0.16.1 # 特定版本的 controller-gen 工具 13├── cmd 14│ └── main.go # Operator 入口点，初始化 Manager 并启动控制器 15├── config 16│ ├── crd 17│ │ ├── kustomization.yaml # CRD 的 kustomize 配置，用于定制 CRD 的生成 18│ │ └── kustomizeconfig.yaml # 自定义资源定义 (CRD) 的额外配置文件 19│ ├── default 20│ │ ├── kustomization.yaml # 默认的 kustomize 配置文件，用于管理 Operator 的部署 21│ │ ├── manager_metrics_patch.yaml # 配置 Manager 的指标导出补丁 22│ │ └── metrics_service.yaml # 用于暴露 Operator 监控指标的服务配置 23│ ├── manager 24│ │ ├── kustomization.yaml # 用于部署 Manager 的 kustomize 配置 25│ │ └── manager.yaml # Manager 的 Kubernetes 部署清单 26│ ├── network-policy 27│ │ ├── allow-metrics-traffic.yaml # 网络策略，允许访问指标服务 28│ │ └── kustomization.yaml # 网络策略的 kustomize 配置 29│ ├── prometheus 30│ │ ├── kustomization.yaml # Prometheus 监控的 kustomize 配置 31│ │ └── monitor.yaml # Prometheus 对 Operator 进行监控的规则 32│ ├── rbac 33│ │ ├── kustomization.yaml # 用于生成 RBAC 配置的 kustomize 配置 34│ │ ├── leader_election_role.yaml # Leader 选举的角色权限配置 35│ │ ├── leader_election_role_binding.yaml # Leader 选举的角色绑定 36│ │ ├── metrics_auth_role.yaml # 监控指标授权的 RBAC 配置 37│ │ ├── metrics_auth_role_binding.yaml # 监控指标授权的角色绑定 38│ │ ├── metrics_reader_role.yaml # 用于读取指标的角色 39│ │ ├── mysql_editor_role.yaml # MySQL 资源编辑者角色 40│ │ ├── mysql_viewer_role.yaml # MySQL 资源查看者角色 41│ │ ├── role.yaml # 默认的 Operator 角色 42│ │ ├── role_binding.yaml # 角色绑定，将角色分配给 ServiceAccount 43│ │ └── service_account.yaml # 定义 Operator 的 ServiceAccount 44│ └── samples 45│ ├── apps_v1_mysql.yaml # 示例自定义资源，定义 MySQL 资源的 YAML 文件 46│ └── kustomization.yaml # 样例资源的 kustomize 配置 47├── go.mod # Go 模块文件，记录依赖关系 48├── go.sum # Go 依赖的版本锁定文件 49├── hack 50│ └── boilerplate.go.txt # 代码文件的版权声明模板 51├── internal 52│ └── controller 53│ ├── mysql_controller.go # MySQL 控制器的核心逻辑，处理 CR 的状态同步和管理 54│ ├── mysql_controller_test.go # 控制器的单元测试 55│ └── suite_test.go # 控制器的测试套件配置 56└── test 57 ├── e2e 58 │ ├── e2e_suite_test.go # 端到端测试的套件配置 59 │ └── e2e_test.go # 端到端测试的逻辑 60 └── utils 61 └── utils.go # 测试过程中使用的工具函数 文件和目录详细说明：\nDockerfile：用于构建 Operator 的容器镜像。部署到 Kubernetes 集群之前，Operator 会被打包为 Docker 镜像。\nMakefile：包含常见的构建命令，如生成 CRD、安装 CRD、编译控制器代码、运行测试、打包 Operator 等。\napi/v1/：该目录包含自定义资源的定义文件。\nmysql_types.go：定义了 MySQL CRD 的 API 结构体，包括 spec 和 status 字段。 zz_generated.deepcopy.go：通过代码生成工具自动生成的代码，用于深度拷贝自定义资源对象。 controllers/：这个目录存放控制器逻辑。\nmysql_controller.go：实现了核心的控制器逻辑，监听 MySQL CR 的变化并执行相应的操作，如创建、删除、更新 MySQL 实例。 config/：存放所有与 Kubernetes 相关的配置文件，如 CRD、RBAC、部署和监控配置。\ncrd/：定义 CRD 的生成与管理。 rbac/：定义 Operator 所需的 RBAC 权限，包括 ServiceAccount 和角色绑定。 samples/：提供了示例自定义资源文件，用于创建 MySQL 实例。 cmd/：存放 main.go 文件，作为 Operator 的入口点，负责启动控制器并与 Kubernetes API 交互。\ntest/：存放测试代码，分为端到端测试（e2e）和辅助工具文件。\nAPI、Controller 和配置文件的作用 api/ 目录：该目录用于定义自定义资源 (CRD) 的 API，包括资源的结构和字段。开发者可以在这里定义 Go 结构体，Kubebuilder 会根据这些结构体自动生成 CRD。 controllers/ 目录：该目录用于编写控制器逻辑。控制器负责监听自定义资源的状态变化，并根据需要采取相应的行动。Kubebuilder 会生成控制器的基础代码，开发者只需填充业务逻辑即可。 config/ 目录：包含了与 Operator 相关的配置文件，包括：CRD 定义：在 config/crd 目录下生成的 CRD 清单文件。RBAC 配置：在 config/rbac 目录下定义了 Operator 所需的 RBAC 权限。 Manager 配置：在 config/manager 目录下定义了控制器管理器的部署配置。 MySQL Operator 1. 使用 Kubebuilder 初始化项目 在已经初始化的项目中（你已经运行过 kubebuilder init），你可以定义新的 API 和控制器逻辑，而不直接应用到集群。首先，我们生成 API 和控制器的代码：\n1kubebuilder create api --group apps --version v1 --kind MySQL --resource --controller --group apps：定义 API 组为 apps，通常与 Kubernetes 中已有的 apps 组保持一致。 --version v1：定义 API 版本为 v1，表示资源版本为 v1。 --kind MySQL：定义新自定义资源的种类（Kind）为 MySQL。 --resource：生成与自定义资源 (CRD) 相关的代码。 --controller：生成控制器相关的代码，控制器将用于管理 MySQL 实例的生命周期。 生成文件内容：\napi/v1/mysql_types.go：此文件将包含自定义资源的定义，包括 Spec 和 Status 的结构。 controllers/mysql_controller.go：此文件将包含初始的控制器代码，用于后续管理 MySQL 资源的生命周期。 config/crd/：此目录将包含生成的 Kubernetes CRD 定义清单文件。 2.CRD 的定义与生成 流程综述：\n生成 API 和控制器文件：使用 kubebuilder create api 命令生成自定义资源相关的文件，但不应用。 编辑 mysql_types.go：定义 MySQL 资源的 Spec 和 Status 字段。 生成代码：使用 make generate 生成深度拷贝函数等辅助代码。 生成 CRD 清单文件：使用 make manifests 生成 Kubernetes CRD YAML 文件，但不将其应用到集群。 手动查看或修改生成的文件：在 config/crd/bases/ 中找到生成的 CRD 文件，进一步检查或修改。 我们将编写自定义资源 MySQL 的 Spec 和 Status 字段，并使用 Kubebuilder 的标注 (annotations) 自动生成深度拷贝函数、CRD 定义等。\n修改 mysql_types.go: mysql_types.go 文件是定义自定义资源类型的主要文件。在这里，我们需要定义 MySQL 的 Spec（期望状态）和 Status（当前状态）。\n文件路径：api/v1/mysql_types.go\n1package v1 2 3import ( 4 metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 5) 6 7// MySQLSpec 定义了 MySQL 资源的期望状态 8type MySQLSpec struct { 9 // MySQL 用户名 10 Username string `json:\u0026#34;username\u0026#34;` 11 12 // MySQL 用户密码 13 Password string `json:\u0026#34;password\u0026#34;` 14 15 // 数据库名称 16 Database string `json:\u0026#34;database\u0026#34;` 17 18 // MySQL 实例的副本数（用于扩展） 19 Size int32 `json:\u0026#34;size\u0026#34;` 20 21 // 定期备份的时间表（Cron 表达式） 22 BackupSchedule string `json:\u0026#34;backupSchedule\u0026#34;` 23 24 // 备份存储路径 25 BackupPath string `json:\u0026#34;backupPath\u0026#34;` 26} 27 28// MySQLStatus 定义了 MySQL 资源的当前状态 29type MySQLStatus struct { 30 // 当前可用的 MySQL 副本数 31 ReadyReplicas int32 `json:\u0026#34;readyReplicas\u0026#34;` 32 33 // 最近备份的时间 34 LastBackupTime *metav1.Time `json:\u0026#34;lastBackupTime,omitempty\u0026#34;` 35 36 // 资源状态条件（如是否可用、是否需要备份等） 37 Conditions []metav1.Condition `json:\u0026#34;conditions,omitempty\u0026#34;` 38} 39 40// +kubebuilder:object:root=true 41// +kubebuilder:subresource:status 42 43// MySQL 是 MySQL 资源的 Schema 44type MySQL struct { 45 metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 46 metav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` 47 48 Spec MySQLSpec `json:\u0026#34;spec,omitempty\u0026#34;` 49 Status MySQLStatus `json:\u0026#34;status,omitempty\u0026#34;` 50} 51 52// +kubebuilder:object:root=true 53 54// MySQLList 包含 MySQL 资源的列表 55type MySQLList struct { 56 metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 57 metav1.ListMeta `json:\u0026#34;metadata,omitempty\u0026#34;` 58 Items []MySQL `json:\u0026#34;items\u0026#34;` 59} 60 61func init() { 62 SchemeBuilder.Register(\u0026amp;MySQL{}, \u0026amp;MySQLList{}) 63} 代码解释\nMySQLSpec：定义期望的 MySQL 实例的配置信息（如用户名、密码、副本数、备份计划等）。 MySQLStatus：定义 MySQL 实例的运行状态，包括副本数、最后备份时间和状态条件。 +kubebuilder:object:root=true：告诉 Kubebuilder 这是自定义资源的根对象。 +kubebuilder:subresource:status：让 Kubernetes 自动创建一个子资源来管理 status 字段。 在完成 mysql_types.go 的定义后，运行以下命令来生成相应的辅助代码：\n1# `make generate` 的作用： 2# 生成深度拷贝函数 `zz_generated.deepcopy.go`，确保在 Kubernetes 控制器中可以安全地拷贝自定义资源对象。 3# 确保自定义资源的代码与 Kubernetes API 兼容。 4make generate 你将在 api/v1/ 目录下看到生成的 zz_generated.deepcopy.go 文件。\n生成 Kubernetes CRD 清单文件\n为了将定义的 CRD 注册到 Kubernetes，我们需要生成相应的 CRD 定义 YAML 文件。此时，生成代码但不应用。你可以使用 make manifests 命令生成清单文件。\n1# **`make manifests` 的作用**： 2# - 该命令会基于 `mysql_types.go` 中的定义生成相应的 Kubernetes CRD 定义文件。 3# - 文件会被生成到 `config/crd/bases/` 目录下。 4make manifests 生成的文件\nconfig/crd/bases/apps.example.com_mysqls.yaml：这个 YAML 文件包含了 MySQL 自定义资源的定义，你可以查看文件，里面会包含以下内容：\nspec 和 status 字段的定义。 API 组名、版本信息和其他元数据。 3. 详细的 Controller 部分开发文档 流程综述\n生成控制器文件：使用 kubebuilder create api --controller 生成控制器文件。 编写控制器逻辑：在 mysql_controller.go 中编写 Reconcile 函数，处理自定义资源的状态变化。 生成代码：运行 make generate 生成辅助代码。 手动查看和修改文件：生成的文件位于 config/ 目录下，可手动查看或修改生成的 Kubernetes 清单。 当你运行 kubebuilder create api --controller 时，已经生成了一个初始的控制器文件。接下来，我们将编写控制器的业务逻辑。\n生成的文件路径：controllers/mysql_controller.go\n1. 编辑 mysql_controller.go\nmysql_controller.go 文件中包含了控制器的主要逻辑。我们将在这里编写 Reconcile 函数，它将根据 MySQL CR 的状态采取相应操作。\n1package controller 2 3import ( 4\t\u0026#34;context\u0026#34; 5\tappsv1 \u0026#34;k8s.io/api/apps/v1\u0026#34; 6\tcorev1 \u0026#34;k8s.io/api/core/v1\u0026#34; 7\t\u0026#34;k8s.io/apimachinery/pkg/api/errors\u0026#34; 8\tmetav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 9\t\u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; 10\t\u0026#34;k8s.io/apimachinery/pkg/types\u0026#34; 11\tctrl \u0026#34;sigs.k8s.io/controller-runtime\u0026#34; 12\t\u0026#34;sigs.k8s.io/controller-runtime/pkg/client\u0026#34; 13\t\u0026#34;sigs.k8s.io/controller-runtime/pkg/log\u0026#34; 14 15\tappsv1alpha1 \u0026#34;github.com/ZhangSIming-blyq/mysql-operator/api/v1\u0026#34; 16) 17 18// MySQLReconciler 是 MySQL 控制器的结构体 19type MySQLReconciler struct { 20\tclient.Client 21\tScheme *runtime.Scheme 22} 23 24// Reconcile 是控制器的核心逻辑，用于处理 MySQL CR 的状态变化 25func (r *MySQLReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) { 26\t/* 27\t是的，目前的 Reconcile 逻辑主要涵盖以下两点： 28 29\t创建 MySQL 的 Deployment：如果 MySQL CR 对应的 Deployment 不存在，会根据 CR 中定义的 spec 创建一个新的 Deployment。 30\t控制副本数：如果 MySQL CR 的 spec.size 与现有 Deployment 的副本数不匹配，控制器会更新 Deployment，以确保实际副本数与期望的副本数一致。 31\t除此之外，Reconcile 函数还会更新 MySQL CR 的 status，将 Deployment 中实际的副本数同步到 MySQL CR 的 ReadyReplicas 字段。 32\t*/ 33\tlog := log.FromContext(ctx) 34 35\t// 获取 MySQL 实例: 在 Kubernetes 的控制器中，r.Get 函数只会返回一个具体的对象，而不会返回多个对象。这是因为 req.NamespacedName 包含了特定的 namespace 和 name，代表了一个唯一的资源实例。因此，不会出现 Get 返回多个对象的情况。 36\tvar mysql appsv1alpha1.MySQL 37\tif err := r.Get(ctx, req.NamespacedName, \u0026amp;mysql); err != nil { 38\tif errors.IsNotFound(err) { 39\t// 如果没有找到 MySQL 实例，可能已经被删除，不采取行动 40\tlog.Info(\u0026#34;MySQL resource not found. Ignoring since object must be deleted\u0026#34;) 41\treturn ctrl.Result{}, nil 42\t} 43\tlog.Error(err, \u0026#34;Failed to get MySQL\u0026#34;) 44\treturn ctrl.Result{}, err 45\t} 46 47\t// 检查 MySQL Secret 是否存在，如果不存在则创建 48\tvar secret corev1.Secret 49\tsecretName := mysql.Name // 使用 MySQL CR 的名称作为 Secret 名称 50\terr := r.Get(ctx, types.NamespacedName{Name: secretName, Namespace: mysql.Namespace}, \u0026amp;secret) 51\tif err != nil \u0026amp;\u0026amp; errors.IsNotFound(err) { 52\tlog.Info(\u0026#34;Creating a new Secret for MySQL\u0026#34;, \u0026#34;Secret.Namespace\u0026#34;, mysql.Namespace, \u0026#34;Secret.Name\u0026#34;, secretName) 53 54\t// 从 MySQL CR 中获取 username 和 password 55\tusername := mysql.Spec.Username 56\tpassword := mysql.Spec.Password 57 58\t// 创建 Secret 59\tsecret = corev1.Secret{ 60\tObjectMeta: metav1.ObjectMeta{ 61\tName: secretName, 62\tNamespace: mysql.Namespace, 63\t}, 64\tStringData: map[string]string{ 65\t\u0026#34;MYSQL_ROOT_PASSWORD\u0026#34;: password, // 使用 CR 中的 password 66\t\u0026#34;MYSQL_USER\u0026#34;: username, // 使用 CR 中的 username 67\t}, 68\tType: corev1.SecretTypeOpaque, 69\t} 70 71\tif err := r.Create(ctx, \u0026amp;secret); err != nil { 72\tlog.Error(err, \u0026#34;Failed to create new Secret\u0026#34;, \u0026#34;Secret.Namespace\u0026#34;, mysql.Namespace, \u0026#34;Secret.Name\u0026#34;, secretName) 73\treturn ctrl.Result{}, err 74\t} 75\t// 重新排队 Reconcile 76\treturn ctrl.Result{Requeue: true}, nil 77\t} else if err != nil { 78\tlog.Error(err, \u0026#34;Failed to get Secret\u0026#34;) 79\treturn ctrl.Result{}, err 80\t} 81 82\t// 检查是否存在 MySQL Deployment，如果不存在则创建 83\tvar deployment appsv1.Deployment 84\terr = r.Get(ctx, types.NamespacedName{Name: mysql.Name, Namespace: mysql.Namespace}, \u0026amp;deployment) 85\tif err != nil \u0026amp;\u0026amp; errors.IsNotFound(err) { 86\tlog.Info(\u0026#34;Creating a new Deployment for MySQL\u0026#34;, \u0026#34;Deployment.Namespace\u0026#34;, mysql.Namespace, \u0026#34;Deployment.Name\u0026#34;, mysql.Name) 87\t// 根据CRD的定义创建 Deployment 88\tdep := r.mysqlDeployment(\u0026amp;mysql) 89\tif err := r.Create(ctx, dep); err != nil { 90\tlog.Error(err, \u0026#34;Failed to create new Deployment\u0026#34;, \u0026#34;Deployment.Namespace\u0026#34;, mysql.Namespace, \u0026#34;Deployment.Name\u0026#34;, mysql.Name) 91\treturn ctrl.Result{}, err 92\t} 93\t// 重新排队 Reconcile 94\treturn ctrl.Result{Requeue: true}, nil 95\t} else if err != nil { 96\tlog.Error(err, \u0026#34;Failed to get Deployment\u0026#34;) 97\treturn ctrl.Result{}, err 98\t} 99 100\t// 确保副本数与期望一致 101\tsize := mysql.Spec.Size 102\tif *deployment.Spec.Replicas != size { 103\tdeployment.Spec.Replicas = \u0026amp;size 104\tif err := r.Update(ctx, \u0026amp;deployment); err != nil { 105\tlog.Error(err, \u0026#34;Failed to update Deployment\u0026#34;, \u0026#34;Deployment.Namespace\u0026#34;, mysql.Namespace, \u0026#34;Deployment.Name\u0026#34;, mysql.Name) 106\treturn ctrl.Result{}, err 107\t} 108\t// 创建完secret没有必要立刻重建 109\treturn ctrl.Result{}, nil 110\t} 111 112\t// 更新 MySQL 状态 113\tmysql.Status.ReadyReplicas = deployment.Status.ReadyReplicas 114\tif err := r.Status().Update(ctx, \u0026amp;mysql); err != nil { 115\tlog.Error(err, \u0026#34;Failed to update MySQL status\u0026#34;) 116\treturn ctrl.Result{}, err 117\t} 118 119\treturn ctrl.Result{}, nil 120} 121 122// mysqlDeployment 返回定义的 MySQL Deployment 123func (r *MySQLReconciler) mysqlDeployment(mysql *appsv1alpha1.MySQL) *appsv1.Deployment { 124\tlabels := map[string]string{\u0026#34;app\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;mysql_cr\u0026#34;: mysql.Name} 125\treplicas := mysql.Spec.Size 126 127\tdep := \u0026amp;appsv1.Deployment{ 128\tObjectMeta: metav1.ObjectMeta{ 129\tName: mysql.Name, 130\tNamespace: mysql.Namespace, 131\t}, 132\tSpec: appsv1.DeploymentSpec{ 133\tReplicas: \u0026amp;replicas, 134\tSelector: \u0026amp;metav1.LabelSelector{ 135\tMatchLabels: labels, 136\t}, 137\tTemplate: corev1.PodTemplateSpec{ 138\tObjectMeta: metav1.ObjectMeta{ 139\tLabels: labels, 140\t}, 141\tSpec: corev1.PodSpec{ 142\tContainers: []corev1.Container{{ 143\tName: \u0026#34;mysql\u0026#34;, 144\tImage: \u0026#34;mysql:5.7\u0026#34;, 145\tPorts: []corev1.ContainerPort{{ 146\tContainerPort: 3306, 147\tName: \u0026#34;mysql\u0026#34;, 148\t}}, 149\tEnv: []corev1.EnvVar{ 150\t{ 151\tName: \u0026#34;MYSQL_ROOT_PASSWORD\u0026#34;, 152\tValueFrom: \u0026amp;corev1.EnvVarSource{ 153\tSecretKeyRef: \u0026amp;corev1.SecretKeySelector{ 154\tKey: \u0026#34;MYSQL_ROOT_PASSWORD\u0026#34;, 155\tLocalObjectReference: corev1.LocalObjectReference{ 156\tName: mysql.Name, 157\t}, 158\t}, 159\t}, 160\t}, 161\t}, 162\t}}, 163\t}, 164\t}, 165\t}, 166\t} 167\t// Set the owner reference for garbage collection 168\tctrl.SetControllerReference(mysql, dep, r.Scheme) 169\treturn dep 170} 171 172// SetupWithManager 将控制器注册到 Manager 中 173func (r *MySQLReconciler) SetupWithManager(mgr ctrl.Manager) error { 174\treturn ctrl.NewControllerManagedBy(mgr). 175\tFor(\u0026amp;appsv1alpha1.MySQL{}). 176\tOwns(\u0026amp;appsv1.Deployment{}). 177\tComplete(r) 178} 代码逻辑解释\n获取 MySQL CR 对象：\n首先，通过 r.Get 函数获取当前的 MySQL 实例。如果实例不存在，控制器会跳过当前操作。 检查 MySQL Deployment(还有前置的secret) 是否存在：\n如果 MySQL 实例的 Deployment 不存在，控制器将根据 MySQL CR 的 Spec 字段创建新的 Deployment，用于启动 MySQL 容器。 同步副本数：\n如果 MySQL 的实际副本数与 spec 中定义的不一致，控制器会更新 Deployment，确保副本数与期望保持一致。 更新 MySQL 的状态：\n将 Deployment 中的副本数写入 MySQL CR 的 Status 字段，以反映当前 MySQL 实例的运行状态。 SetupWithManager：\n控制器通过 SetupWithManager 注册到管理器 (Manager) 中，监听 MySQL 资源以及 Deployment 的变化。 六、生成 Controller 代码\n在编写完控制器逻辑之后，执行以下命令生成并更新相应的代码：\n1make generate 4. 手动部署 Operator 到 Kubernetes 集群并查看效果 完成代码生成后，接下来需要将生成的 Operator 部署到 Kubernetes 集群并验证其功能。以下步骤将指导你如何构建 Operator 镜像、部署 Operator、并测试其运行情况。\n构建并推送 Operator 镜像\n首先，我们需要将 Operator 打包为容器镜像。执行以下命令构建 Docker 镜像：\n1make docker-build IMG=\u0026lt;your-operator-image\u0026gt;:\u0026lt;tag\u0026gt; 将 \u0026lt;your-operator-image\u0026gt; 替换为你镜像的名称（例如 myregistry/mysql-operator），\u0026lt;tag\u0026gt; 替换为版本号（如 v1.0.0）。例如：\n1make docker-build IMG=myregistry/mysql-operator:v1.0.0 接着，将构建好的 Docker 镜像推送到镜像仓库：\n1make docker-push IMG=myregistry/mysql-operator:v1.0.0 更新 Kubernetes 部署文件\n在 config/manager/manager.yaml 文件中，找到 image: 字段，将其更新为刚刚推送的 Docker 镜像：\n1spec: 2 containers: 3 - name: manager 4 image: myregistry/mysql-operator:v1.0.0 5 command: 6 - /manager 生成 Kubernetes 清单文件\n使用以下命令生成 Kubernetes 所需的 CRD、RBAC 规则和部署清单文件：\n1make manifests 生成的文件将位于 config/crd/、config/rbac/ 和 config/manager/ 目录中。\n部署 Operator到kubernetes集群\n1# 上传镜像到kubernetes所在机器 2docker image save docker.io/myregistry/mysql-operator:v1.0.0 \u0026gt; dockerimage 3 4du -sh dockerimage 5 81M\tdockerimage 6 7scp dockerimage siming-dev:~ 8dockerimage 9 10# 部署各种yaml 11k apply -f crd/bases/apps.siming.com_mysqls.yaml 12k apply -f manager/manager.yaml 13k apply -f rbac/service_account.yaml 14k apply -f rbac/role_binding.yaml 15k apply -f rbac/role.yaml 16 17# 查看状态: 如果rbac权限不够，比如代码逻辑需要，记得手动更新 18k logs -f controller-manager-6c784ddb46-2b7lb 192024-09-17T12:46:43Z\tINFO\tsetup\tstarting manager 202024-09-17T12:46:43Z\tINFO\tstarting server\t{\u0026#34;name\u0026#34;: \u0026#34;health probe\u0026#34;, \u0026#34;addr\u0026#34;: \u0026#34;[::]:8081\u0026#34;} 21I0917 12:46:43.256807 1 leaderelection.go:254] attempting to acquire leader lease system/b3982890.siming.com... 22I0917 12:47:00.943439 1 leaderelection.go:268] successfully acquired lease system/b3982890.siming.com 232024-09-17T12:47:00Z\tDEBUG\tevents\tcontroller-manager-6c784ddb46-2b7lb_8dccc7f2-caa7-4e2e-8268-8726aab5a9cf became leader\t{\u0026#34;type\u0026#34;: \u0026#34;Normal\u0026#34;, \u0026#34;object\u0026#34;: {\u0026#34;kind\u0026#34;:\u0026#34;Lease\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;b3982890.siming.com\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;bd617fbe-a002-4545-8a23-ed4dd77d7f82\u0026#34;,\u0026#34;apiVersion\u0026#34;:\u0026#34;coordination.k8s.io/v1\u0026#34;,\u0026#34;resourceVersion\u0026#34;:\u0026#34;1470723\u0026#34;}, \u0026#34;reason\u0026#34;: \u0026#34;LeaderElection\u0026#34;} 242024-09-17T12:47:00Z\tINFO\tStarting EventSource\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;kind source: *v1.MySQL\u0026#34;} 252024-09-17T12:47:00Z\tINFO\tStarting EventSource\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;kind source: *v1.Deployment\u0026#34;} 262024-09-17T12:47:00Z\tINFO\tStarting Controller\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;} 272024-09-17T12:47:01Z\tINFO\tStarting workers\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;worker count\u0026#34;: 1} 测试 Operator 接下来，通过应用 MySQL 自定义资源来测试 Operator 的功能。你可以修改 config/samples/apps_v1_mysql.yaml 文件来创建一个 MySQL 实例。例如：\n1apiVersion: apps.example.com/v1 2kind: MySQL 3metadata: 4 name: example-mysql 5spec: 6 username: root 7 password: password123 8 database: mydatabase 9 size: 3 10 backupSchedule: \u0026#34;*/5 * * * *\u0026#34; 11 backupPath: /backups 创建mysql，查看operator日志\n1k logs -f controller-manager-578b69d9d4-t228b ok | base py | with ubuntu@VM-24-14-ubuntu | at 22:45:08 22024-09-17T14:41:49Z\tINFO\tsetup\tstarting manager 32024-09-17T14:41:49Z\tINFO\tstarting server\t{\u0026#34;name\u0026#34;: \u0026#34;health probe\u0026#34;, \u0026#34;addr\u0026#34;: \u0026#34;[::]:8081\u0026#34;} 4I0917 14:41:49.676064 1 leaderelection.go:254] attempting to acquire leader lease system/b3982890.siming.com... 5I0917 14:42:17.231093 1 leaderelection.go:268] successfully acquired lease system/b3982890.siming.com 62024-09-17T14:42:17Z\tDEBUG\tevents\tcontroller-manager-578b69d9d4-t228b_521b43d8-0f30-44b1-a596-83d2946336b4 became leader\t{\u0026#34;type\u0026#34;: \u0026#34;Normal\u0026#34;, \u0026#34;object\u0026#34;: {\u0026#34;kind\u0026#34;:\u0026#34;Lease\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;b3982890.siming.com\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;bd617fbe-a002-4545-8a23-ed4dd77d7f82\u0026#34;,\u0026#34;apiVersion\u0026#34;:\u0026#34;coordination.k8s.io/v1\u0026#34;,\u0026#34;resourceVersion\u0026#34;:\u0026#34;1484357\u0026#34;}, \u0026#34;reason\u0026#34;: \u0026#34;LeaderElection\u0026#34;} 72024-09-17T14:42:17Z\tINFO\tStarting EventSource\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;kind source: *v1.MySQL\u0026#34;} 82024-09-17T14:42:17Z\tINFO\tStarting EventSource\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;kind source: *v1.Deployment\u0026#34;} 92024-09-17T14:42:17Z\tINFO\tStarting Controller\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;} 102024-09-17T14:42:17Z\tINFO\tStarting workers\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;worker count\u0026#34;: 1} 112024-09-17T14:43:01Z\tINFO\tCreating a new Deployment for MySQL\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;MySQL\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;}, \u0026#34;namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;mysql-sample\u0026#34;, \u0026#34;reconcileID\u0026#34;: \u0026#34;90483a7a-4ba9-4381-a402-04a18635a0b9\u0026#34;, \u0026#34;Deployment.Namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;Deployment.Name\u0026#34;: \u0026#34;mysql-sample\u0026#34;} 122024-09-17T14:45:00Z\tINFO\tMySQL resource not found. Ignoring since object must be deleted\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;MySQL\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;}, \u0026#34;namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;mysql-sample\u0026#34;, \u0026#34;reconcileID\u0026#34;: \u0026#34;a93dd691-e78f-46fa-9672-fde7cf421d6d\u0026#34;} 132024-09-17T14:45:00Z\tINFO\tMySQL resource not found. Ignoring since object must be deleted\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;MySQL\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;}, \u0026#34;namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;mysql-sample\u0026#34;, \u0026#34;reconcileID\u0026#34;: \u0026#34;10467c4f-e29d-4aca-b60d-878a3ceac98a\u0026#34;} 142024-09-17T14:45:07Z\tINFO\tCreating a new Secret for MySQL\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;MySQL\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;}, \u0026#34;namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;mysql-sample\u0026#34;, \u0026#34;reconcileID\u0026#34;: \u0026#34;f4e005b4-b4db-49fd-a838-e9031958e9e8\u0026#34;, \u0026#34;Secret.Namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;Secret.Name\u0026#34;: \u0026#34;mysql-sample\u0026#34;} 152024-09-17T14:45:07Z\tINFO\tCreating a new Deployment for MySQL\t{\u0026#34;controller\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;controllerGroup\u0026#34;: \u0026#34;apps.siming.com\u0026#34;, \u0026#34;controllerKind\u0026#34;: \u0026#34;MySQL\u0026#34;, \u0026#34;MySQL\u0026#34;: {\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;}, \u0026#34;namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;mysql-sample\u0026#34;, \u0026#34;reconcileID\u0026#34;: \u0026#34;748ccf1b-e0ca-4544-8f11-8cd40b526458\u0026#34;, \u0026#34;Deployment.Namespace\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;Deployment.Name\u0026#34;: \u0026#34;mysql-sample\u0026#34;} 16... 17 18kp 19controller-manager-578b69d9d4-t228b 1/1 Running 0 3m39s 20mysql-sample-64b88f58f7-9lkr9 1/1 Running 0 20s 21 22k get mysql mysql-sample -o yaml 23apiVersion: apps.siming.com/v1 24kind: MySQL 25metadata: 26 annotations: 27 kubectl.kubernetes.io/last-applied-configuration: | 28 {\u0026#34;apiVersion\u0026#34;:\u0026#34;apps.siming.com/v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;MySQL\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;app.kubernetes.io/managed-by\u0026#34;:\u0026#34;kustomize\u0026#34;,\u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;mysql-operator\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;mysql-sample\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;system\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;backupPath\u0026#34;:\u0026#34;/backups\u0026#34;,\u0026#34;backupSchedule\u0026#34;:\u0026#34;*/5 * * * *\u0026#34;,\u0026#34;database\u0026#34;:\u0026#34;mydatabase\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;password123\u0026#34;,\u0026#34;size\u0026#34;:1,\u0026#34;username\u0026#34;:\u0026#34;root\u0026#34;}} 29 creationTimestamp: \u0026#34;2024-09-17T14:45:07Z\u0026#34; 30 generation: 1 31 labels: 32 app.kubernetes.io/managed-by: kustomize 33 app.kubernetes.io/name: mysql-operator 34 name: mysql-sample 35 namespace: system 36 resourceVersion: \u0026#34;1484746\u0026#34; 37 uid: 3e799684-8646-4c20-a1dd-6724ab78e56b 38spec: 39 backupPath: /backups 40 backupSchedule: \u0026#39;*/5 * * * *\u0026#39; 41 database: mydatabase 42 password: password123 43 size: 1 44 username: root 45status: 46 readyReplicas: 1 47 48# 把副本改成2之后会通过operator自动创建 49k apply -f samples/apps_v1_mysql.yaml 50mysql.apps.siming.com/mysql-sample configured 51 52kp -w 53NAME READY STATUS RESTARTS AGE 54controller-manager-578b69d9d4-t228b 1/1 Running 0 5m27s 55mysql-sample-64b88f58f7-9lkr9 1/1 Running 0 2m8s 56mysql-sample-64b88f58f7-trwrc 0/1 ContainerCreating 0 1s 57mysql-sample-64b88f58f7-trwrc 1/1 Running 0 2s Kubebuilder 原理详解 Kubebuilder 的核心组件 Controller-runtime 的作用\nController-runtime 是 Kubebuilder 构建 Kubernetes Operator 的核心库，它为开发者提供了一套标准化的控制器开发工具，简化了 Kubernetes 资源的管理工作。controller-runtime 的主要作用包括：\n控制器管理：\ncontroller-runtime 提供了一个 Manager，负责启动和管理所有的控制器。Manager 会管理控制器的生命周期，并确保它们持续运行。 通过 Manager，多个控制器可以并行运行，监控和处理不同资源的状态变化。 事件监听与处理：\nInformer 监听 Kubernetes 资源的变化事件（如创建、更新、删除等），controller-runtime 会通过这些事件驱动控制器的 Reconcile 函数。 当资源的状态与期望不一致时，Reconcile 函数被触发，执行对应的逻辑进行同步。 资源的缓存机制：\ncontroller-runtime 使用缓存本地存储资源的状态，减少与 Kubernetes API Server 的交互。控制器可以优先从缓存中获取资源信息，这提高了系统性能并减少了对 API Server 的负载。 封装 Client 交互：\ncontroller-runtime 提供了一个简化的 Client，开发者可以通过它来对 Kubernetes 资源进行增删改查操作，而无需直接与 Kubernetes API Server 进行复杂的 HTTP 请求交互。 例如，通过 Client 可以轻松创建或更新 Kubernetes 资源，如 Pods、Deployments、Services 等。 为什么 controller-runtime 能做这些？ controller-runtime 封装了复杂的 API 调用、缓存机制和事件监听系统，开发者只需编写核心业务逻辑，它会自动处理资源的状态同步、错误处理、重试等过程。它能够通过 Manager 和 Client 管理控制器的生命周期和资源交互，使得 Operator 能够以高效、优雅的方式与 Kubernetes 生态系统交互。\nCode Generation（代码生成）的原理\n代码生成 是 Kubebuilder 的一个重要特性，它通过自动生成大量样板代码，减少了开发者的重复工作量。Kubebuilder 的代码生成功能基于 Go 语言的代码注解，通过注解和命令行工具生成相应的 CRD 文件、深度拷贝函数、RBAC 权限等。\nAPI 生成：\n当开发者定义自定义资源 (CRD) 的结构体时，Kubebuilder 会根据这些定义自动生成 Kubernetes 所需的 CRD 清单文件以及相应的 Go 代码。例如，你定义的资源 MySQLSpec 和 MySQLStatus 会生成相应的 yaml 文件，用于在集群中注册 CRD。 深度拷贝函数生成：\nKubernetes 需要在内部对对象进行深度拷贝操作，Kubebuilder 提供了自动生成深度拷贝函数的能力。开发者只需定义资源的结构，生成工具会自动为这些结构体生成 DeepCopy 函数，确保对象可以安全地在不同线程和上下文中传递。 RBAC 权限生成：\n在控制器代码中，开发者可以通过注解（如 +kubebuilder:rbac）为控制器生成相应的 RBAC 配置。注解会告诉 Kubebuilder 控制器需要对哪些资源有权限，这样 Kubebuilder 会自动生成 Kubernetes 中的 RBAC 规则清单，确保控制器可以正确操作相关资源。 为什么 Kubebuilder 能做到？ Kubebuilder 通过静态分析代码注解，结合 Kubernetes API 的需求，自动生成符合 Kubernetes 标准的资源清单和代码逻辑。它的底层依赖于 Kubernetes 的工具链（如 controller-tools）和 Go 语言的反射机制，开发者只需编写核心业务逻辑，Kubebuilder 就能自动生成复杂的样板代码。\nKubebuilder 的工作流程 Kubebuilder 的工作流程包括初始化项目、生成 API 和控制器代码、编写业务逻辑，以及最终生成 Kubernetes 清单文件。以下是详细的工作流程。\n1. 初始化项目\n开发者通过 kubebuilder init 命令初始化一个标准化的 Operator 项目。这个命令会生成项目的目录结构，包括 api/、controllers/、config/ 等文件夹。\n1kubebuilder init --domain mydomain.com --repo github.com/myorg/my-operator 生成的文件结构： api/：存放自定义资源的定义文件。 controllers/：存放控制器的逻辑。 config/：存放 Kubernetes 的清单文件（如 CRD、RBAC 配置）。 开发者要做什么？\n执行 kubebuilder init，然后根据生成的结构填充业务逻辑。此时，项目已经具备标准的目录结构。\n2. 创建 API 和控制器\n开发者通过 kubebuilder create api 命令为自定义资源生成 API 结构和控制器骨架代码。\n1kubebuilder create api --group apps --version v1 --kind MySQL 生成的文件： api/v1/mysql_types.go：自定义资源 API 结构的定义。 controllers/mysql_controller.go：控制器的骨架代码。 开发者要做什么？\n在 api/v1/mysql_types.go 中定义自定义资源的 Spec 和 Status，在 controllers/mysql_controller.go 中编写业务逻辑（如如何创建、更新资源）。\n3. 生成代码和配置文件\n开发者完成业务逻辑编写后，运行以下命令生成辅助代码和 Kubernetes 清单文件。\n1make generate 2make manifests make generate：生成深度拷贝函数、API 注册等必要的辅助代码。 make manifests：生成 CRD、RBAC、Deployment 等 Kubernetes 资源的清单文件。 开发者要做什么？\n通过 make generate 生成自动化的辅助代码，无需手动编写深度拷贝和序列化逻辑。通过 make manifests 生成可部署的 CRD 和 Operator 清单文件。\n4. 编写控制器逻辑\n控制器是 Operator 的核心，负责监听和处理资源的状态变化。开发者需要在控制器的 Reconcile 函数中编写核心逻辑，例如当检测到 MySQL CR 创建时，如何为它创建一个相应的 Kubernetes Deployment。\n1func (r *MySQLReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) { 2 // 获取 MySQL 实例 3 var mysql appsv1alpha1.MySQL 4 if err := r.Get(ctx, req.NamespacedName, \u0026amp;mysql); err != nil { 5 return ctrl.Result{}, client.IgnoreNotFound(err) 6 } 7 8 // 检查是否需要创建或更新 Deployment 9 // 处理业务逻辑 10} 开发者要做什么？\n在 controllers/mysql_controller.go 文件中编写核心逻辑，如资源的创建、更新和状态同步。Kubebuilder 提供的骨架代码会自动调用 Reconcile 函数，开发者只需专注于业务逻辑。\n与 Kubernetes API 的集成 Kubebuilder 通过 controller-runtime 进行与 Kubernetes API 的交互，使用 ClientSet、Informer 和 Controller 协同工作，确保资源状态与期望一致。\n如何通过 ClientSet 进行资源管理\n在 controller-runtime 中，Client 是与 Kubernetes API Server 交互的主要方式。开发者可以通过 Client 进行资源的 CRUD 操作。\n获取资源：通过 r.Get 获取当前的资源实例。 创建资源：通过 r.Create 向 Kubernetes 集群中创建资源。 更新资源：通过 r.Update 更新资源状态。 删除资源：通过 r.Delete 删除不再需要的资源。 1var mysql appsv1alpha1.MySQL 2if err := r.Get(ctx, req.NamespacedName, \u0026amp;mysql); err != nil { 3 return ctrl.Result{}, client.IgnoreNotFound(err) 4} 开发者要做什么？\n在控制器中使用 Client 来管理 Kubernetes 资源，编写 Get、Create、Update 和 Delete 的业务逻辑。controller-runtime 封装了与 API Server 的交互，简化了操作。\nInformer、Controller 如何配合工作\nInformer 监听 Kubernetes 中资源的变化（如创建、更新、删除），并将这些事件通知给相应的控制器。控制器通过 Reconcile Loop 响应这些事件，执行资源状态的同步和调整。\nInformer 的工作流程:\n启动时，Informer 从 API Server 获取资源列表并缓存。 通过 Watch 机制，Informer 监听资源的变化并更新缓存。 当资源发生变化时，Informer 将事件通知给 Controller。 Controller 的工作流程：\nController 通过 Reconcile 函数响应来自 Informer 的事件。每当有新的事件发生，Reconcile 函数被调用，执行资源的状态更新或调整。 开发者要做什么？\nKubebuilder 自动生成了 Informer 和 Controller 的配合逻辑。开发者只需在 Reconcile 函数中编写具体的业务逻辑，无需手动处理事件监听或缓存管理。\n总结：开发者如何使用 Kubebuilder 开发 Operator 初始化项目：使用 kubebuilder init 创建标准项目结构。 创建 API 和控制器：通过 kubebuilder create api 生成 CRD 和控制器骨架代码。 编写 API 和控制器：定义 CRD 的 Spec 和 Status，编写控制器的 Reconcile 逻辑。 生成代码和清单文件：运行 make generate 和 make manifests，生成 Kubernetes 所需的清单文件和代码。 部署和测试 Operator：通过 make install 部署 CRD，使用 kubectl 验证 Operator 的工作效果。 ","link":"https://zhangsiming-blyq.github.io/post/kubernetes/operator/","section":"post","tags":["kubernetes","中文"],"title":"Kubernetes Operator 新手开发一文入门"},{"body":"学习内容 学习文档 字符串总结：这篇文档总结了字符串相关的常用操作和处理方法。特别是如何高效地使用 substr、split、reverse 等库函数处理字符串问题。它还包含了各种算法的讨论，例如 KMP 算法如何处理字符串匹配问题，具体可以参考 KMP 模式匹配的高效实现。\n双指针总结：双指针是一种常见且高效的算法思路，尤其在处理字符串和链表问题时特别有效。文档详细介绍了双指针在解决问题中的应用场景，如链表反转、寻找和计算字符串中的特定内容、左右边界的处理等。这个方法也经常用于简化两个嵌套的循环，使时间复杂度从 O(n^2) 降到 O(n)。\n收获总结 字符串是一种特殊的数组，有限字符序列： 字符串本质上就是一系列字符的集合，因此在很多算法问题中，可以将字符串当作数组来处理。字符串相关的操作，如查找、分割、拼接等，本质上与数组操作有相似之处。学会理解这一点，可以让我们在处理字符串问题时更加灵活和高效。\nsubstr、split、reverse 等库函数在 Golang 里的简单使用：\nsubstr 用于提取字符串的子串。 split 用于将字符串按照指定的分隔符进行切分。 reverse 用于将字符串或字符数组进行反转。掌握这些函数能够帮助我们处理很多字符串问题，尤其是在需要对字符串进行拆分、拼接或翻转操作时，简化代码的编写。 双指针在处理字符串问题时的应用： 双指针技术经常用于字符串处理问题，如字符串的反转、查找重复字符、判断回文串等。通过设置两个指针从字符串的不同端开始遍历，可以有效减少遍历次数并提升效率。双指针的典型应用包括：\n字符串反转 为例：我们可以定义两个指针，分别指向字符串的第一个和最后一个字符。在循环中，交换这两个位置的字符，然后同时移动两个指针，一个向右，一个向左，直到它们相遇或交错为止。这个方法能在 O(n) 的时间内完成反转。 字符串填充 问题。如果需要在字符串中插入填充内容，比如插入空格或其他字符，我们可以先根据填充后的最终长度对数组进行扩容，然后使用双指针从末尾向前操作。一个指针从原字符串的最后一个字符开始，另一个指针从扩容后的新位置开始，逐步进行字符的移动和填充，这样避免了额外的多次遍历。 反转链表，我们使用两个指针，prev 和 curr，分别指向当前节点和前一个节点。通过将当前节点的 next 指针指向前一个节点，实现局部反转。然后依次更新指针，直到遍历完整个链表，从而在一次遍历中完成链表的反转。 n 数之和（如 Two Sum 问题）同样可以通过双指针技术来解决。首先将数组排序，然后定义两个指针，分别指向数组的首尾。通过计算这两个指针所指元素的和，根据结果移动指针：如果和小于目标值，则移动左指针以增大和；如果和大于目标值，则移动右指针以减小和。这样可以在 O(n) 的时间内找到所有满足条件的组合。 反转系列问题：先局部后整体或先整体后局部的应用： 字符串或数组的反转问题通常可以分为两类：\n先局部反转再整体反转：这种方法适用于需要反转某个特定区间的内容，然后对整体内容进行反转的情况。 先整体反转再局部反转：用于整体反转之后需要再对局部的特定段进行细化处理。比如字符串旋转的操作可以通过这种方式来实现。 KMP 算法的学习与理解： KMP 算法是一种用于解决字符串匹配问题的高效算法。KMP 的核心思想在于避免重复匹配，通过构建 next 数组，预处理模式串来记录前缀与后缀的匹配情况，使得在遇到不匹配时可以通过 next 数组快速跳过不必要的字符，减少回溯次数。掌握 KMP 算法不仅能够提升匹配效率，而且对于理解复杂字符串问题具有重要意义。\n1// 计算next数组 2func computeNext(pattern string) []int { 3 m := len(pattern) 4 next := make([]int, m) 5 j := 0 6 7 next[0] = 0 // 修改为0 8 9 for i := 1; i \u0026lt; m; i++ { 10 // 如果不匹配，回退到上一个可能的匹配点 11 for j \u0026gt; 0 \u0026amp;\u0026amp; pattern[i] != pattern[j] { 12 j = next[j-1] 13 } 14 // 如果匹配，j递增 15 if pattern[i] == pattern[j] { 16 j++ 17 } 18 next[i] = j // 记录前缀长度，而不是j - 1 19 } 20 21 return next 22} 执行模式匹配:\n遍历主串中的每个字符。 如果主串字符与模式串当前指针指向的字符不匹配，使用next数组来跳过已经匹配过的部分，避免重复比较。 如果字符匹配，移动模式串的指针。 如果模式串的指针达到模式串的末尾，说明找到了一个匹配，将匹配的位置记录下来。 使用next数组中的值来更新模式串的指针，继续搜索。（optional） 1// kmpSearch 2func kmpSearch(text, pattern string) int { 3 n, m := len(text), len(pattern) 4 if m == 0 || n == 0 || m \u0026gt; n { 5 return -1 // 如果模式串为空或主串为空，或模式串比主串长，则没有匹配 6 } 7 8 next := computeNext(pattern) // 计算模式串的next数组 9 j := 0 // 模式串的指针 10 11 for i := 0; i \u0026lt; n; i++ { // 遍历主串 12 // 当出现不匹配时，使用next数组跳过已经匹配过的部分 13 for j \u0026gt; 0 \u0026amp;\u0026amp; text[i] != pattern[j] { 14 j = next[j] + 1 15 } 16 // 如果字符匹配，移动模式串的指针 17 if text[i] == pattern[j] { 18 j++ 19 } 20 // 如果模式串完全匹配 21 if j == m { 22 return i - m + 1 // 返回第一个匹配的位置 23 } 24 } 25 26 return -1 // 如果没有找到匹配，返回-1 27} 传递左右边界的重要性: 显示传递左右边界vs切片方式左闭右开, 是有区别的。在处理字符串问题时，显示传递左右边界可以更好地控制边界条件，避免出现越界问题。这种方式在处理字符串反转、局部替换等问题时尤为重要。 题目解析 题目1：151. 反转字符串中的单词 题目描述： 给定一个字符串，要求将字符串中的单词顺序颠倒，并去除多余的空格。单词之间用单个空格分隔，返回处理后的字符串。\n示例： 输入: \u0026quot;the sky is blue\u0026quot;\n输出: \u0026quot;blue is sky the\u0026quot;\n解法总结：\n使用双指针技术去除多余的空格，包括开头和结尾，以及中间相邻的多个空格。 对整个字符串进行一次反转。 对反转后的字符串中的每个单词进行单独的局部反转，最终得到正确的顺序。 代码实现:\n1func reverseWords(s string) string { 2\tss := []byte(s) 3 4\t// 1. 去除多余空格 5\tslow := 0 6\tfast := 0 7\tn := len(ss) 8 9\t// 去掉开头的空格 10\tfor fast \u0026lt; n \u0026amp;\u0026amp; ss[fast] == \u0026#39; \u0026#39; { 11\tfast++ 12\t} 13 14\tfor ; fast \u0026lt; n; fast++ { 15\tif fast \u0026gt; 0 \u0026amp;\u0026amp; ss[fast] == \u0026#39; \u0026#39; \u0026amp;\u0026amp; ss[fast-1] == \u0026#39; \u0026#39; { 16\tcontinue 17\t} 18\tss[slow] = ss[fast] 19\tslow++ 20\t} 21 22\t// 去掉结尾的空格 23\tif slow \u0026gt; 0 \u0026amp;\u0026amp; ss[slow-1] == \u0026#39; \u0026#39; { 24\tslow-- 25\t} 26 27\t// 截取有效部分 28\tss = ss[:slow] 29 30\t// 2. 整体反转 31\treverse(ss) 32 33\t// 3. 单词局部反转 34\tstart := 0 35\tfor i := 0; i \u0026lt;= len(ss); i++ { 36\t// 遇到空格或者到达字符串末尾时反转单词 37\tif i == len(ss) || ss[i] == \u0026#39; \u0026#39; { 38\treverse(ss[start:i]) 39\tstart = i + 1 40\t} 41\t} 42 43\treturn string(ss) 44} 45 46// 反转 []byte 数组 47func reverse(s []byte) { 48\tleft := 0 49\tright := len(s) - 1 50\tfor left \u0026lt; right { 51\ts[left], s[right] = s[right], s[left] 52\tleft++ 53\tright-- 54\t} 55} 时间复杂度：O(n)，因为每个字符最多被访问两次，整体和局部反转都是线性的。\n空间复杂度：O(1)，只需要使用常数级别的额外空间存储指针位置。\n题目2：55. 右旋字符串 题目描述： 给定一个字符串，要求将其右旋指定次数。旋转的操作是将字符串的后面部分移动到前面。\n示例： 输入: n = 2, str = \u0026quot;abcdefg\u0026quot;\n输出: \u0026quot;fgabcde\u0026quot;\n解法总结：\n先对整个字符串进行一次整体反转。 对旋转点前后分别进行局部反转，这样可以达到右旋的效果。 旋转次数 n 可能大于字符串的长度，因此需要对 n 进行取模运算来保证旋转次数合法。 代码实现:\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5) 6 7func reverse(s []byte, l, r int) { 8\tfor l \u0026lt; r { 9\ts[l], s[r] = s[r], s[l] 10\tl++ 11\tr-- 12\t} 13} 14 15func main() { 16\tvar n int 17\tfmt.Scanln(\u0026amp;n) 18 19\t// 读取输入字符串 20\tvar str string 21\tfmt.Scanln(\u0026amp;str) 22 23\t// 将字符串转换为字节数组 24\tstrByte := []byte(str) 25 26\t// 1. 整体反转 27\treverse(strByte, 0, len(strByte)-1) 28 29\t// 边界条件，防止 n 大于或等于字符串长度 30\tif n \u0026gt; len(strByte) { 31\tn = len(strByte) 32\t} 33 34\t// 2. 局部反转 35\treverse(strByte, 0, n-1) 36\treverse(strByte, n, len(strByte)-1) 37 38\t// 输出结果 39\tfmt.Println(string(strByte)) 40} 时间复杂度：O(n)，因为每次反转操作都需要遍历整个字符串。\n空间复杂度：O(1)，只使用了额外的几个变量来记录边界信息。\n题目3：459. [重复的子字符串](459. 重复的子字符串) 题目描述： 给定一个非空字符串，判断该字符串是否可以通过它的一个子串重复若干次构成。\n示例： 输入: \u0026quot;abab\u0026quot;\n输出: true\n解释: \u0026quot;abab\u0026quot; 是由 \u0026quot;ab\u0026quot; 重复两次构成的。\n解法总结： 通过 KMP 算法计算字符串的 next 数组。next[len(s)-1] 的值表示最长相同前后缀的长度。如果字符串的长度减去最长前后缀长度能够整除整个字符串长度，则该字符串是由一个子串重复多次构成的。\n代码实现:\n1func repeatedSubstringPattern(s string) bool { 2 if len(s) == 0 { 3 return false 4 } 5 6 // 数组长度减去最长相同前后缀的长度相当于是第一个周期的长度，也就是一个周期的长度，如果这个周期可以被整除，就说明整个数组就是这个周期的循环。 7 next := computeNext(s) 8 if next[len(s)-1] != 0 \u0026amp;\u0026amp; (len(s)%(len(s)-next[len(s)-1]) == 0) { 9 return true 10 } 11 12 return false 13} 14 15func computeNext(pattern string) []int { 16 m := len(pattern) 17 next := make([]int, m) 18 j := 0 19 20 next[0] = 0 // 修改为0 21 22 for i := 1; i \u0026lt; m; i++ { 23 // 如果不匹配，回退到上一个可能的匹配点 24 for j \u0026gt; 0 \u0026amp;\u0026amp; pattern[i] != pattern[j] { 25 j = next[j-1] 26 } 27 // 如果匹配，j递增 28 if pattern[i] == pattern[j] { 29 j++ 30 } 31 next[i] = j // 记录前缀长度，而不是j - 1 32 } 33 34 return next 35} 时间复杂度：O(n)，KMP 算法的时间复杂度为线性时间。\n空间复杂度：O(n)，需要额外的 next 数组来记录前缀信息。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day9/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第9天 151. 反转字符串中的单词, 55. 右旋字符串, 459. 重复的子字符串"},{"body":"1. Install kubeadm(kubelet kubectl) and docker https://docs.docker.com/engine/install/ubuntu/\nSet up docker apt repository:\n1# Add Docker\u0026#39;s official GPG key: 2sudo apt-get update 3sudo apt-get install ca-certificates curl 4sudo install -m 0755 -d /etc/apt/keyrings 5sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc 6sudo chmod a+r /etc/apt/keyrings/docker.asc 7 8# Add the repository to Apt sources: 9echo \\ 10 \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ 11 $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ 12 sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 13sudo apt-get update Install latest version of docker:\n1sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Download the public signing key for the Kubernetes package repositories:\n1# If the directory `/etc/apt/keyrings` does not exist, it should be created before the curl command, read the note below. 2# sudo mkdir -p -m 755 /etc/apt/keyrings 3curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg Add the Kubernetes apt repository:\n1# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list 2echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list Install kubeadm, kubelet, and kubectl:\n1sudo apt-get update 2sudo apt-get install -y kubelet kubeadm kubectl 3sudo apt-mark hold kubelet kubeadm kubectl 4 5# Enable kubelet service 6sudo systemctl enable --now kubelet Check kubelet status:\n1systemctl status kubelet ok | base py | with ubuntu@VM-24-14-ubuntu | at 23:35:20 2● kubelet.service - kubelet: The Kubernetes Node Agent 3 Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) 4 Drop-In: /etc/systemd/system/kubelet.service.d 5 └─10-kubeadm.conf 6 Active: active (running) since Wed 2024-09-04 23:35:20 CST; 4s ago 7 Docs: https://kubernetes.io/docs/home/ 8 Main PID: 51001 (kubelet) 9 Tasks: 7 (limit: 4613) 10 Memory: 71.2M 11 CGroup: /system.slice/kubelet.service 12 └─51001 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml 13 14Sep 04 23:35:20 VM-24-14-ubuntu systemd[1]: Started kubelet: The Kubernetes Node Agent. 15Sep 04 23:35:26 VM-24-14-ubuntu kubelet[51001]: E0904 23:35:26.374002 51001 server.go:206] \u0026#34;Failed to load kubelet config file\u0026#34; err=\u0026#34;failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file \\\u0026#34;/var/lib/ku\u0026gt; 16Sep 04 23:35:26 VM-24-14-ubuntu systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE 17Sep 04 23:35:26 VM-24-14-ubuntu systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;. Cause we don't have a kubernetes cluster, so the kubelet service will fail to start. It's normal.\n2. Deploy Master Node kubeadm.yaml\n1apiVersion: kubeadm.k8s.io/v1beta3 2kind: InitConfiguration 3nodeRegistration: 4 criSocket: \u0026#34;/var/run/dockershim.sock\u0026#34; 5 kubeletExtraArgs: 6 cgroup-driver: \u0026#34;systemd\u0026#34; 7 ignorePreflightErrors: 8 - IsPrivilegedUser 9 10--- 11apiVersion: kubeadm.k8s.io/v1beta3 12kind: ClusterConfiguration 13kubernetesVersion: \u0026#34;v1.22.4\u0026#34; 14apiServer: 15 extraArgs: 16 runtime-config: \u0026#34;api/all=true\u0026#34; 17controllerManager: 18 extraArgs: 19 \u0026#34;node-cidr-mask-size\u0026#34;: \u0026#34;24\u0026#34; # 24 is more common for Kubernetes networks, adjusting from 20 20imageRepository: \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers\u0026#34; 21clusterName: \u0026#34;example-cluster\u0026#34; 22networking: 23 # Specify the pod network CIDR. For Calico, the default is 192.168.0.0/16. 24 podSubnet: \u0026#34;192.168.0.0/16\u0026#34; 25 # You can also specify the service subnet if needed, but it\u0026#39;s optional. 26 serviceSubnet: \u0026#34;10.96.0.0/12\u0026#34; 27 dnsDomain: \u0026#34;cluster.local\u0026#34; 28 dnsIP: \u0026#34;10.96.0.10\u0026#34; 29--- 30apiVersion: kubelet.config.k8s.io/v1beta1 31kind: KubeletConfiguration 32# Adjust the kubelet cgroup driver to systemd for better compatibility with the control plane 33cgroupDriver: \u0026#34;systemd\u0026#34; 34--- 35apiVersion: kubeproxy.config.k8s.io/v1alpha1 36kind: KubeProxyConfiguration 37# kube-proxy specific options 38mode: \u0026#34;ipvs\u0026#34; # Optionally switch to IPVS for better performance in larger clusters Initialize the cluster:\n1sudo kubeadm init --config kubeadm.yaml Pre-flight checks: The process begins by running several pre-flight checks, such as verifying system compatibility and pulling required container images for the Kubernetes control plane. This ensures that the environment is ready to initialize a cluster.\nCertificate generation: Several certificates are generated for secure communication between the various Kubernetes components. For example:\nThe ca certificate is created to serve as the root certificate authority. The apiserver certificate is generated and signed, allowing the API server to serve secure traffic for both DNS names (like kubernetes.default) and specific IPs (10.96.0.1 and 10.0.24.14). Certificates for etcd are generated (etcd/server, etcd/peer) for secure communication within etcd, including peer communication and client access. Kubeconfig creation: The configuration files (kubeconfig) for various components are written into /etc/kubernetes. These files contain the necessary credentials and context for the components like admin, controller-manager, and scheduler to interact securely with the cluster.\nKubelet setup: The kubelet configuration is written into /var/lib/kubelet/config.yaml, and the kubelet service is started. The kubelet is responsible for managing the lifecycle of pods and communicating with the control plane.\nControl plane pod manifests: Static pod manifests are created for core control plane components (API server, controller manager, scheduler, and etcd) in /etc/kubernetes/manifests. These files define how these core components should run as static pods on the node.\nWaiting for control plane: Kubelet boots up the control plane components as static pods, and kubeadm waits for the API server, scheduler, and controller-manager to become healthy. This takes around 13.5 seconds in this case.\nCluster configuration: Kubeadm then uploads the configuration into the cluster, such as storing the kubeadm-config in a ConfigMap in the kube-system namespace. It also configures kubelet using another ConfigMap (kubelet-config-1.22) for the cluster-wide configuration of kubelets.\nMarking control plane node: The node (vm-24-14-ubuntu) is labeled and tainted as a control-plane node. This includes marking it with labels like node-role.kubernetes.io/control-plane and applying a taint (NoSchedule), ensuring that this node will not schedule regular workloads.\nBootstrap token setup: A bootstrap token is generated and configured to allow worker nodes to join the cluster. This token is used in the kubeadm join command that is provided later.\nRBAC setup for bootstrap: Kubernetes configures RBAC rules for the bootstrap token, enabling it to allow new nodes to authenticate and request certificate signing requests (CSRs) for joining the cluster. It also configures certificate rotation for all nodes.\nCore add-ons: Essential add-ons like CoreDNS (for service discovery within the cluster) and kube-proxy (for managing network rules) are applied to the cluster.\nFinal instructions: After the control plane is successfully initialized, the user is instructed to configure kubectl by copying the admin.conf file and setting up the pod network. Additionally, instructions are provided for adding worker nodes to the cluster using the kubeadm join command, which includes the control plane IP, bootstrap token, and certificate hash.\nIf all environment set correctly, you can see the following output:\n1W0905 02:46:58.306339 199271 strict.go:55] error unmarshaling configuration schema.GroupVersionKind{Group:\u0026#34;kubeadm.k8s.io\u0026#34;, Version:\u0026#34;v1beta3\u0026#34;, Kind:\u0026#34;ClusterConfiguration\u0026#34;}: error unmarshaling JSON: while decoding JSON: json: unknown field \u0026#34;dnsIP\u0026#34; 2[init] Using Kubernetes version: v1.22.4 3[preflight] Running pre-flight checks 4[preflight] Pulling images required for setting up a Kubernetes cluster 5[preflight] This might take a minute or two, depending on the speed of your internet connection 6[preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; 7[certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; 8[certs] Generating \u0026#34;ca\u0026#34; certificate and key 9[certs] Generating \u0026#34;apiserver\u0026#34; certificate and key 10[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local vm-24-14-ubuntu] and IPs [10.96.0.1 10.0.24.14] 11[certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key 12[certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key 13[certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key 14[certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key 15[certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key 16[certs] etcd/server serving cert is signed for DNS names [localhost vm-24-14-ubuntu] and IPs [10.0.24.14 127.0.0.1 ::1] 17[certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key 18[certs] etcd/peer serving cert is signed for DNS names [localhost vm-24-14-ubuntu] and IPs [10.0.24.14 127.0.0.1 ::1] 19[certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key 20[certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key 21[certs] Generating \u0026#34;sa\u0026#34; key and public key 22[kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; 23[kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file 24[kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file 25[kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file 26[kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file 27[kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; 28[kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; 29[kubelet-start] Starting the kubelet 30[control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; 31[control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; 32[control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; 33[control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; 34[etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; 35[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s 36[apiclient] All control plane components are healthy after 8.503051 seconds 37[upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace 38[kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.22\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster 39[upload-certs] Skipping phase. Please see --upload-certs 40[mark-control-plane] Marking the node vm-24-14-ubuntu as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] 41[mark-control-plane] Marking the node vm-24-14-ubuntu as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] 42[bootstrap-token] Using token: 2qah04.0eb5es8dlcv2ouvj 43[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles 44[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes 45[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials 46[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token 47[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster 48[bootstrap-token] Creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace 49[kubelet-finalize] Updating \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; to point to a rotatable kubelet client certificate and key 50[addons] Applied essential addon: CoreDNS 51[addons] Applied essential addon: kube-proxy 52 53Your Kubernetes control-plane has initialized successfully! 54 55To start using your cluster, you need to run the following as a regular user: 56 57 mkdir -p $HOME/.kube 58 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 59 sudo chown $(id -u):$(id -g) $HOME/.kube/config 60 61Alternatively, if you are the root user, you can run: 62 63 export KUBECONFIG=/etc/kubernetes/admin.conf 64 65You should now deploy a pod network to the cluster. 66Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: 67 https://kubernetes.io/docs/concepts/cluster-administration/addons/ 68 69Then you can join any number of worker nodes by running the following on each as root: 70 71kubeadm join 10.0.24.14:6443 --token 2qah04.0eb5es8dlcv2ouvj \\ 72\t--discovery-token-ca-cert-hash sha256:4f83a591d2e11e7a18fc7402b86e2618c74dd9267abd4894ba72dc4918b1c8db 3. Deploy Worker Node 1k get nodes INT | took 28m 32s | base py | with ubuntu@VM-24-14-ubuntu | at 01:40:53 2NAME STATUS ROLES AGE VERSION 3vm-24-14-ubuntu NotReady control-plane,master 61m v1.22.4 4 5kd nodes 6... 7 Ready False Thu, 05 Sep 2024 01:40:02 +0800 Thu, 05 Sep 2024 00:39:31 +0800 KubeletNotReady container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized 8... The worker node is not ready, because we haven't deployed the pod network yet. Using cilium as the pod network:\n1kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/tigera-operator.yaml 2kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.1/manifests/custom-resources.yaml After a while, the worker node will be ready:\n1kno 2NAME STATUS ROLES AGE VERSION 3vm-24-14-ubuntu Ready control-plane,master 2m11s v1.22.4 Calico's default network walkthrough Calico is running in VXLAN CrossSubnet mode, meaning VXLAN tunneling is only used when nodes are in different subnets. BGP is used for intra-subnet communication, where nodes are within the same subnet, and VXLAN is bypassed. Pod-to-Node traffic is routed through physical interfaces and often undergoes NAT when necessary. Scenario Traffic Path Route Interface Used Explanation Pod A to Pod B (Same Node) Pod A -\u0026gt; veth pair -\u0026gt; Node Network Namespace -\u0026gt; veth pair -\u0026gt; Pod B No routing needed veth interfaces (caliX) Pod-to-Pod traffic within the same node is handled entirely within the node's network namespace using veth pairs. It does not go through physical or virtual routing. Pod A to Pod B (Different Node, Same Subnet) Pod A -\u0026gt; Node A (BGP routing) -\u0026gt; Node B -\u0026gt; Pod B 192.168.x.0/24 via 10.0.0.3 dev eth0 eth0 (physical interface) Traffic between nodes in the same subnet uses BGP to exchange routes. The traffic is routed directly through the physical network (eth0) without any VXLAN encapsulation. Pod A to Pod B (Different Node, Different Subnet) Pod A -\u0026gt; VXLAN Encapsulation (Node A) -\u0026gt; Network -\u0026gt; VXLAN Decapsulation (Node B) -\u0026gt; Pod B 192.168.y.0/24 via 10.0.0.3 dev vxlan.calico vxlan.calico When nodes are in different subnets, Calico uses VXLAN to encapsulate the traffic, and the route will include vxlan.calico. The traffic is encapsulated at Node A and decapsulated at Node B. Pod A to Node A Pod A -\u0026gt; Node A (no encapsulation, handled locally) -\u0026gt; Node A No routing needed eth0 or caliX Traffic from Pod to the node it is running on is handled locally and does not traverse the physical network or any other routing. Pod A to Node B (Same Subnet) Pod A -\u0026gt; Node A (BGP routing) -\u0026gt; Node B 10.0.0.3 via dev eth0 eth0 (physical interface) Traffic from a Pod on Node A to Node B in the same subnet will use BGP routes and flow directly through the physical interface (eth0), without encapsulation. Pod A to External Network (e.g., 8.8.8.8) Pod A -\u0026gt; Node A (NAT conversion) -\u0026gt; Node A external interface -\u0026gt; Internet default via 10.0.24.1 dev eth0 src 10.0.24.14 eth0 (NAT-enabled) Traffic from Pod A to the internet is routed via Node A's external interface after undergoing NAT conversion (Pod IP is replaced with Node IP). The route uses the node’s default route to reach external destinations. 4. Reset kubeadm cluster and re-deploy via rke tool kubeadm reset: sudo kubeadm reset\n1[reset] Reading configuration from the cluster... 2[reset] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; 3[reset] WARNING: Changes made to this host by \u0026#39;kubeadm init\u0026#39; or \u0026#39;kubeadm join\u0026#39; will be reverted. 4[reset] Are you sure you want to proceed? [y/N]: y 5[preflight] Running pre-flight checks 6The \u0026#39;update-cluster-status\u0026#39; phase is deprecated and will be removed in a future release. Currently it performs no operation 7[reset] Stopping the kubelet service 8[reset] Unmounting mounted directories in \u0026#34;/var/lib/kubelet\u0026#34; 9[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki] 10[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf] 11[reset] Deleting contents of stateful directories: [/var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni] 12 13The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d 14 15The reset process does not reset or clean up iptables rules or IPVS tables. 16If you wish to reset iptables, you must do so manually by using the \u0026#34;iptables\u0026#34; command. 17 18If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar) 19to reset your system\u0026#39;s IPVS tables. 20 21The reset process does not clean your kubeconfig files and you must remove them manually. 22Please, check the contents of the $HOME/.kube/config file. Install kubernetes cluster via rke: https://rke.docs.rancher.com/installation\nRKE (Rancher Kubernetes Engine) is an open-source, lightweight Kubernetes installer developed by Rancher. It allows users to quickly and easily deploy and manage Kubernetes clusters in any environment, including bare-metal servers, cloud providers, and virtual machines.\n1wget https://github.com/rancher/rke/releases/download/v1.5.12/rke_linux-amd64 2mv rke_linux-amd64 rke 3chmod +x rke 4./rke --version 5 6rke version v1.5.12 Create a cluster configuration file cluster.yml using a interactive method:\n1./rke config --name cluster.yml 2 3[+] Cluster Level SSH Private Key Path [~/.ssh/id_rsa]: 4[+] Number of Hosts [1]: 5[+] SSH Address of host (1) [none]: 10.0.24.14 6[+] SSH Port of host (1) [22]: 7[+] SSH Private Key Path of host (10.0.24.14) [none]: ~/.ssh/id_rsa 8[+] SSH User of host (10.0.24.14) [ubuntu]: 9[+] Is host (10.0.24.14) a Control Plane host (y/n)? [y]: y 10[+] Is host (10.0.24.14) a Worker host (y/n)? [n]: y 11[+] Is host (10.0.24.14) an etcd host (y/n)? [n]: y 12[+] Override Hostname of host (10.0.24.14) [none]: 13[+] Internal IP of host (10.0.24.14) [none]: 14[+] Docker socket path on host (10.0.24.14) [/var/run/docker.sock]: 15[+] Network Plugin Type (flannel, calico, weave, canal, aci) [canal]: 16[+] Authentication Strategy [x509]: 17[+] Authorization Mode (rbac, none) [rbac]: 18[+] Kubernetes Docker image [rancher/hyperkube:v1.28.12-rancher1]: 19[+] Cluster domain [cluster.local]: 20[+] Service Cluster IP Range [10.43.0.0/16]: 21[+] Enable PodSecurityPolicy [n]: 22[+] Cluster Network CIDR [10.42.0.0/16]: 23[+] Cluster DNS Service IP [10.43.0.10]: 24[+] Add addon manifest URLs or YAML files [no]: Start and check cluster's status:\n1./rke up 2 3kno 4NAME STATUS ROLES AGE VERSION 510.0.24.14 Ready controlplane,etcd,worker 5m43s v1.28.12 6 7kp -A 8NAMESPACE NAME READY STATUS RESTARTS AGE 9ingress-nginx ingress-nginx-admission-create-vbzdm 0/1 Completed 0 5m4s 10ingress-nginx ingress-nginx-admission-patch-x7shj 0/1 Completed 1 5m4s 11ingress-nginx nginx-ingress-controller-pk94t 1/1 Running 0 5m4s 12kube-system calico-kube-controllers-5b564d9b7-5lbrn 1/1 Running 0 5m34s 13kube-system canal-lxk8w 2/2 Running 0 5m34s 14kube-system coredns-54cc789d79-mrbpb 1/1 Running 0 5m23s 15kube-system coredns-autoscaler-6ff6bf758-hrxmh 1/1 Running 0 5m23s 16kube-system metrics-server-657c74b5d8-jjxzd 1/1 Running 0 5m14s 17kube-system rke-coredns-addon-deploy-job-rmw2r 0/1 Completed 0 5m27s 18kube-system rke-ingress-controller-deploy-job-2z4d6 0/1 Completed 0 5m7s 19kube-system rke-metrics-addon-deploy-job-9bs7c 0/1 Completed 0 5m17s 20kube-system rke-network-plugin-deploy-job-2pzvs 0/1 Completed 0 5m37s Note that under vxlanMode: Never mode, this is the most significant change: cross-subnet traffic now uses direct routing without VXLAN encapsulation. The physical network interface (eth0) will handle this traffic, just like it does for traffic between nodes in the same subnet.\n1kubectl get ippools.crd.projectcalico.org default-ipv4-ippool -o yaml ok | base py | at local kube | with ubuntu@VM-24-14-ubuntu | at 23:36:25 2 3apiVersion: crd.projectcalico.org/v1 4kind: IPPool 5metadata: 6 annotations: 7 projectcalico.org/metadata: \u0026#39;{\u0026#34;uid\u0026#34;:\u0026#34;d5446eb8-75fb-4979-9a7f-c41818d7d80a\u0026#34;,\u0026#34;creationTimestamp\u0026#34;:\u0026#34;2024-09-05T15:32:38Z\u0026#34;}\u0026#39; 8 creationTimestamp: \u0026#34;2024-09-05T15:32:38Z\u0026#34; 9 generation: 1 10 name: default-ipv4-ippool 11 resourceVersion: \u0026#34;575\u0026#34; 12 uid: a9945c61-3c31-42a4-a8d6-b835da17b59b 13spec: 14 allowedUses: 15 - Workload 16 - Tunnel 17 blockSize: 26 18 cidr: 172.16.0.0/16 19 ipipMode: Never 20 natOutgoing: true 21 nodeSelector: all() 22 vxlanMode: Never ","link":"https://zhangsiming-blyq.github.io/post/kubernetes/kubeadm/","section":"post","tags":["kubernetes","English"],"title":"Deploy Kubernetes cluster via kubeadm"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/english/","section":"tags","tags":null,"title":"English"},{"body":"方法一：基于 Bootstrap Token 的加入方式 原理 Bootstrap Token 是一种临时的令牌，用于新节点在加入集群时进行身份验证。 新节点使用 kubeadm join 命令，提供 --token 和 --discovery-token-ca-cert-hash 参数，与控制平面 API 服务器建立安全连接。 控制平面验证 token 的有效性，并向新节点提供所需的证书和配置文件，使其能够加入集群。 具体步骤 1. 在控制平面节点上生成 Bootstrap Token 使用以下命令生成新的引导令牌：\n1kubeadm token create --print-join-command 输出示例：\n1kubeadm join 10.0.24.14:6443 --token abcdef.0123456789abcdef \\ 2 --discovery-token-ca-cert-hash sha256:430cb53669a7fde6e44338968458d47f3fcdbeda4d73bda7435df34ed20ad5be --print-join-command 参数会直接输出用于加入集群的完整命令，包括 token 和 discovery-token-ca-cert-hash。 2. 在新节点上执行加入命令 在新节点上，以 root 或具有相应权限的用户身份执行上述输出的命令：\n1kubeadm join 10.0.24.14:6443 --token abcdef.0123456789abcdef \\ 2 --discovery-token-ca-cert-hash sha256:430cb53669a7fde6e44338968458d47f3fcdbeda4d73bda7435df34ed20ad5be 3. 加入过程解析 身份验证：新节点使用 token 与控制平面 API 服务器进行身份验证。 证书验证：使用 --discovery-token-ca-cert-hash 提供的哈希值，确保连接的 API 服务器是可信的。 获取配置：验证通过后，新节点从控制平面获取 kubelet 所需的配置文件和证书。 节点注册：kubelet 启动并与控制平面通信，节点被注册到集群中。 注意事项 Token 有效期：默认情况下，token 有效期为 24 小时。可以使用 --ttl 参数调整有效期。 Token 管理：使用 kubeadm token list 查看现有 token，kubeadm token delete \u0026lt;token-id\u0026gt; 删除 token。 方法二：使用 静态 Kubeconfig 文件 的方式(这种是最常规的, 最正确的) 原理 预先在控制平面节点上为新节点生成 kubeconfig 文件，包含必要的证书和配置信息。 将 kubeconfig 文件安全地传输到新节点。 新节点的 kubelet 使用该 kubeconfig 文件与控制平面通信，完成加入过程。 具体步骤 1. 在控制平面节点上生成 kubeconfig 文件 使用 kubectl 或 kubeadm 生成适用于新节点的 kubeconfig 文件。例如：\n1kubeadm kubeconfig user --client-name=\u0026lt;node-name\u0026gt; --config=/path/to/cluster/config.yaml \u0026gt; /etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 或者手动创建 kubeconfig 文件：\n1kubectl config set-cluster kubernetes \\ 2 --certificate-authority=/etc/kubernetes/pki/ca.crt \\ 3 --embed-certs=true \\ 4 --server=https://10.0.24.14:6443 \\ 5 --kubeconfig=/etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 6 7kubectl config set-credentials system:node:\u0026lt;node-name\u0026gt; \\ 8 --client-certificate=/etc/kubernetes/pki/nodes/\u0026lt;node-name\u0026gt;.crt \\ 9 --client-key=/etc/kubernetes/pki/nodes/\u0026lt;node-name\u0026gt;.key \\ 10 --embed-certs=true \\ 11 --kubeconfig=/etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 12 13kubectl config set-context default \\ 14 --cluster=kubernetes \\ 15 --user=system:node:\u0026lt;node-name\u0026gt; \\ 16 --kubeconfig=/etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 17 18kubectl config use-context default --kubeconfig=/etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 2. 传输 kubeconfig 文件到新节点 将生成的 /etc/kubernetes/\u0026lt;node-name\u0026gt;-kubeconfig 文件通过安全方式复制到新节点的 /etc/kubernetes/kubelet.conf。\n3. 在新节点上启动 kubelet 确保 kubelet 已安装并配置为使用 /etc/kubernetes/kubelet.conf：\n1systemctl restart kubelet 4. 节点注册 kubelet 启动后，会使用提供的 kubeconfig 与控制平面通信，节点被注册到集群中。\n注意事项 证书管理：需要为每个节点生成唯一的客户端证书，通常由集群的 CA 签名。 安全性：必须安全地传输 kubeconfig 文件和证书，防止泄露。 方法三：基于 TLS Bootstrapping 的方式 原理 新节点的 kubelet 使用临时的引导身份（通常是 bootstrap.kubeconfig）向控制平面发起 CSR（证书签名请求）。 API 服务器根据配置（通常是自动批准 CSR）为新节点签发客户端证书。 kubelet 获取证书后，使用正式身份与控制平面通信，完成节点加入。 具体步骤 1. 在控制平面节点上创建引导 Token 生成一个用于 TLS 引导的 token：\n1kubeadm token create --usage \u0026#34;authentication,signing\u0026#34; --groups \u0026#34;system:bootstrappers:node-bootstrapper\u0026#34; 2. 为引导 Token 绑定适当的 RBAC 规则 确保引导 token 具有请求 CSR 的权限：\n1apiVersion: rbac.authorization.k8s.io/v1 2kind: ClusterRoleBinding 3metadata: 4 name: kubeadm:kubelet-bootstrap 5roleRef: 6 apiGroup: rbac.authorization.k8s.io 7 kind: ClusterRole 8 name: system:node-bootstrapper 9subjects: 10- apiGroup: rbac.authorization.k8s.io 11 kind: Group 12 name: system:bootstrappers 应用上述配置：\n1kubectl apply -f rbac.yaml 3. 在新节点上配置 kubelet 创建 bootstrap.kubeconfig 文件，内容包含引导 token：\n1kubeadm kubeconfig user --client-name=system:bootstrap:\u0026lt;token-id\u0026gt; --config=/path/to/cluster/config.yaml \u0026gt; /etc/kubernetes/bootstrap-kubelet.conf 或者手动创建：\n1kubectl config set-cluster kubernetes \\ 2 --certificate-authority=/etc/kubernetes/pki/ca.crt \\ 3 --embed-certs=true \\ 4 --server=https://10.0.24.14:6443 \\ 5 --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf 6 7kubectl config set-credentials kubelet-bootstrap \\ 8 --token=\u0026lt;bootstrap-token\u0026gt; \\ 9 --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf 10 11kubectl config set-context default \\ 12 --cluster=kubernetes \\ 13 --user=kubelet-bootstrap \\ 14 --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf 15 16kubectl config use-context default --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf 4. 启动 kubelet 配置 kubelet 使用 bootstrap-kubelet.conf：\n1systemctl restart kubelet 5. 自动批准 CSR 配置控制平面自动批准节点的 CSR：\n1kubectl create clusterrolebinding node-client-auto-approve \\ 2 --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \\ 3 --group=system:bootstrappers 4 5kubectl create clusterrolebinding node-server-auto-approve \\ 6 --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \\ 7 --group=system:nodes 6. 节点加入集群 kubelet 启动后，会自动发起 CSR，控制平面批准后，kubelet 获取正式证书并加入集群。\n注意事项 一句话总结: Kubernetes 提供了 TLS Bootstrapping 机制，通过使用 certificates.k8s.io API 和 bootstrap token 自动生成 Kubelet 所需的证书，简化了工作节点的证书管理流程，实现了节点与 kube-apiserver 的安全通信，并在生成正式证书后删除初始的 kubeconfig 文件，避免 bootstrap token 泄露。 安全性：自动批准 CSR 存在安全风险，需要确保引导 token 的安全性。 Token 有效期：引导 token 应设置合理的有效期，防止长期暴露。 总结 基于 Bootstrap Token 的方式：最常用，使用 kubeadm join 和 token，适合大多数场景。 使用静态 Kubeconfig 文件：预先生成配置文件，适合需要**手动管理证书**的场景。 基于 TLS Bootstrapping 的方式：使用 kubelet 的 CSR 机制，自动获取证书，适合自动化程度较高的环境。 在实际应用中，选择适合自己环境和需求的节点加入方式，能够提高集群的安全性和管理效率。\n","link":"https://zhangsiming-blyq.github.io/post/kubernetes/addnode/","section":"post","tags":["kubernetes","中文"],"title":"如何加节点到Kubernetes集群"},{"body":"学习内容 收获总结 字符串和字节数组的转换：在 Go 语言中，字符串是不可变的。对于需要修改字符串的操作，如反转、替换等，我们通常会先将字符串转换为 []byte 类型。这是因为 []byte 是可变的，可以通过索引操作直接修改其内容。在许多字符串操作中，将字符串转换为字节数组是一个有效的优化策略，尤其是在需要大量的字符替换和处理时，这种转换能够提高性能和代码的可读性。\nunicode.IsDigit 和 rune 的用法：在处理字符串中数字字符时，使用 unicode.IsDigit 函数来判断字符是否为数字非常便捷。unicode.IsDigit 适用于所有 Unicode 字符，能够处理多字节字符，如中文或特殊字符。而 rune 是 Go 语言中用于表示 Unicode 码点的类型，它可以存储多字节字符。因此，在处理包含不同字符集的字符串时，理解 rune 和 unicode.IsDigit 的作用，可以让我们编写的代码更具通用性和健壮性。\n从后向前替换字符的技巧：当处理需要对字符进行替换且替换后长度不同的情况时（例如将单个数字字符替换为多个字符），先扩展数组的长度，然后从后向前进行替换操作。这种方式能够有效避免字符替换过程中覆盖未处理的部分，保证替换操作的正确性。在替换操作时，提前计算所需的最终数组长度，并从末尾倒序进行填充，能够让操作更为高效，也避免了不必要的内存分配。\n题目解析 题目1：344. 反转字符串 题目描述：\n给定一个字符数组 s，请你将该字符数组原地反转。要求算法的空间复杂度为 O(1)，也就是说必须在原数组上进行修改，而不借助额外的空间。\n示例：\n输入：[\u0026quot;h\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;l\u0026quot;, \u0026quot;l\u0026quot;, \u0026quot;o\u0026quot;] 输出：[\u0026quot;o\u0026quot;, \u0026quot;l\u0026quot;, \u0026quot;l\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;h\u0026quot;] 解法说明：\n本题的最佳解决方法是使用双指针法。我们从数组的头尾两端分别设立两个指针，一个指向数组的第一个元素（left），另一个指向最后一个元素（right）。然后通过不断交换 left 和 right 所指向的元素，left 逐渐向右移动，right 逐渐向左移动，直到两个指针相遇或交错。这样便完成了原地反转操作，且没有额外的空间开销。\n这种方法非常简洁，且利用了数组的特性，使得反转操作只需遍历一遍数组即可完成，非常高效。\n代码实现:\n1func reverseString(s []byte) { 2\t// 对撞双指针反转法 3\tleft := 0 4\tright := len(s) - 1 5 6\tfor left \u0026lt; right { 7\ts[left], s[right] = s[right], s[left] 8\tleft++ 9\tright-- 10\t} 11} 复杂度说明：\n时间复杂度为 O(n)，其中 n 是数组的长度。每个元素被访问和交换一次，因此遍历的时间复杂度是线性的。\n空间复杂度为 O(1)，因为我们是在原数组上进行操作，未使用任何额外的空间。\n题目2：541. 反转字符串 II 题目描述：\n给定一个字符串 s 和一个整数 k，请将字符串按照以下规则进行反转：\n每隔 2k 个字符，反转前 k 个字符。 如果剩余字符少于 k 个，则将所有剩余字符反转。 如果剩余字符多于 k 个但少于 2k 个，则只反转前 k 个字符，其余字符保持不变。 示例：\n输入：s = \u0026quot;abcdefg\u0026quot;, k = 2 输出：\u0026quot;bacdfeg\u0026quot; 解法说明：\n该题的核心是按照每 2k 个字符为一组，反转其中的前 k 个字符。为了实现这一点，首先我们需要将字符串转换为可修改的 []byte，然后按照步长为 2k 进行遍历。在每个 2k 的区间内，判断当前剩余的字符数：\n如果该区间的字符数大于或等于 k，则对前 k 个字符进行反转。 如果剩余字符少于 k 个，则将所有剩余字符反转。 最终处理完所有区间后，将字节数组重新转换为字符串并返回。 这种解法灵活地处理了各种剩余字符的情况，同时通过局部反转，达到了题目的要求。反转操作依旧使用双指针法，因此时间复杂度不会过高。\n代码实现:\n1func reverseStr(s string, k int) string { 2\tss := []byte(s) 3 4\t// 同样使用对撞双指针，只不过逻辑上往前移动2k个，前k个反转；还要考虑怎么收尾处理问题 5\tfor i := 0; i \u0026lt; len(s); i += 2 * k { 6\t// 1. 如果还可以往前走k个，则反转前k个 7\tif i+k \u0026lt;= len(s)-1 { 8\treverseFunc(ss[i : i+k]) 9\t} else { 10\t// 2. 其他情况反转全部 11\treverseFunc(ss[i:]) 12\t} 13\t} 14\treturn string(ss) 15} 16 17func reverseFunc(s []byte) { 18\tstart := 0 19\tend := len(s) - 1 20 21\tfor start \u0026lt; end { 22\ts[start], s[end] = s[end], s[start] 23\tstart++ 24\tend-- 25\t} 26} 复杂度说明：\n时间复杂度为 O(n)，其中 n 是字符串的长度。由于我们每次以 2k 为单位进行遍历并在部分区间内进行反转，整体上所有字符的操作次数是线性的。\n空间复杂度为 O(n)，因为我们将字符串转换为了字节数组，这个转换过程需要额外的空间来存储新的字节数组。\n题目3：54. 替换数字（第八期模拟笔试） 题目描述：\n给定一个包含数字和字母的字符串，将其中的每个数字字符替换为字符串 \u0026quot;rebmun\u0026quot;。例如，字符串 \u0026quot;a1b2c3\u0026quot; 中的数字 1、2、3 分别替换为 \u0026quot;rebmun\u0026quot;，结果是 \u0026quot;arebmubrebmuncrebmun\u0026quot;。\n示例：\n输入：\u0026quot;a1b2c3\u0026quot; 输出：\u0026quot;arebmubrebmuncrebmun\u0026quot; 解法说明：\n这道题目要求我们对字符串中的每一个数字字符进行替换。我们可以先遍历整个字符串，统计其中数字字符的个数。然后，根据数字字符的个数，扩展数组的长度，为每个数字字符替换为 \u0026quot;rebmun\u0026quot; 预留足够的空间。\n接着，我们使用倒序遍历字符串的方式进行替换操作：从字符串的末尾开始，遇到数字字符时，将其替换为 \u0026quot;rebmun\u0026quot;。如果遇到非数字字符，则将其原样放回。这种从后往前替换的方式能够避免覆盖未处理的字符，保证替换过程的正确性。\n该解法的关键在于对数组的扩展和倒序替换。扩展数组是为了避免频繁的内存分配，而倒序替换则能够确保每个字符都能得到正确的处理，特别是在原地替换的场景中。\n代码实现:\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;unicode\u0026#34; 6) 7 8func replaceNumber(ss []byte) []byte { 9 // 1. 统计数字字符的个数 10 count := 0 11 for _, i := range ss { 12 if unicode.IsDigit(rune(i)) { 13 count++ 14 } 15 } 16 17 // 2. 扩充原切片大小 18 expandedSize := len(ss) + count * 5 // 每个数字替换成 \u0026#34;rebmun\u0026#34;，长度为 5 19 ss = append(ss, make([]byte, count*5)...) // 扩展原始切片大小 20 21 // 3. 从后往前替换 22 newindex := expandedSize - 1 23 oldindex := len(ss) - count*5 - 1 24 25 for oldindex \u0026lt; newindex { 26 if unicode.IsDigit(rune(ss[oldindex])) { 27 // 替换数字为 \u0026#34;rebuman\u0026#34; 28 ss[newindex-5] = \u0026#39;n\u0026#39; 29 ss[newindex-4] = \u0026#39;u\u0026#39; 30 ss[newindex-3] = \u0026#39;m\u0026#39; 31 ss[newindex-2] = \u0026#39;b\u0026#39; 32 ss[newindex-1] = \u0026#39;e\u0026#39; 33 ss[newindex] = \u0026#39;r\u0026#39; 34 newindex -= 6 35 } else { 36 ss[newindex] = ss[oldindex] 37 newindex-- 38 } 39 oldindex-- 40 } 41 42 return ss 43} 44 45func main() { 46 var str string 47 fmt.Scanln(\u0026amp;str) 48 49 strByte := []byte(str) 50 newString := replaceNumber(strByte) 51 52 fmt.Println(string(newString)) 53} 复杂度说明：\n时间复杂度为 O(n)，其中 n 是字符串的长度。我们需要遍历整个字符串两次：第一次用于统计数字字符的个数，第二次用于从后向前进行替换操作。因此时间复杂度是线性的。\n空间复杂度为 O(n)，因为我们需要扩展数组的大小来存储替换后的字符串，并且扩展后的数组长度与原字符串成正比。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day8/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第8天 344. 反转字符串, 541. 反转字符串 II, 54. 替换数字（第八期模拟笔试）"},{"body":"学习内容 学习文档： 哈希表理论基础 收获总结 哈希表的基本应用: 哈希表是一种通过键值对存储数据的数据结构，具有O(1)的平均查找时间复杂度。其优势在于能够快速判断一个元素是否存在于集合中。通过哈希函数将键映射到存储位置，我们可以在常数时间内完成插入、删除和查找操作。这在需要频繁查找或去重的算法问题中非常有用。\n哈希函数的理解与设计: 哈希函数是哈希表的核心，负责将输入（键）映射到特定的存储桶位置。一个好的哈希函数应当能够均匀地分布输入数据，避免哈希碰撞的发生。哈希碰撞是指不同的输入映射到了同一存储桶，这会导致性能下降。常用的哈希函数设计包括除留余数法、乘积法和平方取中法等。\n哈希碰撞及其处理策略: 哈希碰撞是无法完全避免的，因此需要设计合理的碰撞处理策略。常见的方法有链地址法（即使用链表处理同一存储桶中的多个元素）和开放地址法（即在发生碰撞时寻找下一个可用位置存储）。链地址法的优点是简单易实现，且能处理多种数据类型；而开放地址法则可以更好地利用空间，但在负载因子较高时性能下降明显。\n数组作为特殊的哈希表: 在某些特定的算法问题中，我们可以使用数组来模拟哈希表。特别是当键值范围固定且有限时（如小写字母a-z），数组能够提供与哈希表类似的功能，但由于数组的访问速度更快且无哈希碰撞，因此在特定场景下表现更佳。例如，在统计字符频次的题目中，使用固定大小的数组可以大幅提升性能。\nset数据结构的应用: 在某些问题中，需要频繁检查某个元素是否已经存在，或需要确保数据不重复。此时，集合（set）是一种理想的数据结构。Go语言中没有原生的set结构，但可以通过map[T]struct{}来模拟实现，其中T是元素类型。由于struct{}{}在Go语言中不占用额外空间，因此这种方法既节省内存，又能够实现集合所需的所有操作（如插入、删除、查找）。\nmap作为哈希表的高级应用: Go语言中的map不仅可以用来模拟集合，还能够用于更复杂的场景，如计数器、查找表等。在处理组合问题时，map常用于记录不同组合出现的次数，并通过查找实现快速匹配。例如在\u0026quot;四数相加II\u0026quot;问题中，使用两个map分别记录前两组数的和与后两组数的和，从而在O(1)时间内完成匹配，大大提升了算法效率。\n拓展理解：哈希表在实际问题中的应用: 在实际开发中，哈希表广泛应用于缓存（如LRU缓存）、数据库索引、计数器统计等场景。学习哈希表的基础知识并理解其实现细节，能够帮助我们更好地应对这些实际问题。通过这次学习，我们不仅掌握了哈希表的理论知识，还在实践中理解了如何通过优化哈希函数、处理哈希碰撞等方法，提升算法的效率和可靠性。\n题目解析 题目1：第454题.四数相加II 题目描述: 给定四个整数数组nums1、nums2、nums3和nums4，统计有多少个四元组(i, j, k, l)使得nums1[i] + nums2[j] + nums3[k] + nums4[l] = 0。为了简化问题，假设所有的四个数组长度相同，且长度不超过500。\n示例:\n1输入: nums1 = [1, 2], nums2 = [-2,-1], nums3 = [-1, 2], nums4 = [0, 2] 2输出: 2 3解释: 两个符合条件的四元组为: 4(0, 0, 0, 1) -\u0026gt; nums1[0] + nums2[0] + nums3[0] + nums4[1] = 1 + (-2) + (-1) + 2 = 0 5(1, 1, 0, 0) -\u0026gt; nums1[1] + nums2[1] + nums3[0] + nums4[0] = 2 + (-1) + (-1) + 0 = 0 解法总结: 该题目要求我们找到所有满足条件的四元组。直接暴力枚举四个数组中的元素组合会导致O(n^4)的时间复杂度，无法在合理时间内解决问题。因此，利用哈希表的快速查找特性可以将问题转化为两两分组求和。首先，我们遍历nums1和nums2，计算每对元素的和，并将其存储在哈希表中，键为和，值为出现的次数。然后遍历nums3和nums4，计算它们的和并检查哈希表中是否存在该和的相反数，如果存在则说明找到了符合条件的四元组，结果增加该和的出现次数。通过这种方法，时间复杂度降低到了O(n^2)。\n1func fourSumCount(nums1 []int, nums2 []int, nums3 []int, nums4 []int) int { 2\tresultMap := map[int]int{} 3\tresult := 0 4 5\t// 1. 第一部分for循环循环nums1，nums2，之和作为key，value为组合次数 6\tfor _, v := range nums1 { 7\tfor _, sV := range nums2 { 8\tresultMap[v+sV]++ 9\t} 10\t} 11 12\t// 2. 第二部分for循环直接比对resultMap是否有答案 13\tfor _, v := range nums3 { 14\tfor _, sV := range nums4 { 15\tif ssV, ok := resultMap[0-(v+sV)]; ok { 16\tresult += ssV 17\t} 18\t} 19\t} 20\treturn result 21} 时间复杂度: O(n^2)，其中n是每个数组的长度。我们首先计算两两数组组合的和，这需要O(n^2)的时间，然后在第二部分查找哈希表也需要O(n^2)的时间。\n空间复杂度: O(n^2)，用于存储前两组数的和的哈希表。这个哈希表最多存储n^2个不同的和，因此空间复杂度为O(n^2)。\n题目2：383. 赎金信 题目描述: 给定一个ransomNote字符串和一个magazine字符串，判断ransomNote能否由magazine里面的字符构成。如果可以，返回true；否则返回false。magazine中的每个字符只能在ransomNote中使用一次。\n示例:\n1输入: ransomNote = \u0026#34;a\u0026#34;, magazine = \u0026#34;b\u0026#34; 2输出: false 3 4输入: ransomNote = \u0026#34;aa\u0026#34;, magazine = \u0026#34;ab\u0026#34; 5输出: false 6 7输入: ransomNote = \u0026#34;aa\u0026#34;, magazine = \u0026#34;aab\u0026#34; 8输出: true 解法总结: 这道题的关键在于判断magazine中是否有足够的字符可以构成ransomNote。解法是遍历magazine字符串并统计每个字符的出现次数，然后遍历ransomNote字符串，检查每个字符是否可以在magazine中找到并且次数足够。如果某个字符的数量不够，则直接返回false。如果所有字符都满足条件，则返回true。通过使用一个固定大小的数组来记录字符的出现次数，可以在O(1)时间内完成查找和更新操作，这种方法有效地利用了数组作为特殊哈希表的特性。\n1func canConstruct(ransomNote string, magazine string) bool { 2\tmagazineMap := make([]int, 26) 3 4\t// 1. magazine只能用一次，magazine映射到map，+1 5\tfor _, v := range magazine { 6\tmagazineMap[v-rune(\u0026#39;a\u0026#39;)]++ 7\t} 8 9\t// 2. 循环ransomNote进行-1，如果减完了小于0，则返回false；最后返回true 10\tfor _, v := range ransomNote { 11\tmagazineMap[v-rune(\u0026#39;a\u0026#39;)]-- 12\tif magazineMap[v-rune(\u0026#39;a\u0026#39;)] \u0026lt; 0 { 13\treturn false 14\t} 15\t} 16\treturn true 17} 时间复杂度: O(n + m)，其中n和m分别是ransomNote和magazine的长度。我们需要分别遍历这两个字符串来统计和检查字符的出现次数。\n空间复杂度: O(1)，因为我们使用了一个固定大小的数组（长度为26）来存储字符的频次，不随输入大小变化。\n题目3：第15题. 三数之和 题目描述: 给定一个包含n个整数的数组nums，判断nums中是否存在三个元素a，b，c，使得a + b + c = 0。请找出所有和为0且不重复的三元组。\n示例:\n1输入: nums = [-1, 0, 1, 2, -1, -4] 2输出: [[-1, 0, 1], [-1, -1, 2]] 解法总结: 该题目要求找出所有和为0的三元组，且不能有重复的三元组。暴力解法会尝试每个三元组合，时间复杂度为O(n^3)，效率低下。为提高效率，可以首先对数组进行排序，然后利用双指针法进行查找：固定一个数作为基准，剩下的两个数通过左右双指针向中间搜索，确保找到的三元组和为零。排序能够帮助我们轻松跳过重复的元素，避免产生重复的结果。最终的时间复杂度为O(n^2)，远优于暴力解法。\n暴力解法: 注意，暴力解法虽然正确，但是会超时；第二种双指针写法更优\n1func threeSum(nums []int) [][]int { 2\tcheckMap := map[int]int{} 3\tresult := [][]int{} 4\tseenMap := map[string]struct{}{} 5 6\t// 1. 第一轮循环，从头扫描到尾，把对应的值放checkMap进去，key是0-v，value是index 7\tfor index, v := range nums { 8\tcheckMap[0-v] = index 9 10\t} 11 12\t// 2. 第二轮循环，双指针循环(不重复)，同时需要相加判断checkMap是否有，index是否重合 13\tfor i := 0; i \u0026lt; len(nums); i++ { 14\tfor j := i + 1; j \u0026lt; len(nums); j++ { 15\tif v, ok := checkMap[nums[i]+nums[j]]; ok { 16\tif v != i \u0026amp;\u0026amp; v != j { 17\ttmp := []int{nums[v], nums[i], nums[j]} 18\tsort.Ints(tmp) 19\tif _, ok := seenMap[fmt.Sprintf(\u0026#34;%d%d%d\u0026#34;, tmp[0], tmp[1], tmp[2])]; !ok { 20\tresult = append(result, tmp) 21\tseenMap[fmt.Sprintf(\u0026#34;%d%d%d\u0026#34;, tmp[0], tmp[1], tmp[2])] = struct{}{} 22\t} 23\t} 24\t} 25\t} 26\t} 27\treturn result 28} 对撞双指针解法\n1import \u0026#34;sort\u0026#34; 2 3func threeSum(nums []int) [][]int { 4\tresult := [][]int{} 5 6\t// 0. 排序数组(默认由小到大)，这个是后面对撞双指针的前提 7\tsort.Ints(nums) 8 9\t// 1. 由于要找三个数，在不重复的情况下，i应该\u0026lt;len-2 10\tfor i := 0; i \u0026lt; len(nums)-2; i++ { 11\t// 2. 并且排序后如果已经\u0026gt;0了都直接跳过 12\tif nums[i] \u0026gt; 0 { 13\tbreak 14\t} 15 16\t// 3. 去重a 17\tif i \u0026gt;= 1 \u0026amp;\u0026amp; nums[i] == nums[i-1] { 18\tcontinue 19\t} 20 21\t// 4. 对撞双指针找b和c 22\tleft := i + 1 23\tright := len(nums) - 1 24 25\tfor left \u0026lt; right { 26\tb, c := nums[left], nums[right] 27\tif nums[i]+b+c == 0 { 28\ttmp := []int{nums[i], b, c} 29\tresult = append(result, tmp) 30 31\t// 去重b 32\tfor left \u0026lt; right \u0026amp;\u0026amp; nums[left] == b { 33\tleft++ 34\t} 35\t// 去重c 36\tfor left \u0026lt; right \u0026amp;\u0026amp; nums[right] == c { 37\tright-- 38\t} 39\t} else if nums[i]+b+c \u0026lt; 0 { 40\tleft++ 41\t} else { 42\tright-- 43\t} 44\t} 45\t} 46\treturn result 47} 时间复杂度: O(n^2)。排序需要O(n log n)，双指针查找需要O(n^2)。\n空间复杂度: O(1)。除了排序所需的空间外，不需要额外的空间来存储数据。\n题目4：第18题. 四数之和 题目描述: 给定一个包含n个整数的数组nums和一个目标值target，判断nums中是否存在四个元素a，b，c，d，使得a + b + c + d的和与target相等。请找出所有符合条件且不重复的四元组。\n示例:\n1输入: nums = [1, 0, -1, 0, -2, 2], target = 0 2输出: [[-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 解法总结: 该题目是“三数之和”的扩展版，要求找到四个数的和等于目标值的所有不重复四元组。解法与“三数之和”类似，可以通过排序和双指针法来解决。首先对数组进行排序，然后固定两个数，剩下的两个数通过左右双指针进行搜索，确保找到的四元组和为目标值。为了避免重复解，固定的数以及双指针搜索过程中都需要进行去重处理。最终时间复杂度为O(n^3)，其中n是数组的长度。\n对撞双指针解法\n1import \u0026#34;sort\u0026#34; 2 3func fourSum(nums []int, target int) [][]int { 4\tresult := [][]int{} 5\t// 双指针解法 6\t// 0. 排序 7\tsort.Ints(nums) 8 9\t// 1. a+b+c+d 第一个循环a 10\tfor i := 0; i \u0026lt; len(nums)-3; i++ { 11\t// a去重 12\ta := nums[i] 13\tif i \u0026gt; 0 \u0026amp;\u0026amp; a == nums[i-1] { 14\tcontinue 15\t} 16 17\t// 2. 往后循环b 18\tfor j := i + 1; j \u0026lt; len(nums)-2; j++ { 19\tb := nums[j] 20\tif j \u0026gt; i+1 \u0026amp;\u0026amp; b == nums[j-1] { 21\tcontinue 22\t} 23 24\t// 3. 双指针c，d(left, right) 25\tleft := j + 1 26\tright := len(nums) - 1 27 28\tfor left \u0026lt; right { 29\tc := nums[left] 30\td := nums[right] 31\tsum := a + b + c + d 32\tif sum == target { 33\tresult = append(result, []int{a, b, c, d}) 34\t// 如果下一个数字和已经加入result的相同，就直接按照方向跳过 35\tfor left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { 36\tleft++ 37\t} 38\tfor left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1] { 39\tright-- 40\t} 41\t// 双指针同时移动 42\tleft++ 43\tright-- 44\t} else if sum \u0026lt; target { 45\tleft++ 46\t} else { 47\tright-- 48\t} 49\t} 50\t} 51\t} 52\treturn result 53} 时间复杂度: O(n^3)。排序需要O(n log n)，三层嵌套循环分别是O(n^3)。\n空间复杂度: O(1)。除了排序所需的空间外，不需要额外的空间来存储数据。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day7/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第7天 第454题.四数相加II, 383. 赎金信, 第15题. 三数之和，第18题. 四数之和"},{"body":"学习内容 学习文档：\n哈希表理论基础\n收获总结 Go中的rune类型: 在Go语言中，rune是一种别名类型，它表示一个Unicode码点，即一个整数，通常用于表示字符。Go的字符串是以字节数组的形式存储的，因此在处理多字节字符（如汉字、表情符号等）时，直接使用索引访问可能会得到不完整的字符。rune类型解决了这个问题，它能够正确处理和表示多字节的Unicode字符。这对于处理包含非ASCII字符的字符串时非常重要，尤其在国际化或多语言支持的应用中。通过这次学习，我们掌握了如何使用rune遍历字符串，确保对每个字符进行准确的操作。\n数组作为简单高效的哈希表: 在解决某些特定范围的哈希问题时，数组可以作为一种极为简单和高效的哈希表实现方式。特别是在字符计数和映射问题中，如果字符集固定（例如，字母a到z），我们可以使用一个固定长度的整数数组（如[26]int）来记录每个字符的出现次数。数组的索引直接对应字符的ASCII值减去偏移量，这使得字符查找和更新操作都可以在常数时间内完成。学习这部分内容让我们理解了如何在时间复杂度和空间复杂度上进行权衡，选择最合适的数据结构。\nGo中使用map实现set: 在Go语言中，集合(set)这一数据结构并没有直接实现，但我们可以通过map来间接实现。使用map[T]struct{}这种方式来模拟集合，其中T是元素类型，struct{}是一种不占用内存的零大小结构体。通过map键的唯一性，保证集合中的元素不重复，同时由于值类型为空结构体，节省了内存空间。我们还学习了如何利用delete函数从map中删除元素，进而动态地管理集合内容。这种技巧在需要高效去重和查找操作的场景中非常有用。\nGo中struct{}{}占用空间最小: 在Go语言中，struct{}{}是一个空的结构体类型，占用空间为零。在使用map实现集合时，我们可以将map的值类型定义为struct{}{}，这样可以在实现集合功能的同时，极大地节省内存空间。与其他语言的集合实现相比，这种方式更为轻量级，适合内存受限的场景。通过这种学习，我们进一步理解了Go语言在性能优化方面的设计思想，以及如何在日常编程中应用这些知识提高程序的效率。\n两数之和的双指针与哈希表解法: 对于两数之和问题，如果数组是有序的，我们可以利用双指针（也称为对撞指针）策略，从数组两端同时向中间移动，根据当前和与目标值的比较结果决定指针的移动方向，从而在O(n)时间复杂度内找到解。如果数组是无序的，则可以使用哈希表来记录已遍历过的数值及其索引。在遍历数组时，通过查找哈希表，快速判断是否存在与当前元素互补的数值，并在常数时间内找到目标组合。这些方法各有优劣，双指针法简单直观但只能用于有序数组，而哈希表法适用于无序数组且查找效率更高。通过学习这两种解法，我们理解了不同场景下算法选择的依据。\n扩展知识: 在这次学习中，还扩展了关于哈希表、双指针法在不同算法问题中的广泛应用。深入理解了哈希表在解决查找问题中的效率优势，以及双指针在排序数组中优化搜索过程的应用场景。这些知识不仅在理论层面增强了我们的算法理解，也为我们实际解决编程问题提供了多种思路和工具。\n题目解析 题目1：242. 有效的字母异位词 题目描述: 给定两个字符串 s 和 t，编写一个函数来判断 t 是否是 s 的字母异位词。字母异位词是指由相同的字母组成，但排列顺序不同的字符串。注意，字符串中的字母全部为小写字母。\n示例:\n1输入: s = \u0026#34;anagram\u0026#34;, t = \u0026#34;nagaram\u0026#34; 2输出: true 3 4输入: s = \u0026#34;rat\u0026#34;, t = \u0026#34;car\u0026#34; 5输出: false 解法总结: 该题目要求判断两个字符串是否为字母异位词，核心在于统计两个字符串中各字符的出现次数。如果两个字符串中各字符出现的次数完全相同，那么这两个字符串就是字母异位词。解法采用了固定长度的整数数组来记录字符的频次，其中每个字符的频次通过其ASCII码的偏移计算得出。在遍历第一个字符串时，对应字符的计数器加一；在遍历第二个字符串时，对应字符的计数器减一。最后，如果数组中的所有值都为零，则说明两个字符串是字母异位词。这个方法利用了数组的高效查找特性，使得整个过程的时间复杂度保持在O(n)。\n1func isAnagram(s string, t string) bool { 2\tvar tmp [26]int 3\t// 1. 映射s到数组+1(数组是简单高效的哈希表) 4\tfor _, c := range s { 5\ttmp[c-rune(\u0026#39;a\u0026#39;)]++ 6\t} 7\t// 2. 映射t到数组-1 8\tfor _, c := range t { 9\ttmp[c-rune(\u0026#39;a\u0026#39;)]-- 10\t} 11 12\t// 3. 检查是否有元素不为0 13\tfor _, c := range tmp { 14\tif c != 0 { 15\treturn false 16\t} 17\t} 18\treturn true 19} 时间复杂度: O(n)，其中n是字符串的长度。算法主要耗时在两次遍历字符串上，每次遍历的时间复杂度均为O(n)。\n空间复杂度: O(1)。由于使用了固定大小的数组来存储字符频次，无论字符串的长度如何变化，空间复杂度始终保持常数。\n题目2：349. 两个数组的交集 题目描述: 给定两个数组，编写一个函数来计算它们的交集。返回结果中的每个元素应是唯一的，结果可以是任意顺序。\n示例:\n1输入: nums1 = [1,2,2,1], nums2 = [2,2] 2输出: [2] 3 4输入: nums1 = [4,9,5], nums2 = [9,4,9,8,4] 5输出: [9,4] 解法总结: 该题目的目标是找出两个数组中的公共元素，并确保结果中的元素不重复。通过使用两个map结构，一个用于存储第一个数组中的元素，另一个用于存储交集结果。首先，将第一个数组中的所有元素存入一个map中，以去重。然后，遍历第二个数组，检查每个元素是否存在于第一个数组的map中，如果存在，则将该元素添加到结果集并从map中删除，以确保结果集中元素的唯一性。这种方法利用了哈希表的快速查找特性，能够高效地找出两个数组的交集。\n1func intersection(nums1 []int, nums2 []int) []int { 2\tnums1Map := map[int]struct{}{} 3\tresult := []int{} 4 5\t// 1. 将nums1编入map,并且去重 6\tfor _, v := range nums1 { 7\tif _, ok := nums1Map[v]; !ok { 8\tnums1Map[v] = struct{}{} 9\t} 10\t} 11 12\t// 2. 循环nums2，如果nums1有就放入结果集 13\tfor _, v := range nums2 { 14\tif _, ok := nums1Map[v]; ok { 15\tresult = append(result, v) 16 delete(nums1Map, v) 17\t} 18\t} 19 20\treturn result 21 22} 时间复杂度: O(n + m)，其中n和m分别是两个数组的长度。时间复杂度主要耗费在两个数组的遍历和哈希表的查找操作上。\n空间复杂度: O(min(n, m))。空间复杂度主要由存储第一个数组的map以及结果集map决定，取决于两个数组中较小的那个。\n题目3：202. 快乐数 题目描述: 编写一个算法来判断一个数n是否是快乐数。快乐数定义为：对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程，直到这个数变为1，或是无限循环但始终变不到1。如果可以变为1，则这个数是快乐数。\n示例:\n1输入: 19 2输出: true 3解释: 41² + 9² = 82 58² + 2² = 68 66² + 8² = 100 71² + 0² + 0² = 1 解法总结: 该题目通过不断迭代计算数字的平方和，判断其是否最终收敛到1。为了防止进入无限循环，使用一个map来记录每次迭代后的数字，如果某个数字已经出现过，则表示出现了循环，当前数字不可能是快乐数。具体实现上，首先定义一个辅助函数happyNum来计算平方和，然后在主函数中进行迭代判断，直到数字变为1（返回true）或者出现循环（返回false）。\n1func isHappy(n int) bool { 2\tresultMap := map[int]struct{}{} 3\t// 1. 无限循环计算快乐数 4\tfor { 5\t// 2. 计算快乐数 6\tn = happyNum(n) 7\t// 3. 如果快乐数等于1，直接返回true 8\tif n == 1 { 9\treturn true 10\t} 11 12\t// 4. 如果相同的快乐数出现了两次，返回false 13\tif _, ok := resultMap[n]; ok { 14\treturn false 15\t} 16\tresultMap[n] = struct{}{} 17\t} 18} 19 20func happyNum(n int) int { 21\tsum := 0 22\t// 只适合两位数的 23\tfor n \u0026gt; 0 { 24\tsum += (n % 10) * (n % 10) 25\tn = n / 10 26\t} 27 28\treturn sum 29} 时间复杂度: O(logn)。每次迭代中数字的位数减少，最终将收敛到1或出现循环。由于数字的位数与它的对数成正比，因此时间复杂度是O(logn)。\n空间复杂度: O(logn)。用于记录中间结果的哈希表最多存储数字的平方和的位数，空间复杂度为O(logn)。\n题目4：1. 两数之和 题目描述: 给定一个整数数组nums和一个目标值target，请你在该数组中找出和为目标值的那两个整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n1输入: nums = [2,7,11,15], target = 9 2输出: [0,1] 3解释: 因为 nums[0] + nums[1] = 2 + 7 = 9 解法总结: 对于这道题目，可以采用两种解法：双指针法和哈希表法。如果数组是有序的，可以使用双指针法，通过从两端向中间移动指针，根据当前和与目标值的关系来调整指针，直到找到两个数之和等于目标值的位置。这种方法的时间复杂度为O(n)。如果数组是无序的，可以使用哈希表法。遍历数组的同时，将每个元素及其对应的索引存入哈希表。在遍历过程中，检查哈希表中是否存在目标值与当前元素的差值，如果存在，说明找到了两个数之和等于目标值的位置。这种方法的时间复杂度为O(n)，但空间复杂度也为O(n)。 双指针版本\n1func twoSum(nums []int, target int) []int { 2\t// 1. 定义对撞双指针 3\t// 2. 暴力 4\tfor i := 0; i \u0026lt; len(nums); i++ { 5\tfor j := i + 1; j \u0026lt; len(nums); j++ { 6\tsum := nums[i] + nums[j] 7\tif sum == target { 8\treturn []int{i, j} 9\t} 10\t} 11\t} 12 13\treturn []int{} 14} 哈希表版本\n1func twoSum(nums []int, target int) []int { 2\tresultMap := map[int]int{} 3 4\tfor index, v := range nums { 5\t// 将另一半索引到map里面! 6\tif tarIndex, ok := resultMap[target-v]; ok { 7\treturn []int{index, tarIndex} 8\t} else { 9\tresultMap[v] = index 10\t} 11\t} 12\treturn []int{} 13} 时间复杂度: 双指针法的时间复杂度为O(n)，哈希表法的时间复杂度也为O(n)。\n空间复杂度: 双指针法的空间复杂度为O(1)，哈希表法的空间复杂度为O(n)。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day6/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第6天 242. 有效的字母异位词, 349. 两个数组的交集, 202. 快乐数, 1. 两数之和"},{"body":"收获总结 虚拟头节点的使用：虚拟头节点（Dummy Head）是处理链表问题的一大利器，尤其在增删节点操作中。通过引入虚拟头节点，可以避免处理链表头部时遇到的特殊情况，如删除第一个节点或在第一个节点前插入新节点。这不仅简化了代码，还减少了需要额外考虑的边界条件。例如，在处理 19. 删除链表的倒数第 N 个结点 时，虚拟头节点能够让双指针操作统一化，避免对头节点的单独处理。\n双指针技术：双指针技术是链表问题中的核心工具，特别是在处理链表长度不一致、链表中查找特定节点、或检测链表是否存在环时。双指针通常有两种应用方式：\n快慢指针：通过让一个指针每次走两步（快指针），另一个指针每次走一步（慢指针），这种方法能有效检测链表中的环（如 142. 环形链表 II）。当快慢指针相遇时，表明链表中存在环。随后，通过调整指针，可以精确找到环的起点。 同步指针：在链表相交问题中（如 面试题 02.07. 链表相交），同步指针的应用非常巧妙。让两个指针分别从两个链表的头开始遍历，当其中一个指针走到链表末尾时切换到另一个链表的头部，最终两个指针会在相交点相遇。这种方法的妙处在于，它平衡了链表长度的差异，使得指针在正确的位置相遇。 内置数据结构的应用：在处理链表问题时，合理使用内置的数据结构（如 map）可以大大提高解决问题的效率。例如，在检测链表是否有环时，使用哈希表可以记录已经访问过的节点，一旦再次访问到相同的节点，就可以立即判定链表中存在环，并找到环的入口。这种方法尽管增加了空间复杂度，但通常能够显著降低时间复杂度，是时间换空间的一种常见手段。\n画图和理清思路：链表操作往往涉及多步节点指针的调整，容易出现操作顺序错误导致链表断裂或死循环的问题。因此，在进行复杂链表操作之前，通过画图来理清每一步的指针变动，明确节点间的连接关系，是非常必要的。比如在解决 24. 两两交换链表中的节点 问题时，通过画图可以清晰地看到每次交换后的链表结构，有助于正确实现节点交换。\n操作的标准化和优化：在链表操作中，保持节点连接的正确性是最重要的。在实现代码时，应尽量避免无效或重复的操作。例如，在删除节点时，应确保先处理前驱节点的 next 指针，再释放目标节点的内存。同时，在实际开发中，掌握一些标准化的代码模板（如增删节点的通用代码框架）能够帮助减少错误，提高代码的复用性和开发效率。\n题目解析 题目1：24. 两两交换链表中的节点 题目描述: 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯地改变节点内部的值，而是需要实际进行节点交换。\n示例:\n1输入: head = [1,2,3,4] 2输出: [2,1,4,3] 解法总结: 这个问题要求我们在链表中两两交换相邻的节点。为了简化操作，可以引入一个虚拟头节点（dummy head），它指向原链表的头节点，这样可以统一对头节点和后续节点的处理。然后使用双指针遍历链表，分别指向当前待交换的两个节点及其前驱节点。关键在于每次交换时，需要提前保存第二个节点的下一个节点，以防止链表断裂。假设1-\u0026gt;2-\u0026gt;3-\u0026gt;4是待交换的两个节点，交换过程如下：\n将pre指向2 将2指向1 将1指向3 将pre指向1 将cur指向3 重复上述步骤，直到cur或cur.Next为空 代码实现:\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func swapPairs(head *ListNode) *ListNode { 9\t// 1. 加虚拟头，定义双指针 10\tdummy := \u0026amp;ListNode{} 11\tdummy.Next = head 12\tcur := head 13\tpre := dummy 14 15\t// 2. 退出循环条件 16\tfor cur != nil \u0026amp;\u0026amp; cur.Next != nil { 17\t// 3. pre --\u0026gt; 2 18\tpre.Next = cur.Next 19 20\t// 4. 2 --\u0026gt; 1, 这里因为cur.Next.Next被改动了，所以要提前把原来的数据保存起来 21\ttmp := cur.Next.Next 22\tcur.Next.Next = cur 23 24\t// 5. 1 --\u0026gt; 3 25\tcur.Next = tmp 26 27\t// 6. pre cur 指针移动 28\tpre = cur 29\tcur = tmp 30\t} 31 32\treturn dummy.Next 33} 时间复杂度: O(n)，因为我们需要遍历整个链表，n 是链表的长度。\n空间复杂度: O(1)，因为只使用了常量级别的额外空间。\n题目2：19. 删除链表的倒数第 N 个结点 题目描述: 给定一个链表，删除链表的倒数第 n 个节点，并返回链表的头节点。要求算法的时间复杂度为 O(n)。\n示例:\n1输入: head = [1,2,3,4,5], n = 2 2输出: [1,2,3,5] 解法总结: 这道题的核心是如何在只遍历一次链表的情况下删除倒数第 n 个节点。使用双指针技术是一个非常有效的办法。通过让其中一个指针 fast 先前进 n 步，然后再让 fast 和另一个指针 slow 同时前进。当 fast 到达链表末尾时，slow 指针正好位于需要删除节点的前一个节点。这个过程只需要一次遍历，因而满足 O(n) 的时间复杂度要求。\n具体步骤:\n初始化虚拟头节点和双指针:\n创建一个虚拟头节点 dummy，使 dummy.Next 指向 head，并初始化两个指针 fast 和 slow，均指向 dummy。 让 fast 先走 n 步:\n通过一个循环，让 fast 指针向前移动 n 步，这样 fast 和 slow 之间的距离正好是 n。 同时移动 fast 和 slow:\n当 fast 指向链表末尾（fast.Next 为 nil）时，slow 刚好指向需要删除节点的前一个节点。 删除节点:\n修改 slow.Next 指向 slow.Next.Next，从而删除目标节点。 返回结果:\n最终返回 dummy.Next 作为新的链表头。 这种方法确保了在遍历链表一次的情况下，准确找到并删除倒数第 n 个节点。\n代码实现:\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func removeNthFromEnd(head *ListNode, n int) *ListNode { 9\t// 1. 定义双指针，增加dummy头 10\tdummy := \u0026amp;ListNode{ 11\tNext: head, 12\t} 13\tfast := dummy 14\tslow := dummy 15 16\t// 2. 检查n的合法性 17\t// 3. fast先走 18\tfor i := 0; i \u0026lt; n; i++ { 19\tfast = fast.Next 20\t} 21 22\t// 4. fast和slow一起走，fast的下一个是nil的时候slow就到了该删除的值的前一位! 23\tfor fast.Next != nil { 24\tfast = fast.Next 25\tslow = slow.Next 26\t} 27 28\tslow.Next = slow.Next.Next 29\treturn dummy.Next 30} 时间复杂度: O(n)，因为需要遍历链表一次，n 是链表的长度。\n空间复杂度: O(1)，因为只使用了常量级别的额外空间。\n题目3：面试题 02.07. 链表相交 题目描述: 给定两个单链表，找出它们相交的起始节点。如果两个链表没有交点，返回 null。\n示例:\n1输入: intersectVal = 8, listA = [4,1,8,4,5], listB = [5,0,1,8,4,5] 2输出: Intersected at \u0026#39;8\u0026#39; 代码实现:\n解法1: 该解法通过分别计算两个链表的长度，然后让较长的链表先行走差值步数，最后再同步遍历两个链表，以找到它们的相交节点。\n具体步骤:\n计算两个链表的长度:\n分别遍历 headA 和 headB，计算出两个链表的长度 lengthA 和 lengthB。 对齐两个链表的起点:\n根据两个链表的长度差，调整较长链表的起始点，使两个链表在剩余长度上对齐。具体操作是让较长链表先走 |lengthA - lengthB| 步。 同步遍历两个链表:\n从新的起点开始，同时遍历两个链表，当 headA 与 headB 相等时，返回该节点，这个节点即为两个链表的相交节点。 这种方法依赖于计算链表的长度，并通过调整起点来找到相交节点。\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func getIntersectionNode(headA, headB *ListNode) *ListNode { 9\t// 无增删改查操作可以不用虚拟头 10\t// 1. 分别求出headA, headB的长度 11\ttmpHeadA := headA 12\tlengthA := 0 13\tfor tmpHeadA != nil { 14\ttmpHeadA = tmpHeadA.Next 15\tlengthA++ 16\t} 17 18\ttmpHeadB := headB 19\tlengthB := 0 20\tfor tmpHeadB != nil { 21\ttmpHeadB = tmpHeadB.Next 22\tlengthB++ 23\t} 24 25\t// 2. 长的先走差值 26\tif lengthA \u0026gt;= lengthB { 27\tfor i := 0; i \u0026lt; lengthA-lengthB; i++ { 28\theadA = headA.Next 29\t} 30\t} else { 31\tfor i := 0; i \u0026lt; lengthB-lengthA; i++ { 32\theadB = headB.Next 33\t} 34\t} 35 36\t// 3. 一起走，看值是否相同，有的话就返回起始交点 37\tfor headA != headB { 38\theadA = headA.Next 39\theadB = headB.Next 40\t} 41\treturn headA 42} 时间复杂度: O(m + n)，其中 m 和 n 分别是两个链表的长度。 空间复杂度: O(1)，只使用了常量级别的额外空间。 解法2: 该解法通过双指针技术，让两个指针分别从 headA 和 headB 开始遍历，当遍历到链表末尾时，指针切换到另一个链表的起点。这样两个指针将在相交节点处相遇，或者在没有相交时，最终指向 null。\n具体步骤:\n初始化双指针:\n初始化两个指针 i 和 j，分别指向 headA 和 headB。 遍历链表:\n在两个指针不相等的情况下，不断遍历链表。当一个指针到达链表末尾时，切换到另一个链表的头部继续遍历。最终两个指针要么在相交节点相遇，要么同时遍历完两个链表后都指向 null。 这种方法不需要预先计算链表长度，通过双指针的遍历自然对齐并找到相交节点，代码更加简洁直观。\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func getIntersectionNode(headA, headB *ListNode) *ListNode { 9\t// 无增删改查操作可以不用虚拟头 10 // 直接开始走两个链表，判断是否相等，走完了就换到另一个 11 // 定义双指针 12 i := headA 13 j := headB 14 15 for i != j { 16 // if i.Next != nil不行，因为这样少判断了最后一位 17 if i != nil { 18 i = i.Next 19 } else { 20 i = headB 21 } 22 23 if j != nil { 24 j = j.Next 25 } else { 26 j = headA 27 } 28 } 29 30 return i 31} 时间复杂度: O(m + n)，其中 m 和 n 分别是两个链表的长度。 空间复杂度: O(1)，只使用了常量级别的额外空间。 对比:\n解法1：需要计算链表长度，并做一次长度调整后再同步遍历。逻辑上清晰，但步骤较多。 解法2：使用双指针技术，不需要计算链表长度，通过自然对齐找到相交节点。代码更简洁高效，推荐使用。 题目4：142. 环形链表 II 题目描述: 给定一个链表，返回链表开始入环的第一个节点。如果链表无环，则返回 null。\n示例:\n1输入: head = [3,2,0,-4], pos = 1 2输出: 返回索引为 1 的链表节点 代码实现:\n解法1: 该解法使用哈希表记录访问过的节点，一旦再次访问到相同的节点，说明链表存在环，该节点即为环的起始节点。\n具体步骤:\n定义哈希表:\n使用一个哈希表 map 来存储已经访问过的节点。 遍历链表:\n遍历链表，对于每个节点，检查它是否已经存在于哈希表中。如果存在，则说明该节点是环的起始节点，返回该节点。 如果节点不在哈希表中，则将其加入哈希表，继续遍历。 返回结果:\n如果遍历完链表没有找到重复节点，说明链表无环，返回 null。 这种方法直接有效，但需要额外的空间来存储已经访问过的节点。\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func detectCycle(head *ListNode) *ListNode { 9\t// 1. 定义map 10 meet := map[*ListNode]bool{} 11 12 // 2. 直接Next找，每次存到meet这个map里面，如果碰到相同的就返回 13 for head != nil { 14 if _, ok := meet[head]; ok { 15 return head 16 } 17 meet[head] = true 18 head = head.Next 19 } 20 21 // 3. 不存在 22 return nil 23} 时间复杂度: O(n)，其中 n 是链表的长度。 空间复杂度: O(n)，用于存储已经访问过的节点。 解法2: 使用快慢指针技术，通过让快指针（一次走两步）和慢指针（一次走一步）同时遍历链表，若链表有环，则两个指针会在环内相遇。然后通过调整指针，找到环的起点。\n具体步骤:\n初始化快慢指针:\n初始化快指针 fast 和慢指针 slow，都指向 head。 检测环:\n快指针每次走两步，慢指针每次走一步。如果快指针与慢指针在某一点相遇，说明链表中存在环。 找到环的起点:\n当快慢指针相遇时，将其中一个指针移到链表头部，然后两个指针每次都走一步。最终它们会在环的起始节点相遇。 返回结果:\n如果快慢指针相遇，返回该节点；如果快指针遍历完链表没有相遇，返回 null。 这种方法不需要额外的存储空间，通过数学推导和遍历链表，能够在常数空间下检测环并找到环的起点。\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func detectCycle(head *ListNode) *ListNode { 9\t// 1. 定义快慢指针 10\tslow := head 11\tfast := head 12 13\t// 2. slow前进步幅为1，fast前进步幅为2；fast按照永远领先一个逼近slow；如果有环在绕了n圈之后一定会相交! 14\tfor fast != nil \u0026amp;\u0026amp; fast.Next != nil { 15\tfast = fast.Next.Next 16\tslow = slow.Next 17 18\tif fast == slow { 19\tfor slow != head { 20\thead = head.Next 21\tslow = slow.Next 22\t} 23\treturn head 24\t} 25\t} 26\treturn nil 27} 时间复杂度: O(n)，其中 n 是链表的长度。 空间复杂度: O(1)，只使用了常量级别的额外空间。 对比:\n解法1：哈希表法直接而有效，但空间复杂度较高。 解法2：快慢指针法通过数学推导实现，时间复杂度和空间复杂度都更优，在实际应用中更为推荐。 ","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day4/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第4天 24. 两两交换链表中的节点, 19. 删除链表的倒数第 N 个结点, 面试题 02.07. 链表相交, 142. 环形链表 II"},{"body":"学习内容 学习文档：\n链表讲解\n收获总结 链表概述 链表是一种基础的数据结构，由一系列节点组成，每个节点包含数据部分和指向下一个节点的指针（或引用）。链表的最后一个节点指向 null，表示链表的末尾。链表动态扩展性强，适合频繁插入和删除操作。\n链表的定义 链表有多种类型，最常见的是单链表和双链表。\n单链表：每个节点包含数据和指向下一个节点的指针 next。链表的头节点指向第一个节点，最后一个节点的 next 指向 null。\nGolang 单链表定义：\n1type ListNode struct { 2 Val int 3 Next *ListNode 4} 双链表：每个节点包含数据、指向下一个节点的指针 next 和指向前一个节点的指针 prev，允许双向遍历。\nGolang 双链表定义：\n1type ListNode struct { 2 Val int 3 Next *ListNode 4 Prev *ListNode 5} 注意事项 循环的时候参考数组，初始条件是i,j; 链表就是cur, cur.Next 链表的第一个节点比较特殊，处理的时候需要特殊处理；引入一个空的头节点dummyHead，可以简化很多操作(一视同仁) 链表的指针就是ListNode本身，因为任何一个ListNode都可以根据Next进行移动; 双指针解法的时候每一个指针都应该是一个ListNode 链表元素的内存分布 链表节点的内存分布不连续，节点在内存中的位置是随机分配的。这使得链表可以灵活地增长或缩小，但查找元素的时间复杂度较高，因为需要从头节点开始逐一遍历。\n节点的插入与删除 插入节点：\n头部插入：新节点的 next 指向当前头节点，并将链表头节点更新为新节点，时间复杂度为 O(1)。 尾部插入：单链表需要遍历链表找到最后一个节点，时间复杂度为 O(n)，双链表则直接访问尾节点，时间复杂度为 O(1)。 删除节点：\n删除头节点：将头节点更新为下一个节点，时间复杂度为 O(1)。 删除指定节点：需要遍历链表找到待删除节点，时间复杂度为 O(n)。 题目解析 题目1：203.移除链表元素 题目描述: 给定一个链表的头节点 head 和一个整数 val，请删除链表中所有满足 Node.val == val 的节点，并返回新的头节点。\n示例:\n1输入: head = [1,2,6,3,4,5,6], val = 6 2输出: [1,2,3,4,5] 解法总结: 使用虚拟头节点 dummyHead 方便处理可能需要删除头节点的情况。遍历链表时，如果当前节点的下一个节点的值等于 val，则跳过该节点（即将当前节点的 next 指向下下个节点），否则继续向下遍历。\n代码实现:\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func removeElements(head *ListNode, val int) *ListNode { 9\tdummyHead := \u0026amp;ListNode{} 10\tdummyHead.Next = head 11\t// 初始为第一个元素 12\tcur := dummyHead 13 14\tfor cur != nil \u0026amp;\u0026amp; cur.Next != nil { 15\t// 如果即将要看的下一位的值等于要删除的值 16\tif cur.Next.Val == val { 17\t// 移除就是跳过两位 18\tcur.Next = cur.Next.Next 19\t} else { 20\t// 跳过一位 21\tcur = cur.Next 22\t} 23\t} 24 25\t// 移除dummyHead 26\treturn dummyHead.Next 27} 时间复杂度: O(n)，其中 n 是链表中的节点数。每个节点最多访问一次。\n空间复杂度: O(1)，只使用了常量级别的额外空间。\n题目2：707.设计链表 题目描述: 设计链表实现增删查等基本操作。需要支持在链表头、尾以及指定索引位置进行元素的添加和删除，并能够获取指定索引位置的元素值。\n示例:\n1MyLinkedList linkedList = new MyLinkedList(); 2linkedList.addAtHead(1); 3linkedList.addAtTail(3); 4linkedList.addAtIndex(1, 2); // 链表变为 1-\u0026gt;2-\u0026gt;3 5linkedList.get(1); // 返回 2 6linkedList.deleteAtIndex(1); // 现在链表是 1-\u0026gt;3 7linkedList.get(1); // 返回 3 解法总结: 通过虚拟头节点 dummyHead 简化在头部进行插入和删除操作的实现。链表的设计包括获取指定索引位置的值、在头部或尾部添加元素、在指定索引位置插入或删除元素。注意要处理索引越界的情况。\n代码实现:\n1// type ListNode struct { 2// Val int 3// Next *ListNode 4// } 5 6type MyLinkedList struct { 7\tDummyHead *ListNode 8\tSize int 9} 10 11func Constructor() MyLinkedList { 12\tDummyHead := \u0026amp;ListNode{} 13 14\tMyLinkedList := MyLinkedList{ 15\tDummyHead: DummyHead, 16\tSize: 0, 17\t} 18\treturn MyLinkedList 19} 20 21func (this *MyLinkedList) Get(index int) int { 22\t// 先判断index是否有效 23\tif this == nil || index \u0026lt; 0 || index \u0026gt;= this.Size { 24\treturn -1 25\t} 26 27\tcurNode := this.DummyHead 28\tfor i := 0; i \u0026lt;= index; i++ { 29\tcurNode = curNode.Next 30\t} 31 32\treturn curNode.Val 33} 34 35func (this *MyLinkedList) AddAtHead(val int) { 36\tcurrHead := this.DummyHead.Next 37\tthis.DummyHead.Next = \u0026amp;ListNode{ 38\tVal: val, 39\tNext: currHead, 40\t} 41\tthis.Size++ 42} 43 44func (this *MyLinkedList) AddAtTail(val int) { 45\tcurrNode := this.DummyHead 46\tfor i := 0; i \u0026lt; this.Size; i++ { 47\tcurrNode = currNode.Next 48\t} 49\tcurrNode.Next = \u0026amp;ListNode{ 50\tVal: val, 51\tNext: nil, 52\t} 53\tthis.Size++ 54} 55 56func (this *MyLinkedList) AddAtIndex(index int, val int) { 57\t// 先判断index是否有效 58\tif this == nil || index \u0026lt; 0 || index \u0026gt; this.Size { 59\treturn 60\t} 61 62\tcurNode := this.DummyHead 63\tfor i := 0; i \u0026lt; index; i++ { 64\tcurNode = curNode.Next 65\t} 66\ttmp := curNode.Next 67\tfmt.Println(tmp) 68\tcurNode.Next = \u0026amp;ListNode{ 69\tVal: val, 70\tNext: tmp, 71\t} 72\tthis.Size++ 73} 74 75func (this *MyLinkedList) DeleteAtIndex(index int) { 76\t// 先判断index是否有效 77\tif this == nil || index \u0026lt; 0 || index \u0026gt;= this.Size { 78\treturn 79\t} 80 81\tcurNode := this.DummyHead 82\tfor i := 0; i \u0026lt; index; i++ { 83\tcurNode = curNode.Next 84\t} 85 86\ttmp := curNode.Next.Next 87\tfmt.Println(tmp) 88\tcurNode.Next = tmp 89\tthis.Size-- 90} 91 92/** 93 * Your MyLinkedList object will be instantiated and called as such: 94 * obj := Constructor(); 95 * param_1 := obj.Get(index); 96 * obj.AddAtHead(val); 97 * obj.AddAtTail(val); 98 * obj.AddAtIndex(index,val); 99 * obj.DeleteAtIndex(index); 100 */ 时间复杂度:\nGet 操作: O(n)，需要遍历链表直到指定索引位置。 AddAtHead 和 AddAtTail 操作: O(1)，在链表头或尾进行插入操作。 AddAtIndex 和 DeleteAtIndex 操作: O(n)，需要遍历链表找到指定位置。 空间复杂度: O(1)，只使用了常量级别的额外空间。\n题目3：206. 反转链表 题目描述: 给定一个单链表的头节点 head，将链表反转并返回反转后的链表。\n示例:\n1输入: head = [1,2,3,4,5] 2输出: [5,4,3,2,1] 解法总结: 使用双指针法反转链表。初始化 pre 指针为 nil，cur 指针为链表的头节点。在遍历过程中，通过临时变量 tmp 保存 cur.Next，将 cur.Next 指向 pre 实现链表反转，最后将 pre 移动到 cur 位置，cur 移动到 tmp 位置，直到遍历结束。 一定要注意双指针的时候要根据下面的图解梳理清楚，先是cur后移，然后pre后移，然后cur回指到pre！\n图解: 代码实现:\n1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func reverseList(head *ListNode) *ListNode { 9\tcur := head 10\tvar pre *ListNode 11 12\tfor cur != nil { 13\t// 下次循环cur后移一位 14\ttmp := cur.Next 15 16\t// cur回指到前一个 17\tcur.Next = pre 18 19\t// pre后移一位 20\tpre = cur 21\tcur = tmp 22\t} 23\treturn pre 24} 时间复杂度: O(n)，其中 n 是链表的长度。每个节点被访问一次。\n空间复杂度: O(1)，只使用了常量级别的额外空间。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day3/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第3天 203.移除链表元素, 707.设计链表, 206.反转链表"},{"body":"学习内容 学习文档：\n长度最小子数组讲解\n螺旋矩阵II讲解\n收获总结 滑动窗口： 在某些情况下，滑动窗口可以看作是一种特殊的双指针技术，其中两个指针 i 和 j（即左指针和右指针）从同一端开始，但移动的条件有所不同。滑动窗口的核心思想是通过右指针 j 不断向右扩展窗口，同时左指针 i 尽量向右收缩窗口，以找到满足特定条件的最小或最大窗口。\n举例来说，假设你想找到数组 arr 中两个元素之间的差值等于 diff 的一对元素索引，这可以视为滑动窗口问题，右指针 j 用来扩展窗口，左指针 i 用来收缩窗口，直到找到满足条件的子数组。初始化时可以根据具体问题选择 i, j 都从 0, 0 开始，也可以 0, 1 这种情况。\n题目解析 题目1：209. 长度最小的子数组 题目描述: 给定一个含有 n 个正整数的数组 nums 和一个正整数 target ，找出该数组中满足其和 ≥ target 的长度最小的连续子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。\n示例:\n1输入: target = 7, nums = [2,3,1,2,4,3] 2输出: 2 3解释: 子数组 [4,3] 是该条件下的长度最小的子数组。 解法总结: 该题可以通过滑动窗口技术来解决。我们使用两个指针 i 和 j，分别代表窗口的左右边界。首先，右指针 j 向右移动，扩展窗口，累加窗口内的元素和 sum。当 sum 大于或等于 target 时，开始收缩窗口（移动左指针 i），同时记录当前窗口的最小长度。通过这种方式，可以高效地找到满足条件的最短子数组长度。 这里需要注意的是，因为有可能第一个数就等于target，所以j也要从0开始，同时内侧判断条件也是for!\n代码实现:\n1func minSubArrayLen(target int, nums []int) int { 2\ti, j := 0, 0 3\tsum := 0 4\tmin := len(nums) + 1 5 6\tfor j \u0026lt; len(nums) { 7\tsum += nums[j] 8 9\tfor sum \u0026gt;= target { 10\t// 只在 sum 等于 target 时更新 min 11\tmin = minValue(j-i+1, min) 12\tsum -= nums[i] 13\ti++ 14\t} 15 16\tj++ 17\t} 18 19\t// 最后检查是否找到了符合条件的子数组 20\tif min == len(nums)+1 { 21\treturn 0 22\t} else { 23\treturn min 24\t} 25} 26 27func minValue(x, y int) int { 28\tif x \u0026lt; y { 29\treturn x 30\t} 31\treturn y 32} 时间复杂度: O(n)，因为每个元素在最坏情况下只会被访问两次，分别是被加入到窗口和从窗口中移除。\n空间复杂度: O(1)，仅使用了常数空间来存储索引、和以及最小长度。\n题目2：59. 螺旋矩阵 II 题目描述: 给定一个正整数 n，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵。\n示例:\n1输入: n = 3 2输出: 3[ 4 [1, 2, 3], 5 [8, 9, 4], 6 [7, 6, 5] 7] 解法总结: 这段代码的目的是生成一个 n x n 的螺旋矩阵，矩阵中的元素从 1 开始，按顺时针方向从外向内依次填充。具体来说，代码通过控制矩阵的四个边界（上、下、左、右）来逐步缩小范围。每次循环依次填充当前边界，从左到右、从上到下、从右到左、从下到上，直到所有元素填满为止。在填充过程中，每个方向的边界都会向内收缩一行或一列，确保后续填充在正确的范围内进行。最终，当 num 超过目标值（n * n）时，填充过程结束，返回生成的螺旋矩阵。 在实现过程中，有几个关键要点和注意事项。首先是边界的初始化和更新，确保在每次填充完一个方向后正确地调整 top、bottom、left 和 right 的值，以防止重复填充或越界。其次，在循环过程中需要时刻检查 num 的值，以确保填充过程不会超出范围。此外，需要特别处理小矩阵的特殊情况，如 n = 1 或 n = 0，以保证代码的通用性和正确性。最后，由于算法的时间和空间复杂度均为 O(n^2)，这意味着该算法可以有效地处理中小规模的矩阵生成任务，但在非常大的 n 时需要考虑性能问题。\n代码实现:\n1func generateMatrix(n int) [][]int { 2\t// Init 3\ttop, bottom, left, right := 0, n-1, 0, n-1 4\tnum := 1 5\ttarget := n * n 6 7\tmatrix := make([][]int, n) 8 9\tfor i := 0; i \u0026lt;= n-1; i++ { 10\tmatrix[i] = make([]int, n) 11\t} 12 13\tfor num \u0026lt;= target { 14\tfor i := left; i \u0026lt;= right; i++ { 15\tmatrix[top][i] = num 16\tnum++ 17\t} 18\ttop++ 19 20\tfor i := top; i \u0026lt;= bottom; i++ { 21\tmatrix[i][right] = num 22\tnum++ 23\t} 24\tright-- 25 26\tfor i := right; i \u0026gt;= left; i-- { 27\tmatrix[bottom][i] = num 28\tnum++ 29\t} 30\tbottom-- 31 32\tfor i := bottom; i \u0026gt;= top; i-- { 33\tmatrix[i][left] = num 34\tnum++ 35\t} 36\tleft++ 37\t} 38 39\treturn matrix 40} 时间复杂度: O(n^2)，因为需要填充整个 n x n 的矩阵。\n空间复杂度: O(n^2)，用于存储生成的螺旋矩阵。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day2/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第2天 209. 长度最小的子数组, 59. 螺旋矩阵 II"},{"body":"学习内容 学习文档：数组理论基础\n收获总结 快速排序：\n快速排序是一种基于分治法的排序算法。首先，选择一个基准元素，然后通过分区操作将数组划分为两部分，一部分元素小于基准值，另一部分元素大于基准值。递归地对这两部分进行排序，最终将数组排序完成。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func quickSort(arr []int, low, high int) { 6 if low \u0026lt; high { 7 pi := partition(arr, low, high) 8 quickSort(arr, low, pi-1) 9 quickSort(arr, pi+1, high) 10 } 11} 12 13func partition(arr []int, low, high int) int { 14 pivot := arr[high] 15 i := low - 1 16 for j := low; j \u0026lt; high; j++ { 17 if arr[j] \u0026lt; pivot { 18 i++ 19 arr[i], arr[j] = arr[j], arr[i] 20 } 21 } 22 arr[i+1], arr[high] = arr[high], arr[i+1] 23 return i + 1 24} 二分查找：\n二分查找是一种在有序数组中查找目标值的算法。它通过不断将数组分成两半，并与中间元素进行比较，从而快速缩小查找范围，最终确定目标值的位置。如果目标值不存在，则返回 -1。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func binarySearch(arr []int, low, high, target int) int { 6 if low \u0026lt;= high { 7 mid := low + (high-low)/2 8 if arr[mid] == target { 9 return mid 10 } else if arr[mid] \u0026gt; target { 11 return binarySearch(arr, low, mid-1, target) 12 } else { 13 return binarySearch(arr, mid+1, high, target) 14 } 15 } 16 return -1 17} 双指针，对撞指针，快慢指针常用初始化设计：\n双指针：可以从数组两端开始，常用于查找两个数的和问题。初始化 i 为数组起始位置，j 为数组结束位置，当 i \u0026lt; j 时迭代。另一种情况是从同一端开始，适用于查找具有特定差值的元素对。\n快慢指针：快慢指针常用于处理链表或数组中的问题，比如删除重复元素。i 和 j 初始化为数组或链表的起始位置，迭代条件是 j 指针不越界。\n1// 双指针 - 从两端开始 2func twoSum(arr []int, target int) []int { 3 i, j := 0, len(arr)-1 4 for i \u0026lt; j { 5 sum := arr[i] + arr[j] 6 if sum == target { 7 return []int{i, j} 8 } else if sum \u0026lt; target { 9 i++ 10 } else { 11 j-- 12 } 13 } 14 return nil 15} 16 17// 双指针 - 从同一端开始 18func findPairWithDiff(arr []int, diff int) []int { 19 i, j := 0, 1 20 for i \u0026lt; len(arr) \u0026amp;\u0026amp; j \u0026lt; len(arr) { 21 if i != j \u0026amp;\u0026amp; arr[j]-arr[i] == diff { 22 return []int{i, j} 23 } else if arr[j]-arr[i] \u0026lt; diff { 24 j++ 25 } else { 26 i++ 27 } 28 } 29 return nil 30} 31 32// 快慢指针 33func removeDuplicates(arr []int) int { 34 i, j := 0, 1 35 for j \u0026lt; len(arr) { 36 if arr[i] != arr[j] { 37 i++ 38 arr[i] = arr[j] 39 } 40 j++ 41 } 42 return i + 1 43} 题目解析 题目1：704. 二分查找 题目描述: 给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。\n示例:\n1输入: nums = [-1,0,3,5,9,12], target = 9 2输出: 4 解法总结: 使用二分查找方法。初始化左右指针 low 和 high，每次计算中间元素并与目标值进行比较，更新指针范围，直到找到目标值或确认不存在。\n代码实现:\n1func search(nums []int, target int) int { 2 low := 0 3 high := len(nums) - 1 4 for low \u0026lt;= high { 5 mid := low + (high-low)/2 6 if target == nums[mid] { 7 return mid 8 } else if target \u0026gt; nums[mid] { 9 low = mid + 1 10 } else { 11 high = mid - 1 12 } 13 } 14 return -1 15} 时间复杂度: O(log n)，因为每次查找都将搜索范围缩小一半。 空间复杂度: O(1)，只使用了常数空间。\n题目2：27. 移除元素 题目描述: 给你一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，返回剩余元素的数量。元素的顺序可能发生改变。\n示例:\n1输入: nums = [3,2,2,3], val = 3 2输出: 2, nums = [2,2] 解法总结: 使用双指针方法。i 和 j 都从数组的头部开始遍历，当 j 指向的元素不等于 val 时，将其赋值给 i 指向的位置，并递增 i，最终返回 i 的值作为新数组的长度。\n代码实现:\n1func removeElement(nums []int, val int) int { 2 i, j := 0, 0 3 count := 0 4 for j \u0026lt;= len(nums)-1 { 5 if nums[j] != val { 6 nums[i] = nums[j] 7 count++ 8 i++ 9 } 10 j++ 11 } 12 return count 13} 时间复杂度: O(n)，遍历数组一次即可完成操作。 空间复杂度: O(1)，只使用了常数空间。\n题目3：977.有序数组的平方 题目描述: 给你一个按非递减顺序排序的整数数组 nums，返回每个数字的平方组成的新数组，要求也按非递减顺序排序。\n示例:\n1输入: nums = [-4,-1,0,3,10] 2输出: [0,1,9,16,100] 解法总结: 可以采用两种方法。一种是先对所有元素平方后使用快速排序，另一种是使用双指针从数组两端向中间遍历，将较大的平方值放在结果数组的末尾。第二种方法要注意，因为给定的数组是非递减排序的，所以平方值最大的元素一定在数组的两端(中间小)，所以当我们遍历需要for循环从后往前遍历!\n代码实现:\n方法一：先平方后排序\n1func sortedSquares(nums []int) []int { 2 for i := 0; i \u0026lt; len(nums); i++ { 3 nums[i] = nums[i] * nums[i] 4 } 5 quickSort(nums, 0, len(nums)-1) 6 return nums 7} 8 9func quickSort(arr []int, low, high int) { 10 if low \u0026lt; high { 11 pivot := partition(arr, low, high) 12 quickSort(arr, low, pivot-1) 13 quickSort(arr, pivot+1, high) 14 } 15} 16 17func partition(arr []int, low, high int) int { 18 pivotValue := arr[high] 19 i := low - 1 20 for j := low; j \u0026lt; high; j++ { 21 if arr[j] \u0026lt; pivotValue { 22 i++ 23 arr[i], arr[j] = arr[j], arr[i] 24 } 25 } 26 arr[i+1], arr[high] = arr[high], arr[i+1] 27 return i + 1 28} 时间复杂度: O(n log n)，因为对所有元素进行平方操作后，再使用快速排序。 空间复杂度: O(log n)，递归调用栈的空间开销。\n方法二：双指针法\n1func sortedSquares(nums []int) []int { 2 i, j := 0, len(nums)-1 3 result := make([]int, len(nums)) 4 5 for h := len(nums) - 1; h \u0026gt;= 0; h-- { 6 if nums[i]*nums[i] \u0026gt; nums[j]*nums[j] { 7 result[h] = nums[i] * nums[i] 8 i++ 9 } else { 10 result[h] = nums[j] * nums[j] 11 j-- 12 } 13 } 14 return result 15} 时间复杂度: O(n)，因为只需要一次遍历即可完成操作。 空间复杂度: O(n)，因为使用了额外的数组来存储结果。\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day1/","section":"post","tags":["algorithm","中文"],"title":"【算法刷题系列】第1天 704. 二分查找，27. 移除元素, 977.有序数组的平方"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/etcd/","section":"tags","tags":null,"title":"etcd"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/etcd/","section":"categories","tags":null,"title":"Etcd"},{"body":"Preface: This tutorial focuses exclusively on the Etcd v3 protocol. Throughout Etcd's history, two protocols have been employed: v2 and v3. However, v2 is considered outdated and not recommended for production environments. Furthermore, Etcd v2 and v3 have distinct data storage structures. As a result, you cannot use Etcd v2 to read data from Etcd v3 or use an Etcd v2 snapshot to restore data in Etcd v3. This document is tailored for Etcd instances containing v3 data.\nHow to Deploy an Etcd Cluster? Etcd, a widely used distributed key-value store, plays a pivotal role in Kubernetes and is employed by numerous internet corporations worldwide. For both backend engineers and operations personnel, becoming proficient in handling errors and mastering this middleware is crucial. In this section, we will explore how to deploy an Etcd cluster using container tools such as \u0026quot;Docker\u0026quot; and \u0026quot;Docker Compose.\u0026quot; Let's get started!\nI have chosen an Ubuntu virtual machine as the working platform, specifically version 20.04.2 LTS. I assume you have already installed Docker and Docker Compose on your machine. If not, you can refer to the official Docker and Docker Compose documentation for installation instructions.\nhttps://docs.docker.com/desktop/install/linux-install/\n1. Etcd Directory Structure 1$ tree 2. 3├── docker-compose.yaml 4├── etcd 5├── etcd.conf 6└── etcd-ssl 7 ├── ca.crt 8 ├── ca.key 9 ├── ca.srl 10 ├── client.crt 11 ├── client.csr 12 ├── client.key 13 ├── server.cnf 14 ├── server.crt 15 ├── server.csr 16 └── server.key As you may know, we load our Etcd cluster using Docker Compose. Therefore, we need to create a docker-compose.yaml file to describe our Etcd cluster. Additionally, we require a customized etcd.conf file because the following section will involve configuring our Etcd cluster. The \u0026quot;etcd\u0026quot; and \u0026quot;etcd-ssl\u0026quot; directories are used to store Etcd data and certificates for client authentication.\n2. Complete the docker-compose.yaml File 1version: \u0026#34;3\u0026#34; 2services: 3 etcd: 4 image: quay.io/coreos/etcd:v3.5.9 5 network_mode: \u0026#34;host\u0026#34; 6 container_name: etcd_container 7 command: /usr/local/bin/etcd --config-file /etcd.conf 8 volumes: 9 - ./etcd:/var/lib/etcd 10 - ./etcd.conf:/etcd.conf:ro 11 - ./etcd-ssl:/etcd/etcd-ssl/:ro 12 restart: always 13 ulimits: 14 nofile: 15 soft: 1048576 16 hard: 1048576 We are using the official Etcd image from quay.io, specifically version v3.5.9. The network_mode: \u0026quot;host\u0026quot; configuration allows the Etcd cluster to communicate with each other, enabling the use of the host's IP address for connecting to the Etcd cluster. The restart: always setting ensures that the Etcd cluster remains operational, fully utilizing Etcd's high availability mechanisms. 3. Customize the etcd.conf File 1#---for basic running---# 2#[basic] 3name: k8s-etcd01 4data-dir: /var/lib/etcd 5enable-v2: true 6listen-client-urls: https://0.0.0.0:2379 7listen-peer-urls: http://0.0.0.0:2380 8 9#[cluster] 10initial-advertise-peer-urls: http://10.0.24.14:2380 11advertise-client-urls: https://10.0.24.14:2379 12# for multi-cluster: k8s-etcd01=http://10.0.24.14:2380,k8s-etcd02=http://10.146.80.49:2380,k8s-etcd03=http://10.146.80.52:2380 13initial-cluster: k8s-etcd01=http://10.0.24.14:2380 14initial-cluster-state: existing 15initial-cluster-token: etcd-cluster 16 17#---for cluster election---# 18initial-election-tick-advance: true 19heartbeat-interval: 500 20election-timeout: 3000 21 22#---for performance tuner---# 23quota-backend-bytes: 8589934592 24auto-compaction-mode: \u0026#39;periodic\u0026#39; 25auto-compaction-retention: \u0026#39;1\u0026#39; 26max-request-bytes: 10485760 27snapshot-count: 50000 28max-snapshots: 5 29max-wals: 5 30 31#---for client TLS encryption---# 32client-transport-security: 33 # Path to the client server TLS cert file. 34 cert-file: /etcd/etcd-ssl/server.crt 35 # Path to the client server TLS key file. 36 key-file: /etcd/etcd-ssl/server.key 37 # Enable client cert authentication. 38 # client-cert-auth: false 39 # Path to the client server TLS trusted CA cert file. 40 trusted-ca-file: /etcd/etcd-ssl/ca.crt 41 # Client TLS using generated certificates 42 # auto-tls: false The table below provides explanations for each parameter in the etcd.conf file:\nParameter Description data-dir Specifies the directory where Etcd stores its data, including the database and transaction logs. enable-v2 Enables or disables support for the Etcd version 2 API. Typically set to \u0026quot;false\u0026quot; to encourage the use of the more feature-rich and efficient v3 API. listen-client-urls Defines the URLs on which Etcd listens for client requests, allowing clients to connect to Etcd using these URLs. listen-peer-urls Specifies the URLs on which Etcd listens for communication with other Etcd nodes in the cluster. initial-advertise-peer-urls Specifies the initial URLs used by Etcd to advertise itself to other members when forming or joining a cluster. advertise-client-urls Similar to initial-advertise-peer-urls, this parameter specifies URLs that clients should use to connect to this Etcd member. initial-cluster Provides a list of initial Etcd cluster members and their associated initial-advertise-peer-urls. Used during cluster bootstrapping. initial-cluster-state Indicates whether the cluster should be initially set to \u0026quot;new\u0026quot; or \u0026quot;existing.\u0026quot; Set to \u0026quot;new\u0026quot; for a new cluster or \u0026quot;existing\u0026quot; when adding a new member to an existing cluster. initial-cluster-token An arbitrary string used to identify the cluster. All members in the same cluster should have the same token. initial-election-tick-advance Determines whether to fast-forward initial election ticks on boot for faster election. When true, local member fast-forwards election ticks to expedite \u0026quot;initial\u0026quot; leader election. heartbeat-interval The time interval between heartbeat signals sent by an Etcd leader to maintain leadership. Expressed in milliseconds. Recommended to be around the maximum of the average round-trip time (RTT) between members. election-timeout The maximum time interval an Etcd follower can go without receiving communication from the leader before starting an election. Expressed in milliseconds. Set based on the heartbeat interval and average round-trip time between members. Highly recommended you to see this link: https://etcd.io/docs/v3.5.9/tuning/#election-timeout quota-backend-bytes Specifies the maximum number of bytes that can be used to store data in Etcd. When exceeded, Etcd performs auto-compaction or raises an alarm. auto-compaction-mode Determines when auto-compaction should be performed: \u0026quot;periodic\u0026quot; (at regular intervals) or \u0026quot;revision\u0026quot; (based on the number of revisions). auto-compaction-retention Auto-compaction retention for MVCC key-value store in hours. 0 means disabling auto-compaction. max-request-bytes Sets the maximum size in bytes of an Etcd request. Requests exceeding this size will be rejected. snapshot-count The number of committed transactions to trigger a snapshot, used for data backup and recovery. max-snapshots The maximum number of snapshots to retain; older snapshots may be deleted when this limit is reached. max-wals The maximum number of write-ahead logs (WALs) to retain; older WALs may be deleted when this limit is reached. client-transport-security Security settings for client communication, including client certificate and key files. 4. Generate Certificates for Client Authentication Enabling client authentication for the Etcd cluster is essential for preventing unauthorized access. Therefore, we need to generate certificates for client authentication. For efficiency reasons, in private environments, peer authentication is not necessary, as it may impact performance.\nFollow these commands to generate client certificates using OpenSSL:\n1# Generate ca.crt 2$ openssl genrsa -out ca.key 4096 3$ openssl req -new -x509 -key ca.key -out ca.crt -subj \u0026#34;/CN=etcd-ca\u0026#34; 4 5# Generate server.crt 6$ vim server.cnf 7[req] 8distinguished_name = req_distinguished_name 9req_extensions = v3_req 10[req_distinguished_name] 11[ v3_req ] 12subjectAltName = @alt_names 13[alt_names] 14DNS.1 = xxx.xxx.xxx.xxx 15IP.1 = xxx.xxx.xxx.xxx 16IP.2 = xxx.xxx.xxx.xxx 17IP.3 = xxx.xxx.xxx.xxx 18$ openssl genrsa -out server.key 2048 19$ openssl req -new -key server.key -out server.csr -subj \u0026#34;/CN=etcd-server\u0026#34; -config server.cnf 20$ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365 -extensions v3_req -extfile server.cnf 21 22# Generate client.crt 23$ openssl genrsa -out client.key 2048 24$ openssl req -new -key client.key -out client.csr -subj \u0026#34;/CN=etcd-client\u0026#34; 25$ openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365 5. Optimize the Etcd Environment To achieve optimal performance as an Etcd machine, it's essential to optimize both the Etcd configuration and the host's hardware environment. Here are some recommended parameters to adjust before starting your Etcd cluster:\nFile Descriptors: Linux treats everything as a file, including regular files, directories, sockets, pipes, and more. A file descriptor is a unique integer identifier used by a process to access open files or other resources. It acts as a handle that the process uses to read, write, or manipulate the resource. There are three standard file descriptors: 0 (stdin), 1 (stdout), and 2 (stderr). You can view a process's current open file count with lsof -p \u0026lt;pid\u0026gt; | wc -l. How to view a process's open file limit? cat /proc/\u0026lt;pid\u0026gt;/limits | grep \u0026quot;Max open files\u0026quot; How to view user's current file descriptor limit(per user)? ulimit -n To change the file descriptor limit for your user, modify /etc/security/limits.conf or create a new file under /etc/security/limits.d/, with the following content: 1* soft nofile 1048576 2* hard nofile 1048576 You can also adjust file descriptor limits in systemd service files or Docker Compose YAML files, for example,add the following lines to the [Service] section: 1LimitNOFILE=new_limit 2LimitNPROC=new_limit Max Open Files Count: The \u0026quot;max open files count\u0026quot; or \u0026quot;file descriptor limit\u0026quot; is a system-wide limit on the number of file descriptors a process can have open simultaneously. This limit is in place to prevent a single process from consuming excessive system resources by opening too many files or network connections. It is especially important for server applications that need to handle many concurrent clients, as well as for system daemons and background processes. You can view the current file descriptor limit for a process using the ulimit -Hn command. To change the system-wide file descriptor limit, modify /etc/sysctl.conf, by adding the following line: 1fs.file-max = new_limit Remember that increasing file descriptor limits should be done carefully and with consideration for system resources. Setting limits too high can potentially lead to resource exhaustion, so it's essential to strike a balance between accommodating your application's needs and maintaining system stability. TCP Keepalive: Enable TCP keepalive to prevent idle connections from timing out. Modify net.ipv4.tcp_keepalive_time, net.ipv4.tcp_keepalive_probes, and net.ipv4.tcp_keepalive_intvl, for example: 1net.ipv4.tcp_keepalive_time = 60 2net.ipv4.tcp_keepalive_probes = 3 3net.ipv4.tcp_keepalive_intvl = 10 I/O Scheduler: Choose an I/O scheduler that best suits your workload. For example, for SSDs, you can use the deadline or mq-deadline scheduler, and for HDDs, the cfq scheduler. To check the current scheduler, use cat /sys/block/\u0026lt;device\u0026gt;/queue/scheduler, and to change it, use echo \u0026lt;scheduler\u0026gt; \u0026gt; /sys/block/\u0026lt;device\u0026gt;/queue/scheduler. CPU: Etcd performance benefits from having a fast CPU, so choose a machine with multiple cores and high clock speeds. Memory: Etcd's performance is directly affected by available memory. Ensure you have enough RAM to accommodate your etcd workload. Storage: Etcd performance can be I/O bound, so consider using faster storage solutions like SSDs to reduce latency and increase overall performance. Bandwidth: Ensure your network has sufficient bandwidth to handle the expected etcd traffic. Latency: Minimize network latency between etcd nodes to enhance communication speed. Please note that specific values for these parameters depend on your workload, hardware, and network environment. Perform load testing and benchmarking after making changes to assess their impact on Etcd's performance and stability. Additionally, ensure proper backups and conduct changes in a controlled test environment before applying them to production systems.\n6. Bootstrapping the Etcd Cluster 1$ docker-compose up 2$ docker-compose ps 3 Name Command State Ports 4--------------------------------------------------------------- 5etcd_container /usr/local/bin/etcd --conf ... Up 6# Check logs 7$ docker-compose logs -f 8... 9 10# Check Etcd cluster status 11ETCDCTL_API=3 etcdctl --endpoints=https://10.0.24.14:2379 --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key endpoint status -w table 12+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 13| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | 14+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 15| https://10.0.24.14:2379 | c8e267dee39d90f6 | 3.5.9 | 20 kB | true | false | 6 | 38 | 38 | | 16+-------------------------+ 17 18------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ Etcd Basic Commands Here are some basic Etcd commands you can use:\nDescription Command Set a key-value pair etcdctl put key value Get the value for a key etcdctl get key Delete a key etcdctl delete key Watch changes on a key etcdctl watch key Set a key with a TTL (time-to-live) etcdctl put key value --ttl seconds List all keys in a directory (with prefix) etcdctl get dir --prefix Delete all keys in a directory (with prefix) etcdctl delete dir --prefix Create a new user (for authentication) etcdctl user add username:password Create a role and grant permissions (RBAC) etcdctl role add rolename\netcdctl role grant-permission rolename Add a new Etcd cluster member etcdctl member add --peer-urls=https://new-node:2380 List Etcd cluster members etcdctl member list Remove an Etcd cluster member etcdctl member remove member-id Take a snapshot of the Etcd data etcdctl snapshot save snapshot.db Restore Etcd data from a snapshot etcdctl snapshot restore snapshot.db Display cluster health status etcdctl endpoint status -w table Etcd Common Issues And How To Fix Them 1. Disaster Recovery Taking a Snapshot of Etcd Data You can take a snapshot of the etcd data while it's running using the following command:\n1$ ETCDCTL_API=3 etcdctl --endpoints=https://10.0.24.14:2379 --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key snapshot save ./snapshot.db 2{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:31.982857+0800\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;snapshot/v3_snapshot.go:65\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;created temporary db file\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;./snapshot.db.part\u0026#34;} 3{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:31.992423+0800\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;client\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;v3@v3.5.9/maintenance.go:212\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;opened snapshot stream; downloading\u0026#34;} 4{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:31.992476+0800\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;snapshot/v3_snapshot.go:73\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;fetching snapshot\u0026#34;,\u0026#34;endpoint\u0026#34;:\u0026#34;https://10.0.24.14:2379\u0026#34;} 5{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:32.003568+0800\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;client\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;v3@v3.5.9/maintenance.go:220\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;completed snapshot read; closing\u0026#34;} 6{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:32.008874+0800\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;snapshot/v3_snapshot.go:88\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;fetched snapshot\u0026#34;,\u0026#34;endpoint\u0026#34;:\u0026#34;https://10.0.24.14:2379\u0026#34;,\u0026#34;size\u0026#34;:\u0026#34;20 kB\u0026#34;,\u0026#34;took\u0026#34;:\u0026#34;now\u0026#34;} 7{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-09-06T00:20:32.008952+0800\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;snapshot/v3_snapshot.go:97\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;saved\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;./snapshot.db\u0026#34;} 8Snapshot saved at ./snapshot.db The command will produce output indicating the snapshot has been saved.\nRestoring Etcd Data from a Snapshot To restore etcd data from a snapshot, ensure that the following parameters in your restore command match the ones in your etcd.conf file, such as initial-cluster-token:\n1$ ETCDCTL_API=3 etcdctl --endpoints=https://10.0.24.14:2379 --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key snapshot restore --skip-hash-check ./snapshot.db --initial-cluster=k8s-etcd01=http://10.0.24.14:2380 --initial-cluster-token=etcd-cluster --initial-advertise-peer-urls=http://10.0.24.14:2380 --name k8s-etcd01 --data-dir=./data 2Deprecated: Use `etcdutl snapshot restore` instead. 3 42023-09-06T00:25:53+08:00\tinfo\tsnapshot/v3_snapshot.go:248\trestoring snapshot\t{\u0026#34;path\u0026#34;: \u0026#34;./snapshot.db\u0026#34;, \u0026#34;wal-dir\u0026#34;: \u0026#34;data/member/wal\u0026#34;, \u0026#34;data-dir\u0026#34;: \u0026#34;./data\u0026#34;, \u0026#34;snap-dir\u0026#34;: \u0026#34;data/member/snap\u0026#34;, \u0026#34;stack\u0026#34;: \u0026#34;go.etcd.io/etcd/etcdutl/v3/snapshot.(*v3Manager).Restore\\n\\tgo.etcd.io/etcd/etcdutl/v3@v3.5.9/snapshot/v3_snapshot.go:254\\ngo.etcd.io/etcd/etcdutl/v3/etcdutl.SnapshotRestoreCommandFunc\\n\\tgo.etcd.io/etcd/etcdutl/v3@v3.5.9/etcdutl/snapshot_command.go:147\\ngo.etcd.io/etcd/etcdctl/v3/ctlv3/command.snapshotRestoreCommandFunc\\n\\tgo.etcd.io/etcd/etcdctl/v3/ctlv3/command/snapshot_command.go:129\\ngithub.com/spf13/cobra.(*Command).execute\\n\\tgithub.com/spf13/cobra@v1.1.3/command.go:856\\ngithub.com/spf13/cobra.(*Command).ExecuteC\\n\\tgithub.com/spf13/cobra@v1.1.3/command.go:960\\ngithub.com/spf13/cobra.(*Command).Execute\\n\\tgithub.com/spf13/cobra@v1.1.3/command.go:897\\ngo.etcd.io/etcd/etcdctl/v3/ctlv3.Start\\n\\tgo.etcd.io/etcd/etcdctl/v3/ctlv3/ctl.go:107\\ngo.etcd.io/etcd/etcdctl/v3/ctlv3.MustStart\\n\\tgo.etcd.io/etcd/etcdctl/v3/ctlv3/ctl.go:111\\nmain.main\\n\\tgo.etcd.io/etcd/etcdctl/v3/main.go:59\\nruntime.main\\n\\truntime/proc.go:250\u0026#34;} 52023-09-06T00:25:53+08:00\tinfo\tmembership/store.go:141\tTrimming membership information from the backend... 62023-09-06T00:25:53+08:00\tinfo\tmembership/cluster.go:421\tadded member\t{\u0026#34;cluster-id\u0026#34;: \u0026#34;7cadd2cbf250eee7\u0026#34;, \u0026#34;local-member-id\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;added-peer-id\u0026#34;: \u0026#34;c8e267dee39d90f6\u0026#34;, \u0026#34;added-peer-peer-urls\u0026#34;: [\u0026#34;http://10.0.24.14:2380\u0026#34;]} 72023-09-06T00:25:53+08:00\tinfo\tsnapshot/v3_snapshot.go:269\trestored snapshot\t{\u0026#34;path\u0026#34;: \u0026#34;./snapshot.db\u0026#34;, \u0026#34;wal-dir\u0026#34;: \u0026#34;data/member/wal\u0026#34;, \u0026#34;data-dir\u0026#34;: \u0026#34;./data\u0026#34;, \u0026#34;snap-dir\u0026#34;: \u0026#34;data/member/snap\u0026#34;} Alternatively, you can restore specific keys or directories from a snapshot:\n1$ etcdctl snapshot restore \u0026lt;snapshot-file\u0026gt; --data-dir \u0026lt;data-directory\u0026gt; --restore-from-key \u0026lt;key\u0026gt; 2# or 3$ etcdctl snapshot restore /path/to/snapshot.db --data-dir /var/lib/etcd --restore-from-key /mydir/mykey After adjusting etcd's data directory in the docker-compose.yaml file, start the restored etcd cluster:\n1$ docker-compose up -d 2$ ETCDCTL_API=3 etcdctl --endpoints=https://10.0.24.14:2379 --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key endpoint status -w table 3+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 4| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | 5+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 6| https://10.0.24.14:2379 | c8e267dee39d90f6 | 3.5.9 | 20 kB | true | false | 2 | 4 | 4 | | 7+-------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 2. Issue: \u0026quot;etcdserver: mvcc: database space exceeded\u0026quot; Related links: https://etcd.io/blog/2023/how_to_debug_large_db_size_issue/\nIf you encounter the \u0026quot;etcdserver: mvcc: database space exceeded\u0026quot; issue, you can follow these steps to resolve it:\n1$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 alarm list/disarm 2$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 endpoint status -w table 3$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 compact 4$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 defrag 5 6# Check the etcd revision to identify keys with the most revisions 7$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 endpoint status -w json 8$ ETCDCTL_API=3 etcdctl --endpoints localhost:2379 get \u0026#34;\u0026#34; --prefix --keys-only | grep -v ^$ | awk -F \u0026#39;/\u0026#39; \u0026#39;{ h[$3]++ } END {for (k in h) print h[k], k}\u0026#39; | sort -nr 9 10# Modify the docker-compose.yaml file and restart the etcd cluster 11$ vim docker-compose.yaml In the docker-compose.yaml file, ensure that you specify \u0026quot;--quota-backend-bytes 8589934592\u0026quot; and any other settings for your etcd cluster. Then restart the cluster:\n1$ docker-compose up -d Let's delve into the etcd's revision mechanism:\nIn etcd, the revision represents a continually increasing integer value assigned to each modification made to the etcd key-value store. It serves as a global version number that tracks the historical changes within the etcd cluster. The revision number is incremented each time there is a modification, such as creating, updating, or deleting a key-value pair in etcd. Each modification operation increments the revision by one.\nThe etcd revision number carries several crucial implications:\nConsistency and Order: The revision number ensures the consistency and order of operations within the etcd cluster. It guarantees that operations applied at a higher revision number have occurred after operations at lower revision numbers. Read Operations: When conducting a read operation on etcd, you can specify a revision number to retrieve the state of the key-value store at a specific point in time. This enables you to access a consistent snapshot of the data at a particular revision. Change Detection: By monitoring the revision number, you can identify changes or updates to the etcd key-value store. You can periodically fetch the latest revision number and compare it to a previously recorded value to ascertain if any modifications have taken place. Database Compaction: Etcd offers a compaction mechanism that allows you to remove older or redundant revisions from the database. By compacting the database, you can reclaim storage space and enhance performance. The revision number plays a pivotal role in the compaction process. 3. Adding a New Etcd Cluster Member To add a new etcd cluster member, follow these steps:\nConfigure the new node's etcd.conf file with the following essential parameters:\nname: A unique name for the new node. data-dir: The directory where etcd will store its data. initial-advertise-peer-urls: The URL at which the new node advertises itself to other members. listen-peer-urls: The URLs on which the new node listens for communication with other etcd nodes. listen-client-urls: The URLs on which the new node listens for client requests. advertise-client-urls: The URLs that clients should use to connect to the new node. initial-cluster: A list of the initial etcd cluster members and their associated initial-advertise-peer-urls, which should match those in other nodes' etcd.conf. initial-cluster-state: Set it to \u0026quot;existing\u0026quot; if you're adding a new member to an existing cluster. Use etcdctl to add the new member:\n1$ ETCDCTL_API=3 etcdctl --endpoints=https://ETCDCLUSTER --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key member add ETCDNAME --peer-urls=https://NEW-NODE:2380 Start the new node and check its status: 1$ docker-compose up -d 2$ ETCDCTL_API=3 etcdctl --endpoints=https://ETCDCLUSTER --cacert=./etcd-ssl/ca.crt --cert=./etcd-ssl/client.crt --key=./etcd-ssl/client.key endpoint status -w table Interacting With Kubernetes's Etcd Installing etcdhelper To interact with Kubernetes's etcd, you can install etcdhelper using the following steps:\n1# Clone the etcdhelper repository 2$ git clone https://github.com/openshift/origin.git 3 4# Set up an alias for etcdhelper 5$ vim ~/.zshrc 6alias ectl=\u0026#39;ETCDCTL_API=3 etcdhelper -endpoint=172.31.27.61:2379 -cacert /home/k8s/code/etcd-prod-27-61/cert/ca.pem -cert /home/k8s/code/etcd-prod-27-61/cert/etcd.pem -key /home/k8s/code/etcd-prod-27-61/cert/etcd.key\u0026#39; Accessing Kubernetes's Etcd You can use etcdhelper to access Kubernetes's etcd and retrieve data:\n1$ ectl get /registry/secrets/test/harbor-kubernetes \u0026amp;\u0026amp; echo Please note that Kubernetes stores data in the following order: /registry/{resource_name}/{namespace}/{resource_instance}. Secrets' content is base64 encoded before being stored in etcd, so you need to decode it to retrieve the actual content.\nAdditional Information To explore etcd's API paths, you can use the provided script:\n1#!/bin/bash 2# Get Kubernetes keys from etcd 3export ETCDCTL_API=3 4keys=`ETCDCTL_API=3 etcdctl --endpoints=172.31.27.61:2379 --cacert /etc/ssl/etcd/ssl 5 6/ca.pem --cert /etc/ssl/etcd/ssl/member-ip-172-31-27-61.cn-north-1.compute.internal.pem --key /etc/ssl/etcd/ssl/member-ip-172-31-27-61.cn-north-1.compute.internal-key.pem get /registry --prefix -w json|python -m json.tool|grep key|cut -d \u0026#34;:\u0026#34; -f2|tr -d \u0026#39;\u0026#34;\u0026#39;|tr -d \u0026#34;,\u0026#34;` 7for x in $keys;do 8 echo $x|base64 -d|sort 9done This script helps you retrieve and decode Kubernetes-related keys stored in etcd.\nPlease keep in mind that the most reliable and accurate source for tutorials is the official documentation (https://etcd.io/docs/v3.5/). If you have any questions, please consult the official documentation first. Wishing you the best of luck!\n","link":"https://zhangsiming-blyq.github.io/post/linux/etcd-tutorial/","section":"post","tags":["Etcd","English"],"title":"Etcd Tutorial"},{"body":"一、Java环境安装 Java是一门强大的编程语言，首先需要在您的计算机上安装Java开发环境。以下是安装Java环境的步骤：\n1. 选择Java版本 对于初学者，建议选择Java 8或Java 11版本。您可以从Oracle官方网站下载这些版本。\nJava 8下载链接：https://www.oracle.com/java/technologies/javase/jdk8-archive-downloads.html Java 11下载链接：https://www.oracle.com/java/technologies/javase/jdk11-archive-downloads.html 2. 下载示例代码 您可以下载示例代码，以便学习和实践Java编程。示例代码通常包含了一些基础的Java程序，可以帮助您快速入门。\n示例代码下载链接（以wget为例）：\n1$ wget https://horstmann.com/corejava/corejava11.zip 3. 配置环境变量 将Java主目录添加到系统的PATH环境变量中，这样您就可以在任何位置运行Java命令。您可以使用以下命令来编辑配置文件：\n1$ vim ~/.zshrc 在配置文件中添加以下行：\n1export PATH=/your/java/installation/path/bin:$PATH 确保将/your/java/installation/path替换为您的Java安装路径, 比如\u0026quot;/Users/simingzhang/siming/jdk-11.0.17/bin\u0026quot;。\n4. 验证安装 corejava实例代码和javasrc内置库代码都放到java主目录下：\n1$ tree -L 1 2. 3├── README.html 4├── bin 5├── conf 6├── corejava 7├── include 8├── javasrc 9├── jmods 10├── legal 11├── lib 12├── man 13└── release 使用以下命令验证您的Java安装是否成功：\n1$ javac --version 2javac 11.0.17 3 4$ java --version 5java 11.0.17 2022-10-18 LTS 6Java(TM) SE Runtime Environment 18.9 (build 11.0.17+10-LTS-269) 7Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.17+10-LTS-269, mixed mode) 5. 运行Welcome程序 您可以尝试运行一个简单的Java程序，比如\u0026quot;Welcome\u0026quot;程序。以下是示例代码和运行步骤：\n1$ cat Welcome.java 2/** 3 * This program displays a greeting for the reader. 4 * @version 1.30 2014-02-27 5 * @author Cay Horstmann 6 */ 7public class Welcome 8{ 9 public static void main(String[] args) 10 { 11 String greeting = \u0026#34;Welcome to Core Java!\u0026#34;; 12 System.out.println(greeting); 13 for (int i = 0; i \u0026lt; greeting.length(); i++) 14 System.out.print(\u0026#34;=\u0026#34;); 15 System.out.println(); 16 } 17} 18 19$ ls 20Welcome.java 21$ javac Welcome.java 22$ ls 23Welcome.class Welcome.java 24$ java Welcome 25Welcome to Core Java! 26===================== 这个示例演示了一个简单的Java程序，欢迎您进入Java编程的世界。\n二、基础数据类型 Java具有丰富的数据类型，让我们首先了解一些基本的概念：\n2.1 一个简单的Java应用程序 在Java中，一个简单的应用程序通常由以下几个要素组成：\n使用关键字public作为访问修饰符。 区分大小写。 类名必须以字母开头，遵循大驼峰命名规则。 源代码文件名必须与公共类的名字相同。 运行已编译的程序时，Java虚拟机总是从指定类的main方法开始执行。\n2.2 注释 在Java中，注释是非常重要的。它们用于提供关于代码的说明和文档。\nJava注释示例：\n1// This is a single-line comment. 2 3/* 4 * This is a multi-line comment. 5 * This is the second line. 6 */ 2.3 数据类型 Java是一种强类型语言，每个变量都必须声明一个数据类型。\n整型 Java提供了不同大小的整数类型，例如int、short、long和byte。每种类型都有不同的取值范围。\nint：4字节，取值范围为-2147483648到2147483647。 short：2字节，取值范围为-32768到32767。 long：8字节，取值范围为-9223372036854775808到9223372036854775807。 byte：1字节，取值范围为-128到127。 浮点类型 Java提供了float和double两种浮点类型。double类型的精度是float的两倍。\n浮点类型还有特殊值，如正无穷大、负无穷大和NaN（非数值）。\nchar类型 char类型用于表示字符，字符字面值需要用单引号括起来。\nUnicode和char类型 Java中的char类型使用Unicode编码来表示字符。\nboolean类型 boolean类型只有两个值：true和false。它主要用于条件判断。\n2.4 变量与常量 在Java中，变量用于存储数据，常量用于存储不可变的值。\n2.5 运算符 Java提供了各种运算符，包括算术运算符、比较运算符、逻辑运算符等。\n整数被0除会产生一个异常，浮点数被0除会得到无穷大或者NaN结果; 而且在使用运算符时要小心，避免出现除以零等异常情况。 几个小tips:\n不要在boolean类型与任何数值类型之间进行强制类型转换 可以在赋值中使用二元运算符，这是一种很简便的简写形式; 比如x += 1等价于x = x + 1 建议不要在表达式中使用++，因为这样的代码很容易让人困惑，而且会带来烦人的bug 1public class Variable { 2 // const 需要全大写 3 public static final double CM_PER_INCH = 2.331; 4 5 // 枚举类型在java 11必须要local不能public 6 enum Size {SMALL, MEDIUM, LARGE, EXTRA_LARGE} 7 8 public static void main(String[] args) { 9 // 定义变量并且打印变量 10 double salary; 11 int vacationDays; 12 long earthPopulation; 13 boolean done; 14 int i, j; 15 salary = 1.2; 16 vacationDays = 10; 17 earthPopulation = 20; 18 done = true; 19 double money = 1.15; 20 var test = \u0026#39;Z\u0026#39;; 21 System.out.println(salary); 22 System.out.println(vacationDays); 23 System.out.println(earthPopulation); 24 System.out.println(done); 25 System.out.println(money); 26 System.out.println(test); 27 28 System.out.println(CM_PER_INCH); 29 30 Size s = Size.LARGE; 31 System.out.println(s); 32 /* 33 1.2 34 10 35 20 36 true 37 1.15 38 Z 39 2.331 40 LARGE 41 */ 42 43 // 变量的运算符 44 System.out.println(salary * vacationDays); 45 System.out.println(money + vacationDays); 46 System.out.println(money % vacationDays); 47 /* 48 12.0 49 11.15 50 1.15 51 */ 52 53 test(); 54 convert(); 55 rela_operator(); 56 } 57 58 public static void test() { 59 // 变量的数学计算 60 System.out.println(\u0026#34;This is test part\u0026#34;); 61 double x = 4; 62 double y = Math.sqrt(x); 63 System.out.println(y); 64 System.out.println(y * Math.PI); 65 /* 66 This is test part 67 2.0 68 6.283185307179586 69 */ 70 } 71 72 public static void convert() { 73 // 变量的类型转换 74 System.out.println(\u0026#34;This is convert part\u0026#34;); 75 int n = 1289; 76 float y = n; 77 System.out.println(y); 78 double x = 9.997; 79 int nx = (int) Math.round(x); 80 System.out.println(nx); 81 /* 82 This is convert part 83 1289.0 84 10 85 */ 86 } 87 88 public static void rela_operator() { 89 // 变量的关系运算符 90 System.out.println(\u0026#34;This is relation operator part\u0026#34;); 91 int n = 1; 92 n += 4; 93 n++; 94 System.out.println(n); 95 96 // 前缀形式会先完成+1，而后缀形式会使用变量原来的值, 所以下面的答案都是14(++只是作用于相连的变量上) 97 int a = 2 * ++n; 98 int b = 2 * n++; 99 System.out.println(n); 100 System.out.println(a); 101 System.out.println(b); 102 System.out.println(n); 103 104 int x = 2; 105 int y = 3; 106 boolean b1 = x != 0 \u0026amp;\u0026amp; x \u0026gt; 1; 107 if (b1) { 108 // 三元运算符 109 System.out.println(x \u0026lt; y ? x : y); 110 } 111 /* 112 This is relation operator part 113 6 114 8 115 14 116 14 117 8 118 2 119 */ 120 } 121} 2.6 字符串 Java中的字符串是不可变的，意味着一旦创建，就不能修改。字符串类具有许多有用的方法，如equals()、isEmpty()等。\n1public class Character { 2 public static void main(String[] args) { 3 // 定义字符串 4 String greeting = \u0026#34;Hello\u0026#34;; 5 // 截取字符串，左闭右开 6 String s = greeting.substring(0, 3); 7 System.out.println(s); 8 9 // 拼接字符串 10 String expletive = \u0026#34;Expletive\u0026#34;; 11 String sum = expletive + s; 12 System.out.println(sum); 13 System.out.println(sum.repeat(3)); 14 /* 15 Hel 16 ExpletiveHel 17 ExpletiveHelExpletiveHelExpletiveHel 18 */ 19 20 // 一定不要使用 == 运算符检测两个字符串是否相等，因为这个运算符只能确定两个字符串内存是否相同 21 if (s.equals(\u0026#34;Hel\u0026#34;)) { 22 System.out.println(\u0026#34;s is equal to Hel\u0026#34;); 23 } 24 25 // 空串和 null 26 if (s != null \u0026amp;\u0026amp; s.length() != 0) { 27 System.out.println(\u0026#34;s is not empty\u0026#34;); 28 } 29 30 // 字符串构建 31 StringBuilder builder = new StringBuilder(); 32 builder.append(s); 33 builder.append(\u0026#34;siminghahaha\u0026#34;); 34 String result = builder.toString(); 35 System.out.println(result); 36 /* 37 s is equal to Hel 38 s is not empty 39 Helsiminghahaha 40 */ 41 } 42} 2.7 输入输出 Java提供了多种方式进行输入和输出操作。标准输入输出流是常用的方式之一。\n不过需要注意，因为输入是可见的，所以不适合从控制台读取密码，密码要放入字符数组中，而不是字符串中；比如Console cons = System.console(); char[] passwd = cons.readPassword();。\n1import java.io.*; 2import java.nio.charset.StandardCharsets; 3import java.nio.file.Path; 4import java.util.*; 5 6public class FiFOPart { 7 public static void main(String[] args) throws IOException { 8 // 获取输入 9 Scanner in = new Scanner(System.in); 10 System.out.println(\u0026#34;What\u0026#39;s your name?\u0026#34;); 11 String name = in.nextLine(); 12 13 Scanner ain = new Scanner(System.in); 14 System.out.println(\u0026#34;Your age?\u0026#34;); 15 int age = ain.nextInt(); 16 17 System.out.println(name + \u0026#34; is \u0026#34; + age + \u0026#34; years old.\u0026#34;); 18 19 // 打印输出 20 System.out.printf(\u0026#34;%s is %d years old.\\n\u0026#34;, name, age); 21 /* 22 What\u0026#39;s your name? 23 ZhangSiming 24 Your age? 25 26 26 ZhangSiming is 26 years old. 27 ZhangSiming is 26 years old. 28 */ 29 30 // 读写文件 31 write_file(); 32 read_file(); 33 } 34 35 public static void read_file() throws IOException { 36 Scanner in = new Scanner(Path.of(\u0026#34;test.txt\u0026#34;), StandardCharsets.UTF_8); 37 while (in.hasNext()) { 38 System.out.println(in.nextLine()); 39 } 40 } 41 42 public static void write_file() throws IOException { 43 PrintWriter out = new PrintWriter(\u0026#34;test.txt\u0026#34;, StandardCharsets.UTF_8); 44 out.println(\u0026#34;Hello, world!\u0026#34;); 45 out.close(); 46 } 47} 2.8 控制流程 控制流程用于控制程序的执行顺序。Java支持条件语句、循环语句、switch语句等。\n请注意，在循环中使用for语句时要小心循环变量的范围。\n块作用域：在块内部定义的变量只能在块内部使用，块外部不能使用块内部定义的变量。\n1public class Blockcontrol { 2 public static void main(String[] args) { 3 // if条件判断 4 int x = 10; 5 if (x \u0026lt; 20) { 6 System.out.println(\u0026#34;This is if statement\u0026#34;); 7 } else { 8 System.out.println(\u0026#34;This is else statement\u0026#34;); 9 } 10 // This is if statement 11 12 // while循环 13 int y = 20; 14 while (y \u0026lt; 25) { 15 System.out.println(\u0026#34;value of y : \u0026#34; + y); 16 y++; 17 } 18 /* 19 value of y : 20 20 value of y : 21 21 value of y : 22 22 value of y : 23 23 value of y : 24 24 */ 25 26 // do和while组合表示, 先执行一次do, 然后判断while条件是否成立, 如果成立则继续执行do, 否则退出循环 27 int z = 30; 28 do { 29 System.out.println(\u0026#34;value of z : \u0026#34; + z); 30 z++; 31 } while (z \u0026lt; 25); 32 // value of z : 30 33 34 // for循环 35 for (int i = 0; i \u0026lt; 10; i++) { 36 System.out.println(\u0026#34;value of i : \u0026#34; + i); 37 } 38 /* 39 value of i : 0 40 value of i : 1 41 value of i : 2 42 value of i : 3 43 value of i : 4 44 value of i : 5 45 value of i : 6 46 value of i : 7 47 value of i : 8 48 value of i : 9 49 */ 50 51 // switch语句，如果没有break语句，会一直执行到break语句或者switch语句结束 52 int a = 6; 53 switch (a) { 54 case 1: 55 System.out.println(\u0026#34;value is 1\u0026#34;); 56 break; 57 case 2: 58 System.out.println(\u0026#34;value is 2\u0026#34;); 59 break; 60 case 3: 61 System.out.println(\u0026#34;value is 3\u0026#34;); 62 break; 63 default: 64 System.out.println(\u0026#34;value is not 1, 2 or 3\u0026#34;); 65 } 66 // value is not 1, 2 or 3 67 68 // goto语句，跳转到指定的标签处 69 int gt = 20; 70 goto_exam: 71 while (gt \u0026lt; 25) { 72 // 跳过22 73 if (gt == 22) { 74 gt++; 75 continue; 76 } 77 if (gt == 24) { 78 for (int i = 0; i \u0026lt; 10; i++) { 79 if (i == 5) { 80 break goto_exam; 81 } 82 System.out.println(\u0026#34;value of i : \u0026#34; + i); 83 } 84 } 85 System.out.println(\u0026#34;value of gt : \u0026#34; + gt); 86 gt++; 87 } 88 /* 89 value of gt : 20 90 value of gt : 21 91 value of gt : 23 92 value of i : 0 93 value of i : 1 94 value of i : 2 95 value of i : 3 96 value of i : 4 97 */ 98 } 99} 2.9 大数 对于大数计算，Java提供了BigInteger类，可以处理大整数; 特别大的数比如彩票中奖的几率。\n1import java.math.*; 2import java.util.*; 3public class BigIntegerTest { 4 public static void main(String[] args) { 5 // 这个程序演示了如何使用大数值BigInteger类, 以及如何使用大数值BigInteger类来计算概率 6 // 通俗点说就是计算概率的时候, 用int或者long都会溢出, 所以用BigInteger类来计算 7 Scanner in = new Scanner(System.in); 8 9 System.out.println(\u0026#34;How many numbers do you need to draw?\u0026#34;); 10 int k = in.nextInt(); 11 12 System.out.println(\u0026#34;What is the highest number you can draw?\u0026#34;); 13 int n = in.nextInt(); 14 15 BigInteger lotteryOdds = BigInteger.valueOf(1); 16 for (int i = 1; i \u0026lt;= k; i++) { 17 lotteryOdds = lotteryOdds.multiply(BigInteger.valueOf(n - i + 1)).divide(BigInteger.valueOf(i)); 18 } 19 System.out.println(\u0026#34;Your odds are 1 in \u0026#34; + lotteryOdds + \u0026#34;. Good luck!\u0026#34;); 20 /* 21 How many numbers do you need to draw? 22 111 23 What is the highest number you can draw? 24 1111 25 Your odds are 1 in 228162770660494339523962629246420402033509870004236362946558722063262768528532360822215561441512138917100676811940334385612061873122251943150491920143450176. Good luck! 26 */ 27 } 28} 2.10 数组 数组是一种用于存储多个相同类型的元素的数据结构。Java中，数组的长度是固定的。\n多维数组允许您创建表格或矩阵等数据结构。\n注意：\n长度为0的数组和null并不相同 1import java.util.Arrays; 2 3public class ArrayTest { 4 public static void main(String[] args) { 5 // 定义并初始化数组的几种方法 6 int[] a; 7 a = new int[100]; 8 int[] b = new int[100]; 9 int[] c = {1, 2, 3, 4, 5,}; 10 int[] d = {}; 11 12 // 打印数组的长度 13 System.out.println(\u0026#34;a\u0026#39;s length is \u0026#34; + a.length); 14 System.out.println(\u0026#34;b\u0026#39;s length is \u0026#34; + b.length); 15 // 数组的长度是固定的，不能改变 16 // c[5] = 6; 17 System.out.println(\u0026#34;c\u0026#39;s length is \u0026#34; + c.length); 18 System.out.println(\u0026#34;d\u0026#39;s length is \u0026#34; + d.length); 19 /* 20 a\u0026#39;s length is 100 21 b\u0026#39;s length is 100 22 c\u0026#39;s length is 5 23 d\u0026#39;s length is 0 24 */ 25 26 // 访问数组元素的方式1 27 System.out.println(\u0026#34;c[0] is \u0026#34; + c[0]); 28 29 for (int i = 0; i \u0026lt; c.length; i++) { 30 System.out.println(\u0026#34;c[\u0026#34; + i + \u0026#34;] is \u0026#34; + c[i]); 31 } 32 // 访问数组元素的方式2 33 for (int i : c) { 34 System.out.println(\u0026#34;i is \u0026#34; + i); 35 } 36 // 打印数组元素最快的方式 37 System.out.println(java.util.Arrays.toString(c)); 38 /* 39 a\u0026#39;s length is 100 40 b\u0026#39;s length is 100 41 c\u0026#39;s length is 5 42 d\u0026#39;s length is 0 43 c[0] is 1 44 c[0] is 1 45 c[1] is 2 46 c[2] is 3 47 c[3] is 4 48 c[4] is 5 49 i is 1 50 i is 2 51 i is 3 52 i is 4 53 i is 5 54 [1, 2, 3, 4, 5] 55 */ 56 57 // 数组是引用类型，c和cc指向同一个数组 58 int[] cc = c; 59 cc[0] = 9999; 60 System.out.println(\u0026#34;c[0] is \u0026#34; + c[0]); 61 62 // 数组的拷贝 63 int[] cc_long = Arrays.copyOf(c, c.length + 10); 64 System.out.println(\u0026#34;cc_long\u0026#39;s length is \u0026#34; + cc_long.length); 65 System.out.println(java.util.Arrays.toString(c)); 66 System.out.println(\u0026#34;cc_long[14] is \u0026#34; + cc_long[14]); 67 68 // 快排 69 Arrays.sort(c); 70 System.out.println(java.util.Arrays.toString(c)); 71 /* 72 c[0] is 9999 73 cc_long\u0026#39;s length is 15 74 [9999, 2, 3, 4, 5] 75 cc_long[14] is 0 76 [2, 3, 4, 5, 9999] 77 */ 78 79 MultiArray(); 80 } 81 82 public static void MultiArray() { 83 // define a two-dimensional array 84 double[][] balances; 85 balances = new double[10][10]; 86 balances[0][0] = 1.0; 87 balances[0][1] = 2.0; 88 balances[1][0] = 3.0; 89 balances[1][1] = 4.0; 90 91 double[][] bb = { 92 {1, 2, 3, 4, 5}, 93 {1, 2, 3, 4, 5} 94 }; 95 96 // 打印二维数组 97 for (double[] row : bb) { 98 for (double value : row) { 99 // Print with column and row line 100 System.out.printf(\u0026#34;%10.2f\u0026#34;, value); 101 } 102 } 103 104 // 或者直接用deepToString打印多维数组 105 System.out.println(Arrays.deepToString(balances)); 106 /* 107 1.00 2.00 3.00 4.00 5.00 1.00 2.00 3.00 4.00 5.00[[1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]] 108 */ 109 110 // 打印三角数组 111 int[][] triang = triangular(); 112 for (int[] row : triang) { 113 for (int value : row) { 114 // Print with column and row line 115 System.out.printf(\u0026#34;%2d\u0026#34;, value); 116 } 117 System.out.println(); 118 } 119 /* 120 1 121 1 1 122 1 2 1 123 1 3 3 1 124 1 4 6 4 1 125 1 51010 5 1 126 1 6152015 6 1 127 1 721353521 7 1 128 1 82856705628 8 1 129 1 936841261268436 9 1 130 110451202102522101204510 1 131 */ 132 } 133 134 public static int[][] triangular() { 135 // 打印杨辉三角形 136 // 杨辉三角形：第n行有n个元素，第n行的第k个元素等于第n-1行的第k-1个元素和第k个元素之和 137 final int NMAX = 10; 138 int[][] odds = new int[NMAX + 1][]; 139 for (int n = 0; n \u0026lt;= NMAX; n++) { 140 odds[n] = new int[n + 1]; 141 } 142 143 for (int n = 0; n \u0026lt; odds.length; n++) { 144 for (int k = 0; k \u0026lt; odds[n].length; k++) { 145 int lotteryOdds = 1; 146 for (int i = 1; i \u0026lt;= k; i++) { 147 lotteryOdds = lotteryOdds * (n - i + 1) / i; 148 } 149 150 odds[n][k] = lotteryOdds; 151 } 152 } 153 return odds; 154 } 155} 三、对象与类 算法+数据结构=程序, 算法是第一位的，数据结构是第二位的,这就明确地表述了程序员的工作方式。\n3.1 面向对象程序设计概述 面向对象程序设计是一种重要的编程范式，它强调程序的结构是由对象和对象之间的交互所定义的。\n类是构造对象的模板，对象是类的实例。类包含数据字段和方法，用于描述对象的属性和行为。\n注意：\nJava编写的所有代码都位于某个类里面 对象的数据称为实例字段，操作数据的过程称为方法 程序只能通过对象的方法与对象进行数据交互，封装给对象赋予了\u0026quot;黑盒\u0026quot;特征 所有的类都有一个共同的超类Object，通过扩展一个类来建立另一个类的过程称为继承 对象的三个主要特性：\n对象的行为：可以对对象完成哪些操作，或者可以对对象应用哪些方法 对象的状态：当调用那些方法时，对象会如何响应 对象的标识：如何区分具有相同行为与状态的不同对象 类之间最常见的关系：\n依赖 聚合 继承 3.2 使用预定义类 Java提供了许多预定义类，您可以直接使用它们来完成各种任务。例如，LocalDate类用于处理日期。\n在使用预定义类时，通常需要创建类的实例，并调用其方法来执行操作。\n注意：\nJava中，使用构造器(或称构造函数)构造新实例，构造器的名字应该与类名相同，构造出来的对象需要存到一个变量中 在Java中，任何对象变量的值都是对存储在另外一个地方的某个对象的引用，new操作符的返回值也是一个引用; null表示这个对象变量目前没有引用任何对象, 比如Date deadline = new Date; 下面的程序使用预定义类\u0026quot;LocalDate\u0026quot;打印了当月的日历，并且用星号标识了所在的具体某一天(Java类库中的LocalDate类：Date类使用距离一个固定时间点的毫秒数表示，这个时间点就是所谓的纪元(ephch), 他是UTC时间1970年1月1日00:00:00)。 1/* 2Mon Tue Wed Thu Fri Sat Sun 3 1 2 3 4 5 6 4 7 8 9 10 11 12 13 5 14 15 16 17 18 19 20 6 21* 22 23 24 25 26 27 7 28 29 30 31 8 */ 9 10import java.time.*; 11 12public class CalendarTest { 13 public static void main(String[] args) { 14 // java.time.LocalDate 15 LocalDate date = LocalDate.now(); 16 int month = date.getMonthValue(); 17 int today = date.getDayOfMonth(); 18 // 由当前日期算出月初第一天日期 19 date = date.minusDays(today - 1); 20 DayOfWeek weekday = date.getDayOfWeek(); 21 int value = weekday.getValue(); // 1 = Monday, ... 7 = Sunday 22 System.out.println(\u0026#34;Mon Tue Wed Thu Fri Sat Sun\u0026#34;); 23 24 // 月初打印多少个空格取决于月初第一天是星期几 25 for (int i = 1; i \u0026lt; value; i++) 26 System.out.print(\u0026#34; \u0026#34;); 27 28 // 打印每一天，直到月末，根据是否为周一判断是否换行；并且在当前日期打出*标识 29 while (date.getMonthValue() == month) { 30 System.out.printf(\u0026#34;%3d\u0026#34;, date.getDayOfMonth()); 31 if (date.getDayOfMonth() == today) 32 System.out.print(\u0026#34;*\u0026#34;); 33 else 34 System.out.print(\u0026#34; \u0026#34;); 35 date = date.plusDays(1); 36 if (date.getDayOfWeek().getValue() == 1) 37 System.out.println(); 38 } 39 if (date.getDayOfWeek().getValue() != 1) 40 System.out.println(); 41 } 42} 3.3 用户自定义类 您可以创建自己的类来建模和解决特定问题。自定义类通常包括字段、构造器和方法。\n在类中，使用private关键字来保护数据字段，同时提供公共的访问器和更改器方法。\n构造器用于初始化对象的状态，可以有多个构造器以适应不同的需求。\nJava中最简单的类定义形式为：\n1 class ClassName 2 { 3 field1; 4 field2; 5 ... 6 constructor1; 7 constructor2; 8 ... 9 method1; 10 method2; 11 ... 12 } 关于构造器:\n构造器与类同名 每个类可以有一个以上的构造器 构造器可以有0个、1个或者多个参数 构造器没有返回值 构造器总是伴随着new操作符一起调用 注意:\n关键字public意味着任何类的任何方法都可以调用这些方法; private确保只有Employee类自身的方法能够访问这些实例字段 不要在构造器中定义与实例字段同名的局部变量 不要编写返回可变对象引用的访问器方法，因为如果是引用的话，在外界也可以更改，就违背了封装的设计原则(这个对象只能在方法中修改返回), 会让程序变得不可控 final修饰符(不可修改，并且确保每一个构造器执行之后这个字段已经设置)：如果一个类不希望被继承，就用final修饰符来修饰这个类，如果一个方法不希望被重写，就用final修饰符来修饰这个方法，如果一个变量不希望被修改，就用final修饰符来修饰这个变量 var声明局部变量，Java10以后才会有 1/* 2name=Carl Cracker,salary=78750.0,hireDay=1987-12-15 3name=Harry Hacker,salary=52500.0,hireDay=1989-10-01 4name=Tony Tester,salary=42000.0,hireDay=1990-03-15 5 */ 6 7import java.time.*; 8 9public class EmployeeTest { 10 public static void main(String[] args) { 11 // 创建三个Employee对象 12 Employee[] staff = new Employee[3]; 13 staff[0] = new Employee(\u0026#34;Carl Cracker\u0026#34;, 75000, 1987, 12, 15); 14 staff[1] = new Employee(\u0026#34;Harry Hacker\u0026#34;, 50000, 1989, 10, 1); 15 staff[2] = new Employee(\u0026#34;Tony Tester\u0026#34;, 40000, 1990, 3, 15); 16 // 给每一个Employee对象加薪5% 17 for (Employee e : staff) 18 e.raiseSalary2(5); 19 // 打印出每一个Employee对象的信息 20 for (Employee e : staff) 21 System.out.println(\u0026#34;name=\u0026#34; + e.getName() + \u0026#34;,salary=\u0026#34; + e.getSalary() + \u0026#34;,hireDay=\u0026#34; + e.getHireDay()); 22 } 23} 24 25class Employee { 26 private final String name; 27 private double salary; 28 private LocalDate hireDay; 29 30 public Employee(String n, double s, int year, int month, int day) { 31 name = n; 32 salary = s; 33 hireDay = LocalDate.of(year, month, day); 34 } 35 36 public String getName() { 37 return name; 38 } 39 40 public double getSalary() { 41 return salary; 42 } 43 44 public LocalDate getHireDay() { 45 return hireDay; 46 } 47 48 public void raiseSalary(double byPercent) { 49 double raise = salary * byPercent / 100; 50 // 不能这样操作，因为name被设置成了final：name += \u0026#34;test\u0026#34;; 51 salary += raise; 52 } 53 54 public void raiseSalary2(double byPercent) { 55 double raise = this.salary * byPercent / 100; 56 this.salary += raise; 57 } 58} 3.4 静态域与静态方法 静态域和静态方法属于类而不是对象，它们可以被所有对象共享; 换言之如果将一个字段定义为static，每个类只有一个这样的字段, 并且从这个类实例化出来的每一个对象都共享这个字段的值。\n静态常量: 是不可修改的值，通常使用public static final修饰, 比如public static final double PI = 3.1415926;\n静态方法: 是没有隐式参数(是没有this参数的方法)的方法，可以直接通过类名调用, 无需实例化对象，比如Math.pow(2, 3);\nmain方法也是静态方法，实际上启动程序的时候还没有任何对象，静态的main方法将执行并构造程序所需要的对象\n1/* 2name=Tom,id=1,salary=40000.0 3name=Dick,id=2,salary=60000.0 4name=Harry,id=3,salary=65000.0 5Next available id=4 6 */ 7public class StaticTest { 8 public static void main(String[] args) { 9 EmployeeNew[] staff = new EmployeeNew[3]; 10 staff[0] = new EmployeeNew(\u0026#34;Tom\u0026#34;, 40000); 11 staff[1] = new EmployeeNew(\u0026#34;Dick\u0026#34;, 60000); 12 staff[2] = new EmployeeNew(\u0026#34;Harry\u0026#34;, 65000); 13 14 for (EmployeeNew e : staff) { 15 e.setId(); 16 System.out.println(\u0026#34;name=\u0026#34; + e.getName() + \u0026#34;,id=\u0026#34; + e.getId() + \u0026#34;,salary=\u0026#34; + e.getSalary()); 17 } 18 int n = EmployeeNew.getNextId(); 19 System.out.println(\u0026#34;Next available id=\u0026#34; + n); 20 } 21} 22 23class EmployeeNew { 24 // 所有这个类实例化出来的对象都共享这个nextId 25 private static int nextId = 1; 26 private String name; 27 private double salary; 28 private int id; 29 30 public EmployeeNew(String n, double s) { 31 name = n; 32 salary = s; 33 id = 0; 34 } 35 36 public String getName() { 37 return name; 38 } 39 40 public double getSalary() { 41 return salary; 42 } 43 44 public int getId() { 45 return id; 46 } 47 48 public void setId() { 49 id = nextId; 50 nextId++; 51 } 52 53 public static int getNextId() { 54 return nextId; 55 } 56 57 public static void main(String[] args) { 58 EmployeeNew e = new EmployeeNew(\u0026#34;Harry\u0026#34;, 50000); 59 System.out.println(e.getName() + \u0026#34; \u0026#34; + e.getSalary()); 60 } 61} 3.5 方法参数 程序语言设计汇总关于将参数传递给方法：按值调用表示方法接收的是调用者提供的值，而按引用调用表示方法接收的是调用者提供的变量地址\nJava程序设计语言总是采用按值调用，也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容\nJava中对方法参数能做什么和不能做什么\n方法不能修改基本数据类型的参数 方法可以改变对象参数的状态 方法不能让一个对象参数引用一个新的对象 3.6 对象构造 重载：有些类有多个构造器，这种情况下，编译器会挑选出一个\u0026quot;最近匹配\u0026quot;的构造器，如果没有找到任何匹配的构造器，编译器就会报错\n默认字段初始化：如果再构造器中没有显示地给字段赋值，那么就会自动地将他们初始化为0、false或者null\n显式字段初始化：比如\n1private String name = \u0026#34;\u0026#34;; 2private double salary; 3private LocalDate hireDay; 调用另一个构造器：关键字this只是一个方法的隐式参数，当然还可以在一个构造器中用this调用另一个构造器，这个调用必须是构造器的第一个语句，例如：\n1public Employee(double s) 2{ 3 this(\u0026#34;Employee #\u0026#34; + nextId, s); 4} 注意：\n由于Java会完成自动的垃圾回收，不需要人工回收内存，所以Java不支持析构器；警告不要使用finalize方法来完成清理 1/* 2name=Harry,id=9794,salary=40000.0 3name=Employee #9795,id=9795,salary=60000.0 4name=,id=9796,salary=0.0 5 */ 6 7import java.util.*; 8 9public class ConstructorTest { 10 public static void main(String[] args) { 11 // 创建一个长度为3的EmployeeCt数组 12 EmployeeCt[] staff = new EmployeeCt[3]; 13 // 重载构造器，创建三个EmployeeCt对象 14 staff[0] = new EmployeeCt(\u0026#34;Harry\u0026#34;, 40000); 15 staff[1] = new EmployeeCt(60000); 16 staff[2] = new EmployeeCt(); 17 18 // 打印对象信息 19 for (EmployeeCt e : staff) { 20 System.out.println(\u0026#34;name=\u0026#34; + e.getName() + \u0026#34;,id=\u0026#34; + e.getId() + \u0026#34;,salary=\u0026#34; + e.getSalary()); 21 } 22 } 23} 24 25class EmployeeCt { 26 private static int nextId; 27 private int id; 28 private String name = \u0026#34;\u0026#34;; // instance field initialization 29 private double salary; 30 31 // static initialization block 32 // 所有的类，不管是不是实例化，都只执行最开始的一次 33 static { 34 Random generator = new Random(); 35 // set nextId to a random number between 0 and 9999 36 nextId = generator.nextInt(10000); 37 } 38 39 // object initialization block 40 { 41 id = nextId; 42 nextId++; 43 } 44 45 // 下面是三个重载的构造器 46 public EmployeeCt(String n, double s) { 47 name = n; 48 salary = s; 49 } 50 51 public EmployeeCt(double s) { 52 // calls the Employee(String, double) constructor 53 this(\u0026#34;Employee #\u0026#34; + nextId, s); 54 } 55 56 public EmployeeCt() { 57 // name initialized to \u0026#34;\u0026#34; --see above 58 // salary not explicitly set--initialized to 0 59 // id initialized in initialization block 60 } 61 62 public String getName() { 63 return name; 64 } 65 66 public double getSalary() { 67 return salary; 68 } 69 70 public int getId() { 71 return id; 72 } 73} 3.7 包 使用包的主要原因是确保类名的唯一性；类的导入示例：\n1import java.util.*; 2import java.sql.*; 有一种import语句允许导入静态方法和静态字段，而不只是类：\n1import static java.lang.System.*; 注意：\n如果没有在源文件中放置package语句，这个源文件中的类就属于无名包 编译器处理文件(带有文件分隔符和扩展名.java的文件), 而Java解释器(虚拟机)执行类(带有点号和.class扩展名的文件) 标记为public的部分可以由任意类使用，标记为private的部分只能由定义他们的类使用；如果没有指定访问修饰符，那么这个类只能被同一个包中的其他类访问 类存储在文件系统的子目录中，类的路径必须与包名匹配 类文件也可以存储在JAR(Java归档)文件中，在一个JAR文件中，可以包含多个压缩形式的类文件和子目录 1$ tree . 2. 3├── TestPackage.java 4├── com 5│ └── horstmann 6│ └── corejava 7│ └── TestClass.java 8 9$ cat TestPackage.java 10import com.horstmann.corejava.*; 11 12public class TestPackage { 13 public static void main(String[] args) { 14 // 不需要使用全限定名，因为有import语句 15 TestClass.main(args); 16 } 17} 18 19$ cat com/horstmann/corejava/TestClass.java 20package com.horstmann.corejava; 21 22public class TestClass { 23 public static void main(String[] args) { 24 System.out.println(\u0026#34;Hello, World!\u0026#34;); 25 } 26} 3.8 JAR文件 JAR文件是Java应用程序或库的打包方式，它将所有相关的类和资源打包到一个文件中，方便分发和部署。\nJAR的清单文件：清单文件是一个包含应用程序或者库的主清单属性的特殊文件，清单文件的名字是META-INF/MANIFEST.MF，清单文件的第一行必须是Manifest-Version: 1.0，清单文件中的每一行都是一个属性-值对，属性名和值之间用冒号分隔，属性名区分大小写，属性值前后可以有空格，属性值可以跨越多行，如果以空行开头，那么它就是前一个属性值的一部分，清单文件的最后一行必须以换行符结束\n3.9 文档注释 类注释：类注释必须放在import语句之后，类定义之前，比如：\n1/** 2* @version 1.01 2004-02-21 3* @author 4*/ 5public class ClassName 6{ 7 . . . 8} 方法注释：每一个方法注释必须放在所描述的方法之前：\n@param：参数的名字和说明 @return：返回值的说明 @exception：抛出的异常 比如：\n1/** 2* Computes the square root of a number. 3* @param x a nonnegative number 4* @return the square root of x 5* @throws IllegalArgumentException if x is negative 6*/ 7public static double sqrt(double x) 8{ 9 if (x \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;x must be nonnegative\u0026#34;); 10 return Math.sqrt(x); 11} 字段注释：只需要对公共字段建立\n1/** 2* The name of the employee. 3*/ 4private String name; 通用注释：\n@version：版本号 @since：自从哪个版本 @see：参考 @deprecated：不建议使用 3.10 类设计技巧 设计良好的类是编程的基础，以下是一些类设计的技巧：\n保证数据私有性。 对数据进行初始化。 不要过多使用基本数据类型: 如果一个类中有很多基本类型，那么就应该考虑将它分解成多个类 不要为每个字段都提供独立的访问器和更改器。 将职责过多的类进行分解。 类名和方法名应该能够清晰地反映其职责。 ","link":"https://zhangsiming-blyq.github.io/post/java/java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF1/","section":"post","tags":["Java","中文"],"title":"【Java入门系列】Java基础入门 --- 安装，数据类型，类"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/java/","section":"tags","tags":null,"title":"Java"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/java/","section":"categories","tags":null,"title":"Java"},{"body":"Neovim, a powerful editor often hailed as a third-party extension for Vim, boasts an impressive 70k stars on GitHub. This robust tool makes for an excellent default editor choice. This guide will take you through the installation process and equip you with effective typing techniques.\nInstallation GitHub Link\nNeovim Installation On MacOS 1$ brew install neovim 2 3$ which nvim 4/usr/local/bin/nvim 5 6$ vim ~/.zshrc 7alias vim=\u0026#39;nvim\u0026#39; 8alias old_vim=\u0026#39;vim\u0026#39; 9 10# replace the normal vim with nvim 11$ which vim 12vim: aliased to nvim 13 14$ vim --version 15NVIM v0.7.2 16Build type: Release 17LuaJIT 2.1.0-beta3 18Compiled by brew@Monterey 19 20Features: +acl +iconv +tui 21See \u0026#34;:help feature-compile\u0026#34; 22 23 system vimrc file: \u0026#34;$VIM/sysinit.vim\u0026#34; 24 fall-back for $VIM: \u0026#34;/usr/local/Cellar/neovim/0.7.2_1/share/nvim\u0026#34; 25 26Run :checkhealth for more info Essential Components Installing a Plugin Manager If you haven't already, it's crucial to set up a plugin manager for seamless plugin installation and management in Neovim. Some popular options include vim-plug, dein.vim, and packer.nvim. In this guide, we'll demonstrate with vim-plug as the example.\nInstall vim-plug by following the instructions provided on its GitHub repository: https://github.com/junegunn/vim-plug\n1sh -c \u0026#39;curl -fLo \u0026#34;${XDG_DATA_HOME:-$HOME/.local/share}\u0026#34;/nvim/site/autoload/plug.vim --create-dirs \\ 2 https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\u0026#39; Configuring nvim's Initialization File Locate the configuration file at ~/.config/nvim/init.vim. This file plays a pivotal role in configuring Neovim and loading plugins effectively.\nPlugin Installation After saving your init.vim file, restart Neovim or run :source ~/.config/nvim/init.vim to apply the changes. Inside Neovim, input the following command to install the plugins:\n1:PlugInstall This command initiates the download and installation of all configured plugins mentioned in your configuration, simultaneously generating output in your vim console.\nCrafting Your Personalized Neovim Setup Let's delve into the intricacies of configuring each line in your initialization file:\n1set paste 2set number 3set relativenumber The initial three lines comprise simple settings for Neovim. The set paste command activates \u0026quot;paste mode,\u0026quot; effectively disabling auto-indentation and other automatic formatting adjustments when pasting text. This prevents unintentional formatting changes when pasting code from external sources. set number introduces line numbering, revealing line numbers on the left side of the buffer. set relativenumber displays relative line numbers instead of absolute ones. This approach designates the current line as 0, with other lines denoted by positive or negative offsets relative to the current line. This feature streamlines navigation within the buffer. 1set background=dark This line establishes the background color of the editor. While this configuration adopts dark mode, you can easily switch to a light-themed background by using light. 1set nocompatible This line eliminates compatibility with the old-time vi editor. As Neovim represents an enhanced and extended iteration of Vim, disabling compatibility ensures the availability of Neovim-specific features. You'll always need to include this line in your configuration file. 1set showmatch 2set ignorecase 3set mouse=v 4set hlsearch 5set incsearch set showmatch activates the highlighting of matching parentheses, brackets, and similar pairs when the cursor hovers over them. set ignorecase enforces case-insensitivity during search operations, allowing matches for both lowercase and uppercase instances. set mouse=v enables mouse support, facilitating navigation, split resizing, and middle-click pasting via the mouse. set hlsearch highlights search matches in real-time while entering the search query, enhancing visibility of match locations. set incsearch showcases incremental search outcomes as the search query evolves. The feature highlights partial matches while typing. 1set tabstop=4 2set softtabstop=4 3set expandtab 4set shiftwidth=4 5set autoindent 6set number set tabstop=4 establishes the count of columns occupied by a tab character, fixed at 4 in this case. set softtabstop=4 recognizes a group of spaces as a tab for indentation purposes, enabling Backspace to function as expected. set expandtab converts tab characters into spaces, ensuring uniform indentation, particularly when collaborating with others who might have varied tab settings. set shiftwidth=4 designates the number of spaces used for auto-indentation after pressing Enter. This setting governs the cursor's rightward movement during auto-indentation. set autoindent aligns new lines with the indentation of the previous line, maintaining consistency in indentation levels. 1set wildmode=longest,list 2set cc=80 set wildmode=longest,list simulates bash-like tab completion behavior. If only one match exists, it's automatically completed. With multiple matches, a list prompts you to choose. set cc=80 introduces a color column at the 80th column, serving as a visual guide to maintain code within a defined width, promoting clean coding practices. 1filetype plugin indent on 2syntax on 3set mouse=a 4set clipboard=unnamedplus 5filetype plugin on filetype plugin indent on enables filetype detection, thereby activating corresponding plugins and indent settings based on the file type. syntax on triggers syntax highlighting, offering color-coded visuals for diverse programming languages and file types. set mouse=a empowers mouse support, encompassing mouse clicks and scrolling functionality. set clipboard=unnamedplus directs Neovim to employ the system clipboard (if available) for copy and paste tasks, streamlining interaction with the system clipboard. 1set cursorline 2set ttyfast set cursorline accentuates the line where the cursor resides, simplifying tracking of the active line. set ttyfast optimizes scrolling performance within the terminal, leading to smoother scrolling within terminal-based Neovim. 1\u0026#34; set spell \u0026#34; enabling spell check (may require language package download) 2\u0026#34; set noswapfile \u0026#34; preventing swap file creation 3\u0026#34; set backupdir=~/.cache/vim \u0026#34; Directory for storing backup files. Lines commencing with \u0026quot; entail commented-out options, currently inactive within the configuration(I suggest not active these three configuration lines). set spell empowers spell checking functionality, highlighted by identifying misspelled words. set noswapfile inhibits the generation of swap files. While these files aid in recovering unsaved changes after crashes, deactivation implies potential loss of unsaved edits upon unexpected termination. set backupdir=~/.cache/vim specifies the directory for storing backup files. These duplicates of original files are generated before saving changes. Although the line mentions ~/.cache/vim, it remains commented out. 1call plug#begin(\u0026#39;~/.local/share/nvim/site/plugged\u0026#39;) 2 Plug \u0026#39;dracula/vim\u0026#39; 3 Plug \u0026#39;gruvbox-community/gruvbox\u0026#39; 4 Plug \u0026#39;ryanoasis/vim-devicons\u0026#39; 5 Plug \u0026#39;honza/vim-snippets\u0026#39; 6 Plug \u0026#39;scrooloose/nerdtree\u0026#39; 7 Plug \u0026#39;preservim/nerdcommenter\u0026#39; 8 Plug \u0026#39;mhinz/vim-startify\u0026#39; 9call plug#end() These lines leverage vim-plug to facilitate plugin management. The segment lies between call plug#begin() and call plug#end(). Each Plug line designates a plugin for installation and management. This configuration includes Dracula and Gruvbox themes, Devicons for file icons, Vim Snippets, NERDTree, NerdCommenter, Startify, and more. 1autocmd BufReadPost * 2 \\ if line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;) \u0026gt; 0 \u0026amp;\u0026amp; line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;) \u0026lt;= line(\u0026#34;$\u0026#34;) | 3 \\ exe \u0026#34;normal! g`\\\u0026#34;\u0026#34; | 4 \\ endif Remember the last cursor position when opening a file 1if has(\u0026#39;persistent_undo\u0026#39;) 2 \u0026#34; Set a directory to store undo files 3 let g:undo_dir = $HOME . \u0026#39;/.vim/undodir\u0026#39; 4 if !isdirectory(g:undo_dir) 5 call mkdir(g:undo_dir, \u0026#39;p\u0026#39;) 6 endif 7 8 \u0026#34; Store undo history in the specified directory 9 set undodir=$HOME/.vim/undodir 10 11 \u0026#34; Enable persistent undo 12 set undofile 13endif Enable undo history across sessions 1colorscheme gruvbox Set the theme to Gruvbox, it's also my favorite vim theme. 1\u0026#34; move line or visually selected block - alt+j/k 2inoremap \u0026lt;A-j\u0026gt; \u0026lt;Esc\u0026gt;:m .+1\u0026lt;CR\u0026gt;==gi 3inoremap \u0026lt;A-k\u0026gt; \u0026lt;Esc\u0026gt;:m .-2\u0026lt;CR\u0026gt;==gi 4vnoremap \u0026lt;A-j\u0026gt; :m \u0026#39;\u0026gt;+1\u0026lt;CR\u0026gt;gv=gv 5vnoremap \u0026lt;A-k\u0026gt; :m \u0026#39;\u0026lt;-2\u0026lt;CR\u0026gt;gv=gv 6 7\u0026#34; move split panes to left/bottom/top/right 8 nnoremap \u0026lt;A-h\u0026gt; \u0026lt;C-W\u0026gt;H 9 nnoremap \u0026lt;A-j\u0026gt; \u0026lt;C-W\u0026gt;J 10 nnoremap \u0026lt;A-k\u0026gt; \u0026lt;C-W\u0026gt;K 11 nnoremap \u0026lt;A-l\u0026gt; \u0026lt;C-W\u0026gt;L 12 13\u0026#34; move between panes to left/bottom/top/right 14 nnoremap \u0026lt;C-h\u0026gt; \u0026lt;C-w\u0026gt;h 15 nnoremap \u0026lt;C-j\u0026gt; \u0026lt;C-w\u0026gt;j 16 nnoremap \u0026lt;C-k\u0026gt; \u0026lt;C-w\u0026gt;k 17 nnoremap \u0026lt;C-l\u0026gt; \u0026lt;C-w\u0026gt;l 18 19\u0026#34; Press i to enter insert mode, and ii to exit insert mode. 20:inoremap ii \u0026lt;Esc\u0026gt; 21:inoremap jk \u0026lt;Esc\u0026gt; 22:inoremap kj \u0026lt;Esc\u0026gt; 23:vnoremap jk \u0026lt;Esc\u0026gt; 24:vnoremap kj \u0026lt;Esc\u0026gt; Some key-mapping tips for you, can be used according to personal habits. A Sneak Peek Now here is our ultimate Neovim configuration, Take a look at it!\nSome Valuable Features I Prefer Your history endures even after file closure, enabling convenient use of Ctrl + R or u for undoing changes. Cursor placement is preserved upon reopening files, proving particularly advantageous when working on substantial projects. Pasting maintains its original structure, preventing inadvertent indentation issues and code disruption. The chosen theme is Dracula, an impressive Vim theme renowned for its aesthetics and functionality. Now you've got a gorgeous and up-to-coming enhanced Vim, embrace Productive Coding, and wish You a Wonderful Day.\n","link":"https://zhangsiming-blyq.github.io/post/linux/neovim/","section":"post","tags":["vim","English"],"title":"Comprehensive Guide to Neovim"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/vim/","section":"tags","tags":null,"title":"vim"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/vim/","section":"categories","tags":null,"title":"vim"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/git/","section":"tags","tags":null,"title":"git"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/git/","section":"categories","tags":null,"title":"git"},{"body":" 参考链接: https://www.atlassian.com/git/tutorials/cherry-pick/ git 的 cherry-pick 操作简单来讲就是可以把具体的commit从一个分支，直接嫁接(复制)到另一个分支, 下面看一个例子: 1$ git branch 2* feat/siming 3 master 4$ git log 5commit 1d7df64add47be9891efa6469f663e78acf3982f (HEAD -\u0026gt; feat/siming, origin/feat/siming) 6Author: zhangsiming \u0026lt;zhangsiming@360.cn\u0026gt; 7Date: Fri Feb 10 20:18:59 2023 +0800 8 9 test2 10 11commit a272f807df9f22c58aa2a970ff26a13a66abec4d 12Author: zhangsiming \u0026lt;zhangsiming@360.cn\u0026gt; 13Date: Fri Feb 10 19:59:06 2023 +0800 14 15 test 16... 17 18# 可以看到feat/siming分支最近两个commit一个是test，一个是test2，我们现在记录一下test的commitId，然后把他cherry-pick到master分支 19$ git checkout master 20$ git cherry-pick a272f807df9f22c58aa2a970ff26a13a66abec4d 21 22# 大功告成，test部分的变更已经追加到了master分支，我们看一下git log graph(注意看HEAD指针位置) 23$ git log --pretty=oneline --graph --decorate --all 24 25* 1d7df64add47be9891efa6469f663e78acf3982f (origin/feat/siming, feat/siming) test2 26* a272f807df9f22c58aa2a970ff26a13a66abec4d test 27* 627f296be9f64418d4f6dfe99d2fcf6881196f30 (HEAD -\u0026gt; master, origin/master, origin/HEAD) Merge branch \u0026#39;feat/siming\u0026#39; into \u0026#39;master\u0026#39; 28|\\ 29| * 3a64ef1e9c78dba97b775ac6fcf3a1ecf0c7e925 fix: 优化gpu-alarmer 30| * 08358da0a98490e9e87a990342d13dbeffb7758f add: k8s-weekly-report 31| * 7231fc0a739fae55a5800e883d2e811b6c58e7f3 fix: 修改eventsinformer时间展示 32 33# 如果不想要这个commit了，可以reset回退(HEAD后面有几个^就回退几个commit，或者采用HEAD~n) 34$ git reset --hard HEAD^ ","link":"https://zhangsiming-blyq.github.io/post/linux/git%E7%9A%84cherry-pick%E6%93%8D%E4%BD%9C/","section":"post","tags":["shorthand","git","中文"],"title":"git的cherry-pick操作"},{"body":" kubernetes的cordon打上的SchedulingDisabled仅仅影响调度，也就是直接打上nodeName不会受到该参数的影响 kubernetes的QosClass判断pod内的全部container，包括init-container，也就是如果init-container不进行限制，其他container无论怎么配置仍然不是Guaranteed kubernetes集群新版本如果cordon打上unschedule，会默认追加Taint；旧版本不会 kubernetes集群对于unschedule的节点不会走入调度环节，只有可以正常调度的节点才会走到后面判断Toleration，label等；特别地，对于daemonset的pod，schedulingDisable无效，但是tolerance等有效(v1.17版本中，Damoneset 的 pod 的调度从 daemonset controller 迁移到 kube-scheduler 来做调度，从而支持 PodAffnity、PodAntiAffinity 等能力) Error(不再重启)，Completed状态的podip会显示，但是实际不占用podip，真实podip已经分配给其他服务使用 kubernetes中，kubelet限制的max-pod数量是限制的具体的pod数量，超出会报错Outofpods 每次pod重启，kubelet会给他分配新的cgroup目录路径，而不会使用原来的；新的pod启动之后间隔一小段时间会删除旧的cgroup路径 kubernetes 推荐使用 systemd 来代替 cgroupfs; 因为systemd是kubernetes自带的cgroup管理器, 负责为每个进程分配cgroups; 但docker的cgroup driver默认是cgroupfs,这样就同时运行有两个cgroup控制管理器；可以使用docker info查看docker使用的cgroup driver，然后从\u0026quot;/etc/docker/daemon.json\u0026quot;中修改成systemd ","link":"https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/","section":"post","tags":["shorthand","kubernetes","中文"],"title":"kubernetes常规问题"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/linux/","section":"tags","tags":null,"title":"linux"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/linux/","section":"categories","tags":null,"title":"linux"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/shorthand/","section":"tags","tags":null,"title":"shorthand"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/shorthand/","section":"categories","tags":null,"title":"shorthand"},{"body":" 中断是什么？中断是一种电信号，由硬件产生并直接送到中断控制器上，再由中断控制器向CPU发送中断信号，CPU检测到信号后，中断当前工作转而处理中断信号；其实准确的说这种算硬中断 如果不像让这种中断，或者系统中断和网络中断和一些业务的中断在同一个cpu上面互相影响；可以把某个中断绑定到某几个特定的cpu核心，来达到目的 默认情况systemctl status irqbalance服务会平衡所有中断均衡地是用cpu 可以用echo cpu号 \u0026gt; /proc/irq/中断号/smp_affinity或者使用taskset来绑定中断到具体的cpu核心 ethtool -l eth0可以看到，一些通道信息(这个通道是可以触发网络中断的队列数量), 设置多了会影响内存等资源，设置小了可能会称为高流量瓶颈 参考链接：https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/interrupt_and_process_binding ","link":"https://zhangsiming-blyq.github.io/post/linux/%E4%B8%AD%E6%96%AD%E7%BB%91%E5%AE%9Acpu%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98/","section":"post","tags":["shorthand","linux","中文"],"title":"中断绑定cpu核心问题"},{"body":"\n该svc作为集群内部服务连接api-server的媒介(这三个信息会被注入到每个集群内部的pod中: KUBERNETES_SERVICE_HOST=10.96.0.1、KUBERNETES_SERVICE_PORT=443、KUBERNETES_SERVICE_PORT_HTTPS=443) 永远使用\u0026quot;--service-cluster-ip-range\u0026quot;定义的CIDR的第一个ip地址 svc以及对应的endpoints都是由master controller(api-server二进制文件在最开始启动的controller之一)管控 RunKubernetesService()是一个循环，里面的逻辑包含支持UpdateKubernetesService()更新这个svc信息，ReconcileEndpoints(...endpointPorts []corev1.EndpointPort...)来更新endpoint，也就是一般3个master的信息；不过有时候看到的endpoint可能只有一个ip，这可能是云厂商传入的master lb层 参考链接: https://networkop.co.uk/post/2020-06-kubernetes-default/ ","link":"https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-default-svc/","section":"post","tags":["shorthand","kubernetes","中文"],"title":"在default命名空间下的svc, kubernetes"},{"body":" For people new to Golang and Python, this article explains what closures are as well as sometips that need to know about when using closures in these two programming languages. To make it easier for you to copy down and run on your own server, the code section would provide the package, import, and other repeated parts. The negative aspect is that this results in some redundancy, so please understand if this causes any inconvenience.\nWhat Is Closures? a closure is a record storing a function together with an environment.\nClosure's two factors: function and environment\nfunction：Refers to the fact that when closures are actually implemented, they are often done by calling an external function that returns its internal function. An internal function may be an internal real-name function, an anonymous function, or a lambda expression. environment：In practice, the referenced environment is the environment of the external function and the closure holds/records all the environment of the external function at the time when it's being generated. To summarize, a closure is a function that extends the scope by retaining the bindings of free variables (variables not bound in the local scope) that existed when the function was defined, so that when the function is called, the definition scope is no longer available, but those bindings can still be used. Here is a look at the common usage of closures:\n1// golang version 2package main 3 4import \u0026#34;fmt\u0026#34; 5 6func outer() func(v int) { 7 x := 1 8 return func(v int) { 9 y := x + v 10 fmt.Println(x) 11 fmt.Println(y) 12 } 13} 14 15func main() { 16 a := outer() 17 a(1) 18 a(2) 19} 20 21// result 221 232 241 253 In the logic inside the golang example, \u0026quot;a\u0026quot; is a closure, the closure function is the internal func(v int){}, the closure environment is the external \u0026quot;x\u0026quot;, since the external environment is \u0026quot;captured\u0026quot;, so each execution of the closure \u0026quot;x\u0026quot; is 1, and the final output result is 1,2,1,3.\n1# python version 2def outer(): 3 x = 1 4 5 def inner(v): 6 y = x + v 7 print(x) 8 print(y) 9 return inner 10 11a = outer() 12a(1) 13a(2) 14 15# result 161 172 181 193 When comes to Python example, the same closure function is inner(v), the closure environment is \u0026quot;x\u0026quot;, so each time the closure is executed \u0026quot;x\u0026quot; is 1 (because the closure environment is captured), and then the logic inside the closure is to add \u0026quot;x\u0026quot; to the parameters passed in by the closure, so the final output is 1,2,1,3.\nClosures In Golang Anonymous Function Since anonymous functions are used very frequently in golang, let's start with this: Anonymous functions and the free variables they \u0026quot;capture\u0026quot; are called closures, and they are closed whether used normally, in a for loop, or in a defer:\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 x := 1 7 a := func(v int) { 8 y := x + v 9 fmt.Println(x) 10 fmt.Println(y) 11 } 12 a(2) 13 a(3) 14} 15 16// result 171 183 191 204 In the above example a is a closure, the closure function is the anonymous function func(v int){}, the closure environment is x, so the result is 1,3,1,4.\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 y := 2 7 8 defer func() { 9 fmt.Println(y) 10 }() 11} 12 13// result 142 The same goes for the anonymous function in defer, which is func(){} in defer, and the closure environment is \u0026quot;y\u0026quot;, so the output is 2.\nModifies The Closure Environment First of all, all reference passing in golang is a value passing, if there is something like reference passing (which will also be mentioned later in this article for convenience), it is actually the \u0026quot;value\u0026quot; of the underlying pointer that is passed, thus achieving the so-called reference passing.\nIf you want to modify the closure environment inside the closure (in the closure function), golang is easy to do that. Owing to the fact that golang is a declarative language, assignment and declaration are written differently(:= for declaration, = for assignment); and golang closure \u0026quot;captures\u0026quot; the essence of the closure environment is reference passing rather than value passing, so directly modify it is ok, see the following example: 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func make_avg() func(v int) { 6 count := 0 7 total := 0 8 return func(v int) { 9 count += 1 10 total += v 11 fmt.Println(float32(total)/float32(count)) 12 } 13} 14 15func main() { 16 a := make_avg() 17 a(1) 18 a(2) 19 a(3) 20} 21 22// result 231 241.5 252 The example is to calculate the average value, the closure is \u0026quot;a\u0026quot;, the closure function is the internal func(v int){} anonymous function, the closure environment is \u0026quot;count\u0026quot; and \u0026quot;total\u0026quot;; count += 1, total += v are direct modifications to the behavior of the closure environment and get the desired effect.\nSpecifically, you can use golang closures to \u0026quot;catch\u0026quot; the essence of the closure environment is reference passing this feature inside the anonymous function (inside the closure function) modify the global variables (closure environment), see the following example:\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7var x int = 1 8 9func main() { 10 a := func() { 11 x += 1 12 } 13 fmt.Println(x) 14 a() 15 fmt.Println(x) 16} 17 18// result 191 202 Modify the closure environment outside the closure You must have some questions, \u0026quot;outside the closure\u0026quot; can modify the closure environment? In fact, it is possible in golang, remember the following two sentences:\nIf all the variables of the external function are local, that is, the life cycle ends when the external function ends, then the environment of the closure is also closed. Conversely, then the closure is no longer closed, and changes to globally visible variables will have an effect on the variables within the closure. Generally speaking, if the environment of a closure can be modified by a pointer, then the environment of the closure can be modified from outside the closure, see the following example:\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func foo1(x *int) func() { 6 return func() { 7 *x = *x + 1 8 fmt.Println(*x) 9 } 10} 11func foo2(x int) func() { 12 return func() { 13 x = x + 1 14 fmt.Println(x) 15 } 16} 17 18func main() { 19 x := 133 20 f1 := foo1(\u0026amp;x) 21 f2 := foo2(x) 22 f1() 23 f1() 24 f2() 25 f2() 26 27 x = 233 28 f1() 29 f1() 30 f2() 31 f2() 32 33 foo1(\u0026amp;x)() 34 foo1(\u0026amp;x)() 35 foo2(x)() 36 foo2(x)() 37} The logic inside the two closures needs to be analyzed, one is the sum of pointer variables, according to what we said earlier, \u0026quot;the closure environment can be modified by pointers\u0026quot;, each time the closure is executed or directly assigned outside will really change the value of the variable, while the \u0026quot;foo2\u0026quot;, which does not use pointers, is the normal closure, that is, the closure environment is only inside the closure; so the first four groups of output as follows:\n1134 2135 3134 4135 The middle four groups are being accumulated by the \u0026quot;f1\u0026quot; closure on the modified 233 because the value of \u0026quot;x\u0026quot; is forced externally, and the \u0026quot;f2\u0026quot; closure is being accumulated in its own environment, so the output is:\n1234 2235 3136 4137 The last four groups generate four new closures, so the \u0026quot;foo1\u0026quot; part is still cumulative based on the current \u0026quot;x\u0026quot; value, and the cumulative value actually acts in the global variable \u0026quot;x\u0026quot;; the cumulative in foo2 is still inside its own closure, so the output is:\n1236 2237 3238 4238 With this example we distinguish between modifying the closure environment from inside the closure and from outside the closure.\nDelayed Binding Of Closures This problem is every golang newbie will encounter, very puzzling problem; please remember the following sentence: when executing the closure, the closure environment declaration cycle is guaranteed, and will go to the external environment to find the latest closure environment (value), the following example when executing the closure \u0026quot;i\u0026quot; is the closure environment, when executing the closure the latest value is already 10, so all will output 10.\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 var handlers []func() 7 for i := 0; i \u0026lt; 10; i++ { 8 handlers = append(handlers, func() { 9 fmt.Println(i) 10 }) 11 } 12 for _, handler := range handlers { 13 handler() 14 } 15} 16 17// result 1810 1910 2010 2110 2210 2310 2410 2510 2610 2710 The solution is to copy an environment variable in the for loop that is not referenced by the closure, and then use that value instead of the closure environment, with the following modified version:\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 var handlers []func() 7 for i := 0; i \u0026lt; 10; i++ { 8 // a is not a closure environment because it is redeclared each time 9 a := i 10 handlers = append(handlers, func() { 11 fmt.Println(a) 12 }) 13 } 14 for _, handler := range handlers { 15 handler() 16 } 17} 18 19// result 200 211 222 233 244 255 266 277 288 299 In fact, the principle is clear, it is not about the for loop, normal use, defer use will be bound by this principle, the execution of the closure, the closure environment declaration cycle is guaranteed, and will go to the external environment to find the latest closure environment (value)\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 x, y := 1, 2 7 8 defer func(a int) { 9 fmt.Println(a, y) 10 }(x) 11 12 x += 100 13 y += 100 14} 15 16// The output, y, is the closure environment, so the execution of the closure will go to the latest value, while a is not the closure environment, copying the value of x so it is not implicated 171 102 The use of anonymous functions in go routines is a common scenario and suffers from this problem, see the following example:\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func show(val int) { 9 fmt.Println(val) 10} 11 12func main() { 13 values := []int{1, 2, 3, 5} 14 for _, val := range values { 15 go show(val) 16 } 17 time.Sleep(time.Second) 18} 19 20// The four outputs 1,2,3,5 will be output each time, although in a different order, because no anonymous function is used, and it is not a closure 215 221 233 242 The four outputs 1,2,3,5 will be output each time, although in a different order, because no anonymous function is used, and it is not a closure.\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func main() { 9 values := []int{1, 2, 3, 5} 10 for _, val := range values { 11 go func(){ 12 fmt.Println(val) 13 }() 14 } 15 time.Sleep(time.Second) 16} 17 18// output 195 205 215 225 The modification method is the same as inside the for loop example, using passing variables to avoid the closure environment.\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func main() { 9 values := []int{1, 2, 3, 5} 10 for _, val := range values { 11 go func(val int){ 12 fmt.Println(val) 13 }(val) 14 } 15 time.Sleep(time.Second) 16} 17 18// output 191 205 213 222 Closures In Python Modifies The Closure Environment Modifying the closure environment from within Since python is not a declarative language, a \u0026quot;=\u0026quot; eats all, we need to use the nonlocal parameter to explicitly declare the variable as a closure environment, and not a local variable, look at the following example, if the same way as golang directly change, sometimes there will be a problem.\nuse Python list as a closure environment\n1def make_avg(count, total): 2 count = [] 3 4 def avg(v): 5 count.append(v) 6 total = sum(count) 7 print(sum(count)/len(count)) 8 return avg 9 10 11a = make_avg(0, 0) 12a(1) 13a(2) 14a(3) 15 16 17# output 181.0 191.5 202.0 use Python character as a closure environment\n1def make_avg(count, total): 2 count = 0 3 total = 0 4 5 def avg(v): 6 count += 1 7 total += v 8 print(total/count) 9 return avg 10 11 12a = make_avg(0, 0) 13a(1) 14a(2) 15a(3) 16 17 18# error 19Traceback (most recent call last): 20 File \u0026#34;/root/code/linux/blog/aa.py\u0026#34;, line 14, in \u0026lt;module\u0026gt; 21 a(1) 22 File \u0026#34;/root/code/linux/blog/aa.py\u0026#34;, line 7, in avg 23 count += 1 24UnboundLocalError: local variable \u0026#39;count\u0026#39; referenced before assignment That is because python has two types of data, one for mutable data types, one for immutable data types, when passing variable data types use reference passing, this and golang closure directly modified characteristics match, but immutable data types such as the above string will be a problem, because python will take him as a newly generated local variables, so the solution is to use nonlocal to tell the python interpreter, This variable is for the closure environment, so that it can run properly, the correct way to write the following:\n1def make_avg(count, total): 2 count = 0 3 total = 0 4 5 def avg(v): 6 nonlocal count, total 7 count += 1 8 total += v 9 print(total/count) 10 return avg 11 12 13a = make_avg(0, 0) 14a(1) 15a(2) 16a(3) 17 18# output 191.0 201.5 212.0 Closures And Decorators I was going to talk about python decorators, but I decided to leave it for another time because there is already a lot of space here.\nSummary There are many examples above, after reading each example, to understand why, then the closure problem will be solved;\nKeep in mind, cuz the closure is not commonly used, and it is not very practical, you don't have to use closures if the work is not necessary to use. Or may trigger some memory leaks, which is not a small problem.\ntwo main elements of the closure: function and environment closure is a function that extends the scope, it will retain the bindings of free variables (variables not bound in the local scope) that existed when the function was defined, so when the function is called, so the definition scope is not available, but can still use those bindings the use of anonymous functions in golang is actually a closure the closure environment variables can be modified from outside the closure by pointers golang closures delayed binding problem: when executing a closure, the declaration cycle of the closure environment is guaranteed, and it will go to the external environment to find the latest closure environment (value) python closures use nonlocal to declare variables as closure environment, instead of local variables The above analysis is my understanding of the closure, I hope golang, python newcomers can avoid a must-step pit after reading, if you have questions about the environment feel free to comment or email contact, thank you.\nReference Links\nhttps://juejin.cn/post/6844904133208604679\nhttps://www.jianshu.com/p/fa21e6fada70\nhttps://zhuanlan.zhihu.com/p/92634505\n","link":"https://zhangsiming-blyq.github.io/post/golang/closure/","section":"post","tags":["golang","python","English"],"title":"Closures In Golang And Python"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/python/","section":"tags","tags":null,"title":"python"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/python/","section":"categories","tags":null,"title":"python"},{"body":" 近期配置了uber家的zap日志库，觉得性能比较强，展示比较美观，在这里做一个分享，代码在第三部分可以自取。\n为什么不选择原生log? 说起golang如何优雅的打印日志，任何一个golang的初学者大概都是用的原生log库，或者直接fmt.Println()...但是这种方式并不优雅，并且有以下缺点：\n对于基础日志：不能细粒度区分info和debug级别的日志; 对于错误日志: 不支持除了fatal或者panic的普通error级别告知。 log示例 1package main 2 3import \u0026#34;log\u0026#34; 4 5func main() { 6 log.Print(\u0026#34;info or debug\u0026#34;) 7 log.Fatal(\u0026#34;fatal\u0026#34;) 8 log.Panic(\u0026#34;panic\u0026#34;) 9} 10 11// 输出如下 122022/11/23 22:23:32 info or debug 132022/11/23 22:23:32 fatal 14exit status 1 为什么不选择logrus? logrus也是比较常用的自定义日志库，不过因为Go语言是一门强类型的静态语言，而logrus需要知道数据的类型来打印日志，怎么办呢？实现方案是使用反射，这导致大量分配计数。虽然通常不是一个大问题（取决于代码），但是在大规模、高并发的项目中频繁的反射开销影响很大，所以这里不进行采用。\n仓库链接: logrus\nlogrus示例 1package main 2 3import log \u0026#34;github.com/sirupsen/logrus\u0026#34; 4 5var logger = log.New() 6 7func main() { 8 // 这里可以通过WithFields来附加字段 9 logger.WithFields(log.Fields{\u0026#34;testfield\u0026#34;: \u0026#34;test\u0026#34;}).Info(\u0026#34;test info\u0026#34;) 10 logger.Info(\u0026#34;info\u0026#34;) 11 logger.Error(\u0026#34;Error\u0026#34;) 12 logger.Fatal(\u0026#34;Error\u0026#34;) 13 logger.Panic(\u0026#34;Panic\u0026#34;) 14} 15 16// 输出如下 17INFO[0000] test info testfield=test 18INFO[0000] info 19ERRO[0000] Error 20FATA[0000] Error 21exit status 1 聊一聊zap日志库 仓库链接：zap\n1. zap支持的六种日志级别 名称 作用 Debug 打印调试时候的debug日志 Info 正常输出普通信息 Warn 警告，可能有部分出现问题但是不影响程序运行 Error 错误，不会中断程序运行但是程序可能已经不正常 Fatal 输出信息，然后调用os.Exit Panic 调用panic 个人建议如果有错就在初始化检查中可以panic掉，之后程序运行期间就不要碰到小错误就panic掉了，能容忍就抛出Error，这样方便程序员主动停掉服务排查而不是已经工作起来的程序异常挂掉。\n2. zap的性能问题及benchmark 官方github在Performance模块中明确说道:\nFor applications that log in the hot path, reflection-based serialization and string formatting are prohibitively expensive — they're CPU-intensive and make many small allocations. Put differently, using encoding/json and fmt.Fprintf to log tons of interface{}s makes your application slow.\nZap takes a different approach. It includes a reflection-free, zero-allocation JSON encoder, and the base Logger strives to avoid serialization overhead and allocations wherever possible. By building the high-level SugaredLogger on that foundation, zap lets users choose when they need to count every allocation and when they'd prefer a more familiar, loosely typed API.\n也就是说，基于反射的序列化，或者字符串格式化这种是很吃cpu资源的，严重了会导致程序变慢(logrus存在这个问题); zap这里定义了一个无反射的，无分配的json encoder来优化这一部分，并且在此基础上提供了Sugar可以舍弃部分性能换取更简单的配置这一特点，我们下面的部分会演示。\n通过benckmark可以看出, zap和zap-sugar在性能上还是非常有优势的!\n3. 代码展示 下面分段展示完整代码，第一部分是各种包的导入；值得注意的是定义了默认的DefaultLog，用于把Info级别以上的日志人性化可读地输出到控制台; 还支持通过给InitLogger函数传递参数自定义想要的日志形式，支持(假设库名叫logger)：\n初始化方式 日志形式 logger.DefaultLog 人性化输出到控制台, 输出高于Info级别的日志 logger.InitLogger(\u0026quot;\u0026quot;, \u0026quot;console\u0026quot;, \u0026quot;debug\u0026quot;).Sugar() 人性化输出到控制台, 输出高于Debug级别的日志 logger.InitLogger(\u0026quot;\u0026quot;, \u0026quot;file\u0026quot;, \u0026quot;debug\u0026quot;).Sugar() 人性化输出到文件(默认当前目录下的log目录，会自动创建), 输出高于Debug级别的日志 logger.InitLogger(\u0026quot;json\u0026quot;, \u0026quot;console\u0026quot;, \u0026quot;debug\u0026quot;).Sugar() json格式输出到控制台, 输出高于Debug级别的日志 1package logger 2 3import ( 4\t\u0026#34;os\u0026#34; 5 6\t\u0026#34;github.com/natefinch/lumberjack\u0026#34; 7\t\u0026#34;go.uber.org/zap\u0026#34; 8\t\u0026#34;go.uber.org/zap/zapcore\u0026#34; 9) 10 11var ( 12\tMyLogger = InitLogger() 13\tDefaultLog = MyLogger.Sugar() 14) 15 16func InitLogger(logArgs ...string) *zap.Logger { 17 ... 18} InitLogger函数中大概分为四个部分:\n接收参数初始化变量 生成encoder 定义日志级别和输出形式 根据指定配置生成并返回日志实例 代码 1func InitLogger(logArgs ...string) *zap.Logger { 2\tvar logger *zap.Logger 3\tvar coreArr []zapcore.Core 4\tvar format, logType, priority string 5 6\t// get the parameters 7\tswitch { 8\tcase len(logArgs) \u0026gt;= 3: 9\tformat = logArgs[0] 10\tlogType = logArgs[1] 11\tpriority = logArgs[2] 12\tcase len(logArgs) == 2: 13\tformat = logArgs[0] 14\tlogType = logArgs[1] 15\tcase len(logArgs) == 1: 16\tformat = logArgs[0] 17\t} 18 19\t// get encoder 20\tencoderConfig := zap.NewProductionEncoderConfig() 21\tencoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder // time format 22\tencoderConfig.EncodeLevel = zapcore.CapitalColorLevelEncoder // use different color for various log levels 23\t// uncomment next line to show full path of the code 24\t// encoderConfig.EncodeCaller = zapcore.FullCallerEncoder 25\t// NewJSONEncoder() for json，NewConsoleEncoder() for normal 26\tif format == \u0026#34;\u0026#34; { 27\tformat = \u0026#34;normal\u0026#34; 28\t} 29\tencoder := zapcore.NewConsoleEncoder(encoderConfig) 30\tif format == \u0026#34;json\u0026#34; { 31\tencoder = zapcore.NewJSONEncoder(encoderConfig) 32\t} 33 34\t// log levels 35\terrorPriority := zap.LevelEnablerFunc(func(lev zapcore.Level) bool { 36\treturn lev \u0026gt;= zap.ErrorLevel 37\t}) 38\tinfoPriority := zap.LevelEnablerFunc(func(lev zapcore.Level) bool { 39\treturn lev \u0026lt; zap.ErrorLevel \u0026amp;\u0026amp; lev \u0026gt;= zap.InfoLevel 40\t}) 41\tdebugPriority := zap.LevelEnablerFunc(func(lev zapcore.Level) bool { 42\treturn lev \u0026lt; zap.InfoLevel \u0026amp;\u0026amp; lev \u0026gt;= zap.DebugLevel 43\t}) 44\tif logType == \u0026#34;\u0026#34; { 45\tlogType = \u0026#34;console\u0026#34; 46\t} 47\t// writeSyncer for debug file 48\tdebugFileWriteSyncer := zapcore.AddSync(\u0026amp;lumberjack.Logger{ 49\tFilename: \u0026#34;./log/debug.log\u0026#34;, // will create if not exist 50\tMaxSize: 128, // max size for log file, unit:MB 51\tMaxBackups: 3, // max backup\u0026#39;s count 52\tMaxAge: 10, // max reserved days for log file 53\tCompress: false, // whether to compress or not 54\t}) 55\tdebugFileCore := zapcore.NewCore(encoder, os.Stdout, debugPriority) 56\tif logType == \u0026#34;file\u0026#34; { 57\tdebugFileCore = zapcore.NewCore(encoder, zapcore.NewMultiWriteSyncer(debugFileWriteSyncer, zapcore.AddSync(os.Stdout)), debugPriority) 58\t} 59\t// writeSyncer for info file 60\tinfoFileWriteSyncer := zapcore.AddSync(\u0026amp;lumberjack.Logger{ 61\tFilename: \u0026#34;./log/info.log\u0026#34;, 62\tMaxSize: 128, 63\tMaxBackups: 3, 64\tMaxAge: 10, 65\tCompress: false, 66\t}) 67\tinfoFileCore := zapcore.NewCore(encoder, os.Stdout, infoPriority) 68\tif logType == \u0026#34;file\u0026#34; { 69\tinfoFileCore = zapcore.NewCore(encoder, zapcore.NewMultiWriteSyncer(infoFileWriteSyncer, zapcore.AddSync(os.Stdout)), infoPriority) 70\t} 71\t// writeSyncer for error file 72\terrorFileWriteSyncer := zapcore.AddSync(\u0026amp;lumberjack.Logger{ 73\tFilename: \u0026#34;./log/error.log\u0026#34;, 74\tMaxSize: 128, 75\tMaxBackups: 5, 76\tMaxAge: 10, 77\tCompress: false, 78\t}) 79\terrorFileCore := zapcore.NewCore(encoder, os.Stdout, errorPriority) 80\tif logType == \u0026#34;file\u0026#34; { 81\terrorFileCore = zapcore.NewCore(encoder, zapcore.NewMultiWriteSyncer(errorFileWriteSyncer, zapcore.AddSync(os.Stdout)), errorPriority) 82\t} 83 84\tswitch priority { 85\tcase \u0026#34;\u0026#34;: 86\tcoreArr = append(coreArr, infoFileCore) 87\tcoreArr = append(coreArr, errorFileCore) 88\tcase \u0026#34;info\u0026#34;: 89\tcoreArr = append(coreArr, infoFileCore) 90\tcoreArr = append(coreArr, errorFileCore) 91\tcase \u0026#34;error\u0026#34;: 92\tcoreArr = append(coreArr, errorFileCore) 93\tcase \u0026#34;debug\u0026#34;: 94\tcoreArr = append(coreArr, debugFileCore) 95\tcoreArr = append(coreArr, infoFileCore) 96\tcoreArr = append(coreArr, errorFileCore) 97\t} 98\tlogger = zap.New(zapcore.NewTee(coreArr...), zap.AddCaller()) //zap.AddCaller() is to show the line number 99\treturn logger 100} 4. 效果演示 1package main 2 3import ( 4\t\u0026#34;xxx/pkg/logger\u0026#34; 5) 6 7// var log = logger.DefaultLog 8var log = logger.InitLogger(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;debug\u0026#34;).Sugar() 9 10func main() { 11\tlog.Debug(\u0026#34;debug\u0026#34;) 12\tlog.Info(\u0026#34;info\u0026#34;) 13\tlog.Warn(\u0026#34;warn\u0026#34;) 14\tlog.Error(\u0026#34;error\u0026#34;) 15\tlog.Fatal(\u0026#34;fatal\u0026#34;) 16\tlog.Panic(\u0026#34;panic\u0026#34;) 17} 输出 在性能开销很小的情况下，还可以清晰的展示日志级别，并且使用颜色区分, 十分强大美观，欢迎读者拷贝并使用我个人这份配置，有疑问我们下面评论区随时沟通探讨。\n","link":"https://zhangsiming-blyq.github.io/post/golang/gozap/","section":"post","tags":["golang","中文"],"title":"使用zap打造你的golang日志库"},{"body":"Requirements There is a integer array arr and a window of size w that slides from the leftmost to the rightmost part of the array, with the window sliding one position at a time to the right. For example, the array is [4,3,5,4,3,3,6,7], and the window size is 3.\nIf the length of the array is n and the window size is w, then a total of n-w+1 window maxima are generated. Please implement a function:\nInput: a integer array arr with window size w output: an array res of length n-w+1, res[i] denotes the maximum value in each window state, requiring time complexity O(N*w) Solution 整体逻辑：\n创建一个双端数组，我们需要根据不同情况从两端分别push和pop 核心就是循环这个arr，把最大的值在arr中的下标放到双端数组的最左端(对应下文程序中\u0026quot;for !bq.Empty() \u0026amp;\u0026amp; arr[i] \u0026gt; arr[bq.Back().(int)] {}\u0026quot;的处理) 当窗口走过对应数值区域的时候，把相应的数据进行过期(对应下文程序中\u0026quot;if bq.Front().(int) == i-w {}\u0026quot;) 注意，因为要输出长度为 n-w+1, 所以循环当\u0026quot;i \u0026gt;= w -1\u0026quot;的时候，才开始输出结果到res中 Overall logic:\ncreate a double-ended array, we need to push and pop from both ends according to different situations The core is to loop through the arr and put the largest value subscript in arr at the leftmost end of the double-ended array (corresponding to the following procedure \u0026quot;for !bq.Empty() \u0026amp;\u0026amp; arr[i] \u0026gt; arr[bq. (int)] {}\u0026quot;) expire the corresponding data when the window goes through the corresponding value area (corresponding to the following program \u0026quot;if bq.Front(). (int) == i-w {}\u0026quot;) Note that since the length of the output is n-w+1, the loop starts when \u0026quot;i \u0026gt;= w -1\u0026quot; before outputting the result into res Golang Implementation 1package main 2 3func Getmaxwindow(arr []int, w int) (res []int) { 4\tres = []int{} 5\t// 1. create a bidirectional queue to store the result 6\tbq := newCustomQueue() 7\t// 2. for i \u0026lt; length(arr) 8\tfor i := 0; i \u0026lt; len(arr); i++ { 9\t// 3. for !empty or value(in queue) \u0026gt; value(in bqueue), popback bqueue 10\tfor !bq.Empty() \u0026amp;\u0026amp; arr[i] \u0026gt; arr[bq.Back().(int)] { 11\tbq.PopBack() 12\t} 13\t// 4. pushback id(in queue) 14\tbq.Pushback(i) 15\t// 5. if bqueue\u0026#39;s id \u0026gt;= i - w, expire the front value(in bqueue) 16\tif bq.Front().(int) == i-w { 17\tbq.PopFront() 18\t} 19\t// 6. record results to res slice 20\tif i \u0026gt;= w-1 { 21\tres = append(res, arr[bq.Front().(int)]) 22\t} 23\t} 24\treturn res 25} Test Cases 1package main 2 3import ( 4\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 5\t\u0026#34;testing\u0026#34; 6) 7 8func TestGetmaxwindow(t *testing.T) { 9\ttests := []struct { 10\tname string 11 12\tarr []int 13\tw int 14 15\twantRes []int 16\t}{ 17\t{ 18\tname: \u0026#34;getmaxwindow\u0026#34;, 19\tarr: []int{4, 3, 5, 4, 3, 3, 6, 7}, 20\tw: 3, 21\twantRes: []int{5, 5, 5, 4, 6, 7}, 22\t}, 23\t{ 24\tname: \u0026#34;getmaxwindow1\u0026#34;, 25\tarr: []int{4, 3, 5, 4, 3, 3, 6, 7}, 26\tw: 4, 27\twantRes: []int{5, 5, 5, 6, 7}, 28\t}, 29\t{ 30\tname: \u0026#34;getmaxwindow2\u0026#34;, 31\tarr: []int{4, 3, 9, 8, 3, 1, 6, 7}, 32\tw: 3, 33\twantRes: []int{9, 9, 9, 8, 6, 7}, 34\t}, 35\t} 36\tfor _, tt := range tests { 37\tt.Run(tt.name, func(t *testing.T) { 38\t// test case 39\tres := Getmaxwindow(tt.arr, tt.w) 40\tassert.Equal(t, tt.wantRes, res) 41\t}) 42\t} 43} Result:\n1$ go test -run ^TestSortStark$ . -v 2$ go test -run ^TestGetmaxwindow$ . -v 3=== RUN TestGetmaxwindow 4=== RUN TestGetmaxwindow/getmaxwindow 5=== RUN TestGetmaxwindow/getmaxwindow1 6=== RUN TestGetmaxwindow/getmaxwindow2 7--- PASS: TestGetmaxwindow (0.00s) 8 --- PASS: TestGetmaxwindow/getmaxwindow (0.00s) 9 --- PASS: TestGetmaxwindow/getmaxwindow1 (0.00s) 10 --- PASS: TestGetmaxwindow/getmaxwindow2 (0.00s) 11PASS The test is problem-free and the output is as expected.\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/6/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | Generate an array of window maximums"},{"body":" kubernetes各个组件都是加密通信的, 那么都有哪些证书、各个证书怎么交互、这些证书什么时候过期，这个就变得至关重要; 本文引用了一些其他网络内容(均已附上原文链接)，并适当补充完善，用于让新手完善熟悉kubernetes证书体系(如有侵权联系邮箱可以删除)。\n一、数字证书原理 1.1 传统非对称加密 1message --\u0026gt; (公钥加密) --\u0026gt; || 传输 || --\u0026gt; (私钥解密) --\u0026gt; message 注意:\n1.这里与数字证书认证相反，是公钥加密私钥解密\n2.公钥私钥需要是一个秘钥对\n1.2 哈希函数 1message --\u0026gt; H(message) --\u0026gt; Hash message 处理加入一个随机数，然后得出结果(加盐); 可以有效缓解在输入值是一个有效的集合，哈希值也是固定长度被别人‘试’出来的几率\n1message --\u0026gt; H(R|message) --\u0026gt; Hash message 1.3 数字证书 1.3.1 数字签名 数字签名；把数据根据私钥/哈希进行加密，然后必须要对应的公钥来进行解密认证才能确保数据安全。前半句的加密过程就叫做 '数字签名'\n1.3.2 数字证书认证过程 Alice 想要通过证书加密让 Bob 安全读到自己的信息流程如下：\nAlice 在本地生成 Private Key 和 CSR（Certificate Signing Request）。CSR 中包含了 Alice 的公钥和姓名，机构、地址等身份信息。 Alice 使用该 CSR 向证书机构发起数字证书申请。 证书机构验证 Alice 的身份后，使用 CSR 中的信息生成数字证书，并使用自己的 CA 根证书对应的私钥对该证书签名。 Alice 使用自己的 Private Key 对合同进行签名，然后将签名后的合同和自己的证书一起并发送给 Bob。 Bob 使用操作系统中自带的证书机构根证书中的公钥来验证 Alice 证书中的签名，以确认 Alice 的身份和公钥。(使用内置根证书确认身份并获取Alice证书) Alice 的证书验证成功后，Bob 使用 Alice 证书中的公钥来验证合同中数字签名。(使用刚刚获取的Alice证书(公钥)解析Alice发送的内容) 合同数字签名通过验证，可以证明该合同为 Alice 本人发送，并且中间未被第三方篡改过。 注意：\n1.自签发证书：证书签发商和证书持有者是同一个人，缺点是没有人能告诉你\u0026quot;这个人就是这个人(我就是我)\u0026quot;; 所以需要上面的信任证书机构的介入，多一环进行认证证明\n2.证书链：但是信任的证书机构的根证书是很机密的，一旦被盗取可能会导致很多人都无法证明\u0026quot;我就是我\u0026quot;, 所以一般会引入一些中间证书商，多一层上面的解析循环；这样也保证了万一中间商证书泄露，不至于全部使用证书机构的人都陷于危险之中\n3.证书签发一般都是有一定时期的, 过期了就如同废纸\n参考链接：\nhttps://zhaohuabing.com/post/2020-03-19-pki/\n二、双向 TLS 认证原理 双向 TLS 认证需要的场景是，服务端和客户端都需要确认，这样就是正反都走一遍上面的流程，来完成双向的数据加密，保证双向的数据安全\n参考链接：\nhttps://medium.com/sitewards/the-magic-of-tls-x509-and-mutual-authentication-explained-b2162dec4401/\n三、Kubernetes 中的证书工作机制 3.1 Kubernetes 中使用到的主要证书 etcd 集群中各个节点之间相互通信使用的证书。由于一个 etctd 节点既为其他节点提供服务，又需要作为客户端访问其他节点，因此该证书同时用作服务器证书和客户端证书 etcd 集群向外提供服务使用的证书。该证书是服务器证书 kube-apiserver 作为客户端访问 etcd 使用的证书。该证书是客户端证书 kube-apiserver 对外提供服务使用的证书。该证书是服务器证书 kube-controller-manager 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书 kube-scheduler 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书 kube-proxy 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书 kubelet 作为客户端访问 kube-apiserver 使用的证书,该证书是客户端证书 管理员用户通过 kubectl 访问 kube-apiserver 使用的证书,该证书是客户端证书 kubelet 对外提供服务使用的证书。该证书是服务器证书 kube-apiserver 作为客户端访问 kubelet 采用的证书。该证书是客户端证书 kube-controller-manager 用于生成和验证 service-account token 的证书。该证书并不会像其他证书一样用于身份认证，而是将证书中的公钥/私钥对用于 service account token 的生成和验证。kube-controller-manager 会用该证书的私钥来生成 service account token，然后以 secret 的方式加载到 pod 中。pod 中的应用可以使用该 token 来访问 kube-apiserver， kube-apiserver 会使用该证书中的公钥来验证请求中的 token 注意:\n只有当你运行 kube-proxy 并要支持 扩展 API 服务器 时，才需要 front-proxy 证书 3.2 etcd 证书 1$ ssh 10.20.11.120 2$ sudo systemctl status etcd 3● etcd.service - etcd docker wrapper 4 Loaded: loaded (/etc/systemd/system/etcd.service; enabled; vendor preset: enabled) 5 Active: active (running) since Mon 2020-08-03 15:42:36 CST; 1 months 18 days ago 6$ cat /etc/etcd.env | tail -13 7 8# TLS settings 9ETCD_TRUSTED_CA_FILE=/etc/ssl/etcd/ssl/ca.pem # etcd验证访问 etcd 服务器的客户端证书的 CA 根证书, 服务端签名证书和服务端私钥 10ETCD_CERT_FILE=/etc/ssl/etcd/ssl/member-ip-10-20-11-120.pem 11ETCD_KEY_FILE=/etc/ssl/etcd/ssl/member-ip-10-20-11-120-key.pem 12ETCD_CLIENT_CERT_AUTH=true 13 14ETCD_PEER_TRUSTED_CA_FILE=/etc/ssl/etcd/ssl/ca.pem # etcd peer之间验证访问 etcd 服务器的客户端证书的 CA 根证书, 服务端签名证书和服务端私钥 15ETCD_PEER_CERT_FILE=/etc/ssl/etcd/ssl/member-ip-10-20-11-120.pem 16ETCD_PEER_KEY_FILE=/etc/ssl/etcd/ssl/member-ip-10-20-11-120-key.pem 17ETCD_PEER_CLIENT_CERT_AUTH=True 18 19# 验证etcd证书过期时间 20$ sudo openssl x509 -in /etc/ssl/etcd/ssl/ca.pem -noout -dates 21notBefore=Aug 6 05:07:43 2019 GMT 22notAfter=Jul 13 05:07:43 2119 GMT 3.3 kube-apiserver 证书 1$ ssh 10.20.11.120 2$ cd /etc/kubernetes 3$ cat manifests/kube-apiserver.yaml 4apiVersion: v1 5kind: Pod 6metadata: 7 creationTimestamp: null 8 labels: 9 component: kube-apiserver 10 tier: control-plane 11 name: kube-apiserver 12 namespace: kube-system 13spec: 14 containers: 15 - command: 16 - kube-apiserver 17 - --advertise-address=10.20.11.120 18 - --etcd-cafile=/etc/ssl/etcd/ssl/ca.pem # 用于验证 etcd 客户端证书的 CA 根证书, 用于访问 etcd 的客户端证书和私钥 19 - --etcd-certfile=/etc/ssl/etcd/ssl/node-ip-10-20-11-120.pem 20 - --etcd-keyfile=/etc/ssl/etcd/ssl/node-ip-10-20-11-120-key.pem 21 - --kubelet-client-certificate=/etc/kubernetes/ssl/apiserver-kubelet-client.crt # 用于访问 kubelet 的客户端证书和私钥 22 - --kubelet-client-key=/etc/kubernetes/ssl/apiserver-kubelet-client.key 23 - --proxy-client-cert-file=/etc/kubernetes/ssl/front-proxy-client.crt # 只有当你运行 kube-proxy 并要支持 扩展 API 服务器 时，才需要 front-proxy 证书 24 - --proxy-client-key-file=/etc/kubernetes/ssl/front-proxy-client.key 25 - --client-ca-file=/etc/kubernetes/ssl/ca.crt # 用于验证访问 kube-apiserver 的客户端的证书的 CA 根证书 26 - --service-account-key-file=/etc/kubernetes/ssl/sa.pub # 用于验证 service account token 的公钥 27 - --tls-cert-file=/etc/kubernetes/ssl/apiserver.crt # 用于对外提供服务的服务器证书和私钥 28 - --tls-private-key-file=/etc/kubernetes/ssl/apiserver.key 29 ... 3.4 controller-manager, kubelet, scheduler 证书 上面三个 apiserver 的客户端组件的证书都写在了对应的 KUBECONFIG 中,名为 controller-manager.conf, kubelet.conf, scheduler.conf, 就不一一展示, 随便列举一个如下:\n1# 包含验证apiserver证书的ca证书, 还有请求时候的看客户端证书和私钥 2$ cat scheduler.conf 3apiVersion: v1 4clusters: 5- cluster: 6 certificate-authority-data: ca证书 7 server: https://10.20.11.120:6443 8 name: kubernetes 9contexts: 10- context: 11 cluster: kubernetes 12 user: system:kube-scheduler 13 name: system:kube-scheduler@kubernetes 14current-context: system:kube-scheduler@kubernetes 15kind: Config 16preferences: {} 17users: 18- name: system:kube-scheduler 19 user: 20 client-certificate-data: server证书 21 client-key-data: 秘钥 3.5 Service Account 秘钥对 Service account 主要被 pod 用于访问 kube-apiserver。 在为一个 pod 指定了 service account 后，kubernetes 会为该 service account 生成一个 JWT token，并使用 secret 将该 service account token 挂载到 pod 上。pod 中的应用可以使用 service account token 来访问 api server。service account 证书被用于生成和验证 service account token。\n注意:\nService account加密过程是文章开头说的\u0026quot;非对称加密\u0026quot;, 也就是说只是controller-manager私钥加密数据, 然后kube-apiserver的公钥进行解密而已 由于是非对称加密, 也就是说没有\u0026quot;双向 tls 认证\u0026quot; istio的做法就是为每个 service account 生成一个证书, 之后就可以\u0026quot;双向 tls 认证\u0026quot; 1$ cat manifests/kube-controller-manager.yaml | grep service-account 2 - --service-account-private-key-file=/etc/kubernetes/ssl/sa.key 3 - --use-service-account-credentials=true 4$ cat manifests/kube-apiserver.yaml | grep service-account 5 - --service-account-key-file=/etc/kubernetes/ssl/sa.pub 四、监控kubernetes证书 比较好用的是开源的x509 exporter\n开源链接：\nhttps://github.com/enix/x509-certificate-exporter/\n1$ gc https://github.com/enix/x509-certificate-exporter.git 2$ cd deploy/charts/x509-certificate-exporter 3$ vim values.yaml 4... 5 daemonSets: 6 master: 7 nodeSelector: 8 \u0026#34;node-role.kubernetes.io/controlplane\u0026#34;: \u0026#34;true\u0026#34; 9 tolerations: 10 - effect: NoSchedule 11 operator: Exists 12 - effect: NoExecute 13 operator: Exists 14 watchDirectories: 15 - /etc/kubernetes/ssl/ 16 nodes: 17 tolerations: 18 - effect: NoSchedule 19 operator: Exists 20 watchKubeconfFiles: 21 - /etc/kubernetes/ssl/kubecfg-kube-node.yaml 22 - /etc/kubernetes/ssl/kubecfg-kube-proxy.yaml 23 24$ helm install x509-certificate-exporter . 25$ k get daemonset 26NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE 27x509-certificate-exporter-master 3 3 3 3 3 node-role.kubernetes.io/controlplane=true 18d 28x509-certificate-exporter-nodes 202 202 197 202 197 \u0026lt;none\u0026gt; 18d 29... 在daemonSet配置里面支持将核心的控制节点证书路径，或者kubeconfig文件写进去，然后部署即可；开源社区提供配套dashboard:\nFAQ 1. 在安装 Kubernetes 时，我们需要为每一个工作节点上的 Kubelet 分别生成一个证书。由于工作节点可能很多，手动生成 Kubelet 证书的过程会比较繁琐怎么办? Kubernetes 提供了一个 certificates.k8s.io API，可以使用配置的 CA 根证书来签发用户证书 Kubernetes 提供了 TLS bootstrapping 的方式来简化 Kubelet 证书的生成过程 过程如下:(需要 apiserver 启用--enable-bootstrap-token-auth)\n调用 kube-apiserver 生成一个 bootstrap token 将该 bootstrap token 写入到一个 kubeconfig 文件中，作为 kubelet 调用 kube-apiserver 的客户端验证方式 通过 --bootstrap-kubeconfig 启动参数将 bootstrap token 传递给 kubelet 进程 Kubelet 采用 bootstrap token 调用 kube-apiserver API，生成自己所需的服务器和客户端证书 证书生成后，Kubelet 采用生成的证书和 kube-apiserver 进行通信，并删除本地的 kubeconfig 文件，以避免 bootstrap token 泄漏风险 参考链接:\nhttps://zhaohuabing.com/post/2020-05-19-k8s-certificate/\nhttps://kubernetes.io/zh/docs/tasks/tls/managing-tls-in-a-cluster/\n2. 如何升级 kubernetes 证书但是不让 serviceaccout 轮换？ 我们都知道 serviceaccount 的 token 是依赖于 sa.key 和 sa.pub 的，也就是说如果这俩秘钥更换了，所有的 serviceaccout 就都失效了，会重新创建(kube-system 命名空间的会自动轮换，其他 ns 的需要手动); 但是如果只是更换证书的话，其实是不需要更换 sa 秘钥对的，因为 sa 秘钥对采用的是\u0026quot;非对称加密\u0026quot;, 也就是说永不过期，除非删除秘钥对；\n事实上我们只要手动更换其他证书即可：\n1$ cp -R /etc/kubernetes/ssl /etc/kubernetes/ssl.backup 2$ cp /etc/kubernetes/admin.conf /etc/kubernetes/admin.conf.backup 3$ cp /etc/kubernetes/controller-manager.conf /etc/kubernetes/controller-manager.conf.backup 4$ cp /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.backup 5$ cp /etc/kubernetes/scheduler.conf /etc/kubernetes/scheduler.conf.backup 6 7$ kubeadm alpha certs renew apiserver-kubelet-client 8$ kubeadm alpha certs renew apiserver 9$ kubeadm alpha certs renew front-proxy-client 10$ kubeadm alpha kubeconfig user --client-name system:kube-controller-manager \u0026gt; /etc/kubernetes/controller-manager.conf 11$ kubeadm alpha kubeconfig user --client-name system:kube-scheduler \u0026gt; /etc/kubernetes/scheduler.conf 12$ kubeadm alpha kubeconfig user --client-name system:node:{nodename} --org system:nodes \u0026gt; /etc/kubernetes/kubelet.conf 13 14$ kubeadm alpha kubeconfig user --client-name kubernetes-admin --org system:masters \u0026gt; /etc/kubernetes/admin.conf 15$ cp /etc/kubernetes/admin.conf ~/.kube/config 上述过程每个 master 都需要做(如果有多个 master), 最后重启基础组件即可(嫌麻烦可以直接 master 节点关机重启)\n参考链接：\nhttps://github.com/kubernetes-sigs/kubespray/issues/5464/\n3. kubernetes kubelet 证书自动 renew 1# kubelet配置 2--feature-gates=RotateKubeletServerCertificate=true 3--feature-gates=RotateKubeletClientCertificate=true 4# 1.8版本以上包含1.8都支持证书更换自动重载，以下版本只能手动重启服务 5--rotate-certificates 6 7 8# kube-controller-manager配置 9# 证书有效期为10年 10--experimental-cluster-signing-duration=87600h0m0s 11--feature-gates=RotateKubeletServerCertificate=true 创建自动批准相关 CSR 请求的 ClusterRole:\n1kind: ClusterRole 2apiVersion: rbac.authorization.k8s.io/v1 3metadata: 4 name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver 5rules: 6- apiGroups: [\u0026#34;certificates.k8s.io\u0026#34;] 7 resources: [\u0026#34;certificatesigningrequests/selfnodeserver\u0026#34;] 8 verbs: [\u0026#34;create\u0026#34;] 自动批准 kubelet-bootstrap 用户 TLS bootstrapping 首次申请证书的 CSR 请求\n1kubectl create clusterrolebinding node-client-auto-approve-csr --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --user=kubelet-bootstrap 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求\n1kubectl create clusterrolebinding node-client-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求\n1kubectl create clusterrolebinding node-server-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes 参考链接：\nhttps://www.leiyawu.com/2020/10/11/Untitled/\n","link":"https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-certificate/","section":"post","tags":["kubernetes","中文"],"title":"谈谈kubernetes 证书认证那些事儿"},{"body":" ingress在将流量发往后端的时候是不经过kube-proxy的，ingress controller会直接和kube-apiserver进行交互，然后获取pod endpoints和service的对应关系，进行轮询，负载均衡到后端节点。\n一、验证试验 从集群中删除kube-proxy，查看通过ingress的方式是否可以访问成功?\n1# 实验中选择的是\u0026#34;iptables模式的kube-proxy\u0026#34; 2# 首先关闭kube-proxy 3$ sudo systemctl stop kube-proxy 4 5# 查看服务，ClusterIP的端口是8080，NodePort的端口是30948 6$ ks 7NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 8example-test NodePort 10.0.0.226 \u0026lt;none\u0026gt; 8080:30948/TCP 18h 9traefik NodePort 10.0.0.85 \u0026lt;none\u0026gt; 9000:30001/TCP,80:30002/TCP,443:31990/TCP 19h 10 11# 查看与\u0026#34;10.0.0.226\u0026#34;有关的iptables条目，得知访问\u0026#34;10.0.0.226\u0026#34;且目的端口是\u0026#34;8080\u0026#34;的流量会发送给KUBE-SVC-KNYNFDNL67C7KAZZ链 12$ sudo iptables -S -t nat | grep 10.0.0.226 13-A KUBE-SERVICES ! -s 10.0.0.0/24 -d 10.0.0.226/32 -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080 cluster IP\u0026#34; -m tcp --dport 8080 -j KUBE-MARK-MASQ 14-A KUBE-SERVICES -d 10.0.0.226/32 -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080 cluster IP\u0026#34; -m tcp --dport 8080 -j KUBE-SVC-KNYNFDNL67C7KAZZ 15 16# 查看KUBE-SVC-KNYNFDNL67C7KAZZ链发现，采用的是\u0026#34;--probability\u0026#34;策略，进行后端两个pod的负载均衡 17$ sudo iptables -S -t nat | grep KUBE-SVC-KNYNFDNL67C7KAZZ 18-N KUBE-SVC-KNYNFDNL67C7KAZZ 19-A KUBE-NODEPORTS -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080\u0026#34; -m tcp --dport 30948 -j KUBE-SVC-KNYNFDNL67C7KAZZ 20-A KUBE-SERVICES -d 10.0.0.226/32 -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080 cluster IP\u0026#34; -m tcp --dport 8080 -j KUBE-SVC-KNYNFDNL67C7KAZZ 21-A KUBE-SVC-KNYNFDNL67C7KAZZ -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080\u0026#34; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-O6MCO5C4JB4A4VEJ 22-A KUBE-SVC-KNYNFDNL67C7KAZZ -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080\u0026#34; -j KUBE-SEP-KREF3VGT6NHFYTVH 23 24# 我们再看后面转发的\u0026#34;KUBE-SEP-KREF3VGT6NHFYTVH\u0026#34;, 得知这一步就发送给了真实的pod 25$ sudo iptables -t nat -L KUBE-SEP-KREF3VGT6NHFYTVH --line-numbers 26Chain KUBE-SEP-KREF3VGT6NHFYTVH (1 references) 27num target prot opt source destination 281 KUBE-MARK-MASQ all -- 10.244.2.4 anywhere /* traffic-dispatcher/example-test:port-8080 */ 292 DNAT tcp -- anywhere anywhere /* traffic-dispatcher/example-test:port-8080 */ tcp to:10.244.2.4:8080 30 31# 现在我们要模拟不能走kube-proxy添加的规则访问到服务，于是我们删除刚刚\u0026#34;50%/50%\u0026#34;规则进行负载均衡转发的那两条规则(kube-proxy本质就是负载均衡) 32$ sudo iptables -t nat -L KUBE-SVC-KNYNFDNL67C7KAZZ --line-numbers 33Chain KUBE-SVC-KNYNFDNL67C7KAZZ (2 references) 34num target prot opt source destination 351 KUBE-SEP-O6MCO5C4JB4A4VEJ all -- anywhere anywhere /* traffic-dispatcher/example-test:port-8080 */ statistic mode random probability 0.50000000000 362 KUBE-SEP-KREF3VGT6NHFYTVH all -- anywhere anywhere /* traffic-dispatcher/example-test:port-8080 */ 37 38# 删除规则 39$ sudo iptables -t nat -D KUBE-SVC-KNYNFDNL67C7KAZZ 1 2 现在以ClusterIP+Port的方式访问服务应该走不通了，测试访问:\n1$ ks 2NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 3example-test NodePort 10.0.0.226 \u0026lt;none\u0026gt; 8080:30948/TCP 18h 4traefik NodePort 10.0.0.85 \u0026lt;none\u0026gt; 9000:30001/TCP,80:30002/TCP,443:31990/TCP 19h 5$ curl 10.0.0.226:8080 6访问失败 7$ curl 10.20.13.90:30948 8访问失败 9$ curl 10.20.13.90:30002 -H \u0026#39;Host:testfile.shannonai.com\u0026#39; 10访问成功, 由此证明ingress是不走kube-proxy的! 二、结论 kube-proxy的工作是附加一些转发规则，所以说单单的\u0026quot;systemctl stop kube-proxy\u0026quot;是不会影响已经存在的规则的，也就是原来可以走通的服务只要没有变化，就依旧可以走通；只是我们再添加新的服务，就不能走通了(因为没有kube-proxy为我们添加这些规则了); 另外多节点的集群，只要其他节点的kube-proxy是ok的，就已经可以从其他节点访问服务; 我们做了上述那么多破坏如果想要恢复的话，也只是需要重新\u0026quot;systemctl restart kube-proxy\u0026quot;就会自动把我们破坏掉的规则加回来\n如何理解我们集群的ClusterIP和他对应的端口？我们了解过kube-proxy的规则了之后就很明显的可以得出结论：\n1）pod的ip是pod所处的networkns的真实ip，通过veth和网桥和我们宿主机的真实ip通信\n2）clusterip仅仅为kube-proxy的iptables或者ipvs规则匹配所用，也就是并不会出现在本机进行路由\n1# 本机的路由表只能看到真实的节点ip段和网络插件附加的pod ip段, 没有clusterip的地址段 2$ route -n 3内核 IP 路由表 4目标 网关 子网掩码 标志 跃点 引用 使用 接口 50.0.0.0 10.20.13.1 0.0.0.0 UG 100 0 0 ens5 610.20.13.0 0.0.0.0 255.255.255.0 U 0 0 0 ens5 710.20.13.1 0.0.0.0 255.255.255.255 UH 100 0 0 ens5 810.244.1.0 10.244.1.0 255.255.255.0 UG 0 0 0 flannel.1 910.244.2.0 10.244.2.0 255.255.255.0 UG 0 0 0 flannel.1 10172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 11 12# iptables和ipvs的规则中可以看到clusterip的地址段 13$ sudo iptables -S -t nat | grep 10.0.0.226 14-A KUBE-SERVICES ! -s 10.0.0.0/24 -d 10.0.0.226/32 -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080 cluster IP\u0026#34; -m tcp --dport 8080 -j KUBE-MARK-MASQ 15-A KUBE-SERVICES -d 10.0.0.226/32 -p tcp -m comment --comment \u0026#34;traffic-dispatcher/example-test:port-8080 cluster IP\u0026#34; -m tcp --dport 8080 -j KUBE-SVC-KNYNFDNL67C7KAZZ 由此得出，pod的targetport在对于不同的pod的情况下是可以重复的；nodeport如果是处于同一个节点是不能重复的；clusterip在clusterip的地址不同(也就是iptables和ipvs的规则中不冲突/或者简单理解为不同服务)的情况下是可以重复的\n参考链接: https://xuxinkun.github.io/2016/07/22/kubernetes-proxy/\n","link":"https://zhangsiming-blyq.github.io/post/kubernetes/ingress-mechanism/","section":"post","tags":["kubernetes","中文"],"title":"浅谈kubernetes ingress机制"},{"body":"","link":"https://zhangsiming-blyq.github.io/archives/","section":"","tags":null,"title":"Archives"},{"body":"Requirements A stack whose elements are of type integer now wants to sort the stack from top to bottom in order from smallest to largest, and only one stack is allowed to be requested. Other than that, new variables can be requested, but no additional data structures can be requested. How to complete the sorting?\nSolution apply for a new help stack, keep getting data from the original stack, and compare it with the top data of the new help stack; if it meets the sorting requirements, then push it to the help stack if it does not meet the sorting requirements, pop the top data from the help stack and push it to the original stack until it meets the sorting requirements Finally, the original stack is emptied, and the help stack is the stack that is all sorted, so write it back again to complete the stack sorting. Golang Implementation 1package main 2 3// SortStark stark top --\u0026gt; stark bottom(from small to big) 4func SortStark(stk *Stack) { 5\thelpStack := NewStack() 6\t// 1. while go through target stack until stack is empty 7\tfor stk.Len() \u0026gt; 0 { 8\tcur := stk.Pop() 9\t// 2. if cur \u0026lt; peek, push helpStack.pop() to target stack until cur \u0026gt; peek or helpStack is empty 10\tfor (helpStack.Len() \u0026gt; 0) \u0026amp;\u0026amp; (cur.(int) \u0026lt; helpStack.Peek().(int)) { 11\tstk.Push(helpStack.Pop()) 12\t} 13\t// 3. if helkStack is not empty, compare cur with helpStack\u0026#39;s peek value 14\t// 4. while cur \u0026gt; peek, push cur to helpStack 15\thelpStack.Push(cur) 16\t} 17\t// 5. push back helpStack to target stack 18\tfor helpStack.Len() \u0026gt; 0 { 19\tstk.Push(helpStack.Pop()) 20\t} 21} Test Cases 1package main 2 3import ( 4\t\u0026#34;testing\u0026#34; 5 6\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 7) 8 9func TestSortStark(t *testing.T) { 10\ttests := []struct { 11\tname string 12 13\tval *Stack 14 15\twantRes []int 16\t}{ 17\t{ 18\tname: \u0026#34;sortstark\u0026#34;, 19\tval: NewStack(), 20\t// transpose once, then return to the original order of last-in first-out 21\twantRes: []int{0, 1, 2, 3, 5, 8}, 22\t}, 23\t} 24\tfor _, tt := range tests { 25\tt.Run(tt.name, func(t *testing.T) { 26\t// test case 27\tstk := tt.val 28\tstk.Push(2) 29\tstk.Push(8) 30\tstk.Push(1) 31\tstk.Push(5) 32\tstk.Push(0) 33\tstk.Push(3) 34\tSortStark(stk) 35\tres := []int{} 36\tfor stk.length \u0026gt; 0 { 37\tres = append(res, tt.val.Pop().(int)) 38\t} 39\tassert.Equal(t, tt.wantRes, res) 40\t}) 41\t} 42} Result:\n1$ go test -run ^TestSortStark$ . -v 2=== RUN TestSortStark 3=== RUN TestSortStark/sortstark 4--- PASS: TestSortStark (0.00s) 5 --- PASS: TestSortStark/sortstark (0.00s) 6PASS 7 8Process finished with the exit code 0 Tested with no problems and successfully completed sorting.\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/5/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | Use One Stack To Sort Another Stack"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/apigateway/","section":"tags","tags":null,"title":"apigateway"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/apigateway/","section":"categories","tags":null,"title":"apigateway"},{"body":" kong、apisix是当前比较火的两款开源api网关，本文对比了二者的部署、使用方式；提供一个简单的参考; 对于kong，大家都比较熟悉，但是对于apisix可能熟悉的并不多，那么kong、apisix在使用方式，功能命名上是否有相似，还是理念不同，请看下文。\n一、kong 1.1 安装 1# 安装kong 2$ helm repo add kong https://charts.konghq.com 3$ helm repo update 4$ helm fetch kong/kong 5$ tar xf kong-2.5.0.tgz 6$ cd kong 7$ ls 8CHANGELOG.md Chart.yaml FAQs.md README.md UPGRADE.md charts ci crds example-values requirements.lock requirements.yaml templates values.yaml 9...需要配置 101. postgresql作为存储 112. 允许plain text调用admin API 12 13# 安装konga 14$ gc https://github.com/pantsel/konga.git 15$ ls konga 16Chart.yaml templates values.yaml 17...需要配置 181. 获取postgresql的secret写入连接信息 19 20# 部署 21$ helm install kong . 22$ helm install konga . 23$ kp 24NAME READY STATUS RESTARTS AGE 25kong-kong-85d4dfd88b-hjkwt 2/2 Running 2 111s 26kong-postgresql-0 1/1 Running 0 15m 27konga-5b8c899c9-9zbd6 1/1 Running 0 14m 28vagrant@node1:~/kong/kong$ ks 29NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 30kong-kong-admin NodePort 172.30.46.68 \u0026lt;none\u0026gt; 8001:31055/TCP 15m 31kong-postgresql ClusterIP 172.30.194.189 \u0026lt;none\u0026gt; 5432/TCP 15m 32kong-postgresql-headless ClusterIP None \u0026lt;none\u0026gt; 5432/TCP 15m 33konga NodePort 172.30.111.78 \u0026lt;none\u0026gt; 80:32001/TCP 14m 访问konga UI：localhost:32001\n配置kong admin连接地址：http://kong-kong-admin.kong.svc.cluster.local:8001/\n1.2 配置通过kong访问服务 配置service；service在kong中表示实际要访问的服务，这里配置协议、域名、端口、路径、重试等\nroute必须在service创建，这里创建一个多path路由，并指定规定代理的Host\n1# 测试访问 2$ curl -XGET http://172.16.166.149:8000/api/test/ -H \u0026#34;Host: www.kongtest.com\u0026#34; -H \u0026#34;name: siming\u0026#34; -I 3HTTP/1.1 200 OK 4Content-Type: text/html; charset=UTF-8 5Content-Length: 2381 6Connection: keep-alive 7Accept-Ranges: bytes 8Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 9Date: Fri, 29 Oct 2021 03:05:59 GMT 10Etag: \u0026#34;588604c8-94d\u0026#34; 11Last-Modified: Mon, 23 Jan 2017 13:27:36 GMT 12Pragma: no-cache 13Server: bfe/1.0.8.18 14Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/ 15X-Kong-Upstream-Latency: 31 16X-Kong-Proxy-Latency: 109 17Via: kong/2.6.0 1.3 consumers and plugin consumers抽象表示一组相同的请求，plugin可以实现认证、限流等多种控制功能，这里展示一个jwt认证插件\n在route中的plugin里面enable jwt认证，配置获取jwt的token方式为从uri param \u0026quot;jwt\u0026quot;中获取，并且jwt的校验key为client_id jwt可以再jwt官网(https://jwt.io/)生成，填写对应的加密方式和PAYLOAD(之前route里面约定的key) 然后把上面的信息填入consumers的jwt plugin中(key的名字，加密算法，公钥)并保存 测试访问 1$ curl -XGET http://172.16.166.149:8000/api/test/?username=zhangsiming -H \u0026#34;Host: www.kongtest.com\u0026#34; -H \u0026#34;name: siming\u0026#34; 2{\u0026#34;message\u0026#34;:\u0026#34;Unauthorized\u0026#34;} 3 4$ curl -XGET http://172.16.166.149:8000/api/test/?jwt=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbGllbnRfaWQiOiJzaW1pbmcifQ.OciIJI2HRNa6CteoCn3D87q7pjJZ3u7vrXp0TaKWTuCgwyUJfCoC2c1RSKTz0Eg2GjOrP-u74hVMhBPZzCK1T9ChEOlFqmmS-CnKmh_jlC8RPeGJ2AhJDk7yOos176xgu11jt14nFVFAKzaTaKI4YkmXJ7eTx7TB3WYG0HpNDAgIl6q3UluHERMO-5DT4n3-ev5xHCe-H6InHmGzKkR2t02_lUbbR7EDz2M_YDWJu8enXgBeyHKIoE7ewE0rO66yIm-3UHqHfUJd4BQ5ii73xd8IuhcAgFgTuZ6ffXotxAHuBdoPCEN-qRxcI_dhEXxmiKCNg1QPX1FBpRcbG9uOaw -H \u0026#34;Host: www.kongtest.com\u0026#34; -H \u0026#34;name: siming\u0026#34; -I 5HTTP/1.1 200 OK 6Content-Type: text/html; charset=UTF-8 7Content-Length: 2381 8Connection: keep-alive 9Accept-Ranges: bytes 10Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 11Date: Fri, 29 Oct 2021 06:51:27 GMT 12Etag: \u0026#34;588604c8-94d\u0026#34; 13Last-Modified: Mon, 23 Jan 2017 13:27:36 GMT 14Pragma: no-cache 15Server: bfe/1.0.8.18 16Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/ 17X-Kong-Upstream-Latency: 39 18X-Kong-Proxy-Latency: 1 19Via: kong/2.6.0 二、apisix 2.1 安装 区别于kong、apisix官方自带web UI\n1$ helm repo add apisix https://charts.apiseven.com 2$ helm repo update 3$ helm fetch apisix/apisix 4$ helm fetch apisix/apisix-dashboard 5 6$ kp 7NAME READY STATUS RESTARTS AGE 8apisix-5d5665c8f-sbjhr 1/1 Running 0 17m 9apisix-dashboard-59fb575657-zt26r 1/1 Running 0 6m 10apisix-etcd-0 0/1 Running 0 13s 11apisix-etcd-1 1/1 Running 0 93s 12apisix-etcd-2 1/1 Running 0 2m55s 部署好了访问dashboard，默认账号密码是admin/admin\n2.2 配置通过apisix访问服务 这里与kong的概念稍有不同：\nupstream：类似kong的sevice，表示由apisix代为调用的上游服务，支持配置负载均衡权重 route：和kong概念相同，可以配置访问apisix的具体路径，方式等 service：route的配置模板，在service中配置了可以直接在route中复用(不用也行) 这里配置一个service，配置要以\u0026quot;www.testapisix.com\u0026quot;域名访问apisix才认为路由匹配，且上游服务为test\n这里配置上游服务为访问www.baidu.com，负载均衡机制为rr\n这里配置route：\n直接复用service配置，所以host部分不需要配置Host； 配置请求apisix的path，支持通配符 URI Override类似kong的strip host，代理的时候变更uri部分 最后还可以附加自定义的Header要求 测试访问\n1$ curl -XGET http://172.16.166.158:9080/api/test/ -H \u0026#34;Host: www.testapisix.com\u0026#34; -H \u0026#34;test: name\u0026#34; -I 2HTTP/1.1 200 OK 3Content-Type: text/html; charset=utf-8 4Content-Length: 2381 5Connection: keep-alive 6Accept-Ranges: bytes 7Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 8Date: Mon, 01 Nov 2021 08:10:41 GMT 9Etag: \u0026#34;588604c8-94d\u0026#34; 10Last-Modified: Mon, 23 Jan 2017 13:27:36 GMT 11Pragma: no-cache 12Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/ 13Server: APISIX/2.10.0 1.3 consumers and plugin apisix支持自己生成jwt token，这里演示jwt token认证插件\nconsumer中添加plugin配置，编辑json协商\u0026quot;key\u0026quot;: \u0026quot;唯一的值\u0026quot;，然后公钥私钥，加密方式，之后保存\n在service(或者route)开启jwt plugin\n测试访问\n1$ curl -XGET http://172.16.166.158:9080/api/test/more/ -H \u0026#34;Host: www.testapisix.com\u0026#34; -H \u0026#34;test: name\u0026#34; -I 2HTTP/1.1 401 Unauthorized 3Date: Mon, 01 Nov 2021 08:10:17 GMT 4Content-Type: text/plain; charset=utf-8 5Transfer-Encoding: chunked 6Connection: keep-alive 7Server: APISIX/2.10.0 8 9# 获取apisix生成的jwt token 10$ curl -XGET http://172.16.166.158:9080/apisix/plugin/jwt/sign?key=zhangsiming 11eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1YyI6WyItLS0tLUJFR0lOIFBVQkxJQyBLRVktLS0tLVxuTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FROEFNSUlCQ2dLQ0FRRUF1MVNVMUxmVkxQSENvek14SDJNb1xuNGxnT0VlUHpObTB0UmdlTGV6VjZmZkF0MGd1blZUTHc3b25MUm5ycTBcL0l6Vzd5V1I3UWtybUJMN2pUS0VuNXVcbitxS2hid0tmQnN0SXMrYk1ZMlprcDE4Z25UeEtMeG9TMnRGY3pHa1BMUGdpenNrdWVtTWdoUm5pV2FvTGN5ZWhcbmtkM3FxR0VsdldcL1ZETDVBYVdUZzBuTFZralJvOXorNDBSUXp1VmFFOEFrQUZteFp6b3czeCtWSllLZGp5a2tKXG4waVQ5d0NTMERSVFh1MjY5VjI2NFZmXC8zanZyZWRaaUtSa2d3bEw5eE5Bd3hYRmcweFwvWEZ3MDA1VVdWUklrZGdcbmNLV1RqcEJQMmRQd1ZaNFdXQys5YUdWZCtHeW4xbzBDTGVsZjRyRWpHb1hiQUFFZ0FxZUdVeHJjSWxialhmYmNcbm13SURBUUFCXG4tLS0tLUVORCBQVUJMSUMgS0VZLS0tLS1cbiJdfQ.eyJleHAiOjE2MzU4NDA2MjksImtleSI6InpoYW5nc2ltaW5nIn0.UErqUg229bwy5ZgYwEibtawT1CpwVP_UKIm-C7-XtMYUjhM6-lE695zFP31s7hp3SsS2PvoZtAEhCgd_fmZXx92EGGL87XYI0xbJ5uWweKettmxkc0cLFWwEL6MNOmqyoaW9gNDtd28K_M1dpzAwZdzz2GNr2e_G1UTrxlQUNorJEg9THIrkLjvrs7NAuvRuSnGd93G4tcXy1G6m0pCAg-Z4oehJS4vMpicmwedQbob0GytBM9Ef_r2gSj8IVVW8MMLWkA-TkPWuMx2nWeK1DdB4-l5I2f4Iu1It17rZqn6VX2ARnN_AFyG5ahT22pIGtdw71Od320hUUDH3I1rmtQ 12 13# 通过jwt token访问 14$ curl -XGET http://172.16.166.158:9080/api/test/?jwt=eyJ0eXAiOiJKV1QiLCJ4NWMiOlsiLS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0tLS1cbk1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBdTFTVTFMZlZMUEhDb3pNeEgyTW9cbjRsZ09FZVB6Tm0wdFJnZUxlelY2ZmZBdDBndW5WVEx3N29uTFJucnEwXC9Jelc3eVdSN1Frcm1CTDdqVEtFbjV1XG4rcUtoYndLZkJzdElzK2JNWTJaa3AxOGduVHhLTHhvUzJ0RmN6R2tQTFBnaXpza3VlbU1naFJuaVdhb0xjeWVoXG5rZDNxcUdFbHZXXC9WREw1QWFXVGcwbkxWa2pSbzl6KzQwUlF6dVZhRThBa0FGbXhaem93M3grVkpZS2RqeWtrSlxuMGlUOXdDUzBEUlRYdTI2OVYyNjRWZlwvM2p2cmVkWmlLUmtnd2xMOXhOQXd4WEZnMHhcL1hGdzAwNVVXVlJJa2RnXG5jS1dUanBCUDJkUHdWWjRXV0MrOWFHVmQrR3luMW8wQ0xlbGY0ckVqR29YYkFBRWdBcWVHVXhyY0lsYmpYZmJjXG5td0lEQVFBQlxuLS0tLS1FTkQgUFVCTElDIEtFWS0tLS0tXG4iXSwiYWxnIjoiUlMyNTYifQ.eyJleHAiOjE2MzU4MzkwNjcsImtleSI6InpoYW5nc2ltaW5nIn0.UR6UnkdAuELK_YP3Kk6V4D4CxoPzTSw5lAx-64As_p68tyUQsp7cuR0MvCLEZ1LtSpF5VlJ1-4fUreAbNAzJQs_FBgDvkUcm4SkdqO_Ss4b0xDiXbF771oJeVybKQA-3fDd_4ieEjCyfsFkg1urgzc_tj96NBiW0YOV98RNJzf9adYZI2MLU_QbEqSEH-f9m0ArTlFLEBnVDOQls3JSc6dWobVbkZZ1kE12YeEq0zCdjEFoUEqy3f6rojobgBFmzvG7xQqn4Jd0o3d5iXBcGbMNn19X_Jo5z47zPI8tCN9ZfHWPtc8ts3HYx_2DmBPZAlEeY3Gs2izPdCHt38evEoA -H \u0026#34;Host: www.testapisix.com\u0026#34; -H \u0026#34;test: name\u0026#34; -I 15HTTP/1.1 200 OK 16Content-Type: text/html; charset=utf-8 17Content-Length: 2381 18Connection: keep-alive 19Accept-Ranges: bytes 20Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 21Date: Mon, 01 Nov 2021 08:10:41 GMT 22Etag: \u0026#34;588604c8-94d\u0026#34; 23Last-Modified: Mon, 23 Jan 2017 13:27:36 GMT 24Pragma: no-cache 25Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/ 26Server: APISIX/2.10.0 注意，apisix支持的两种jwt访问方式：\nuri param：?jwt=xxxxx Header: -H \u0026quot;Authorization: xxxx\u0026quot; 三、kong 对比 apisix apisix配置更新生效时间0.2毫秒，事件通知；kong需要定期轮询5s左右 单核QPS(开启限流和prometheus插件)，apisix18000，kong1700 并且支持用户自定义负载均衡算法，自带维护dashboard，支持指定时间窗口的限速等 参考链接：\nGitHub - apache/apisix: The Cloud-Native API Gateway 插件 - 插件热加载 - 《Apache APISIX v1.4 使用教程》 - 书栈网 · BookStack\n","link":"https://zhangsiming-blyq.github.io/post/linux/apigateway/","section":"post","tags":["linux","apigateway","中文"],"title":"API网关对比"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/ansible/","section":"tags","tags":null,"title":"ansible"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/ansible/","section":"categories","tags":null,"title":"ansible"},{"body":" Ansible 是一个开源的基于 OpenSSH 的自动化配置管理工具。可以用它来配置系统、部署软件和编排更高级的 IT 任务，比如持续部署或零停机更新。\n一、ansible 简介 Ansible 的主要目标是简单和易用，并且它还高度关注安全性和可靠性。基于这样的目标，Ansible 适用于开发人员、系统管理员、发布工程师、IT 经理，以及介于两者之间的所有人。Ansible 适合管理几乎所有的环境，从拥有少数实例的小型环境到有数千个实例的企业环境。\n1.1 ansible 变量优先级如下 command line values (eg \u0026quot;-u user\u0026quot;) role defaults inventory file or script group vars inventory group_vars/all playbook group_vars/all inventory group_vars/* playbook group_vars/* inventory file or script host vars inventory host_vars/*: inventory 下面的 hosts_vars 目录下的变量优先级大于 group_vars 目录下的 playbook host_vars/* host facts / cached set_facts play vars play vars_prompt play vars_files: vars_files 优先级大于同级别的 vars 字段(play 内定义) role vars (defined in role/vars/main.yml): role 里面的 vars 目录下的定义变量 block vars (only for tasks in block) task vars (only for the task): task 里面的 vars 字段优先级别比较高(本 task) include_vars set_facts / registered vars: 比较常用 set_facts 更改一些后面要使用的变量，全局生效；registered vars 一般连续的 task 用的比较多 role (and include_role) params include params extra vars (always win precedence): 执行 ansible-playbook 命令时候传入的 extra vars 级别最高，高于一切 1.2 变量的作用范围(Scoping variables) Global: this is set by config, environment variables and the command line Play: each play and contained structures, vars entries (vars; vars_files; vars_prompt), role defaults and vars. Host: variables directly associated to a host, like inventory, include_vars, facts or registered task outputs Ansible 1.2 及以上的版本中,group_vars/ 和 host_vars/ 目錄可放在 inventory 目錄下,或是 playbook 目錄下. 如果兩個目錄下都存在,那麼 playbook 目錄下的配置會覆蓋 inventory 目錄的配置(对应解释上分 4-10 条变量优先级)\n1.3 ansible 目录结构最佳实践 结构如下： 1├── playbooks.yml 2├── inventory(inventory下可以任意加子目录进行分组) 3| ├── group_vars ├── all ├── *.yml 4| | ├── *.yml 5| | └── * 6| ├── host_vars 7| | 8│ └── hosts.ini 9| 10├── roles 11│ ├── common 12│ │ ├── files 13│ │ ├── handlers 14│ │ ├── meta 15│ │ ├── templates 16│ │ ├── tasks 17│ │ │ └── main.yml 18│ │ └── vars 19| | 20│ ├── others 21│ ├── files 22│ ├── handlers 23│ ├── meta 24│ ├── templates 25│ ├── tasks 26│ │ └── main.yml 27│ └── vars 28└── *.yml 使用 roles 管理不同的安装模块 使用 inventory/host.ini 管理操作主机，对不同主机进行分组 使用 group_vars 管理基本的默认变量，playbook 中使用 set_facts 设置需要的变量，默认不想被修改的变量写在 roles/vars/main.yml 每个 task 都要写 name tags 写在 role 阶段 1.4 ansible-playbook roles 初始化行为规划 如果角色 /xxx/tasks/main.yaml 存在，则其中列出的任务将添加到任务中，否则将不会添加任务中 如果角色 /xxx/handlers/main.yaml 存在，则其中列出的处理程序将添加到任务中，否则将不会添加任务中 如果角色 /xxx/vars/main.yml 存在，则其中列出的处理程序将添加到任务中，否则将不会添加任务中 如果角色 /xxx/defaults/main.yml 存在，则其中列出的处理程序将添加到任务中，否则将不会添加任务中 如果角色 /xxx/meta/main.yml 存在，则其中列出的任何角色依赖项将添加到角色列表（1.3 及更高版本） 任何副本，脚本，模板或包含任务（在角色中）都可以引用 roles / x / {files，templates，tasks} /（dir 取决于任务）中的文件，而无需相对或绝对地路径化它们 1.5 ansible-playbook 执行顺序 pre_tasks 游戏中定义的任何内容 列出的每个角色将依次执行。将首先运行角色中定义的任何角色依赖项，但需遵循标记过滤和条件。roles meta/main.yml tasks 游戏中定义的任何内容 post_tasks 游戏中定义的任何内容 二、kubespray 部署集群 playbook 解读 github 地址：https://github.com/kubernetes-sigs/kubespray\n1$ gc https://github.com/kubernetes-sigs/kubespray 2$ cd kubespray 3 4# 查看部署集群playbook 5$ cat cluster.yml 6--- 7# 检查ansible版本 8- name: Check ansible version 9 import_playbook: ansible_version.yml 10 11# 检查inventory中组的版本，进行适配旧版本的group名称 12- name: Ensure compatibility with old groups 13 import_playbook: legacy_groups.yml 14 15# 堡垒机配置(没有跳过) 16- hosts: bastion[0] 17 gather_facts: False 18 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 19 roles: 20 - { role: kubespray-defaults } 21 - { role: bastion-ssh-config, tags: [\u0026#34;localhost\u0026#34;, \u0026#34;bastion\u0026#34;] } 22 23# 默认linear,每个主机的单个task执行完成会等待其他都完成后再执行下个任务，设置free可不等待其他主机，继续往下执行(看起来会比较乱) 24# linear策略即线性执行策略，线性执行策略指主机组内所有主机完成一个任务后才继续下一个任务的执行，在执行一个任务时，如果某个主机先执行完则会等待其他主机执行结束。说直白点就是第一个任务在指定的主机都执行完，再进行第二个任务的执行，第二个任务在指定的主机都执行完后，再进行第三个任务的执行…… 以此类推。 25# free策略即自由策略，即在一个play执行完之前，每个主机都各顾各的尽可能快的完成play里的所有任务，而不会因为其他主机没执行完任务而等待，不受线性执行策略那样的约束。所以这种策略的执行结果给人感觉是无序的甚至是杂乱无章的，而且每次执行结果的task显示顺序很可能不一样 26 27# 此阶段对于etcd的每一个节点一个一个的进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact), bootstrap-os(装一些yum源，基础包，改一些主机名等操作) 28- hosts: k8s_cluster:etcd 29 strategy: linear 30 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 31 gather_facts: false 32 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 33 roles: 34 - { role: kubespray-defaults } 35 - { role: bootstrap-os, tags: bootstrap-os} 36 37- name: Gather facts 38 tags: always 39 import_playbook: facts.yml 40 41# 此阶段对于etcd的每一个节点一个一个的进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact)、kubernetes/preinstall(预先配置一些环境，比如禁用SWAP、配置替换resolvconf，设置一些cni的bin路径等、创建/检查一些安装目录、期间对于特定文件触发handler重启相关服务、配置systemd-resolved、修改/etc/hosts文件等)、container-engine(选择容器runtime，进行安装、配置、reload等)、 42# download(模块用于下载所有有需要的镜像，先在ansible执行机缓存，之后再下载所有需要的二进制包，包括kubeadm需要的、kubernetes集群需要的等等) 43- hosts: k8s_cluster:etcd 44 gather_facts: False 45 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 46 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 47 roles: 48 - { role: kubespray-defaults } 49 - { role: kubernetes/preinstall, tags: preinstall } 50 - { role: \u0026#34;container-engine\u0026#34;, tags: \u0026#34;container-engine\u0026#34;, when: deploy_container_engine|default(true) } 51 - { role: download, tags: download, when: \u0026#34;not skip_downloads\u0026#34; } 52 53# 此阶段开始执行etcd role，先进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact)、再进行etcd(检查、创建etcd证书，部署etcd集群，添加etcd节点，检查etcd状态，创建etcd执行用户等...) 54- hosts: etcd 55 gather_facts: False 56 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 57 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 58 roles: 59 - { role: kubespray-defaults } 60 - role: etcd 61 tags: etcd 62 vars: 63 etcd_cluster_setup: true 64 etcd_events_cluster_setup: \u0026#34;{{ etcd_events_cluster_enabled }}\u0026#34; 65 when: not etcd_kubeadm_enabled| default(false) 66 67# 设置etcd_cluster_setup、etcd_events_cluster_setup为 false，主要是将k8s cluster中的机器，分发配置信息etcd的证书, 用于后续与etcd集群交互 68- hosts: k8s_cluster 69 gather_facts: False 70 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 71 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 72 roles: 73 - { role: kubespray-defaults } 74 - role: etcd 75 tags: etcd 76 vars: 77 etcd_cluster_setup: false 78 etcd_events_cluster_setup: false 79 when: not etcd_kubeadm_enabled| default(false) 80 81# 此阶段执行kubernetes/nodes role，先进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact), 再进行kubernetes/node(检查docker cgroup, 配置一些参数等、拷贝一些数据，比如cni目录下的，等等、通过镜像挂载的方式配置安装kubelet、部署apiserver的负载均衡、确保预留nodePort端口范围，通过sysctl修改内核参数、确认kube-proxy ipvs需要的内核模块已开启) 82- hosts: k8s_cluster 83 gather_facts: False 84 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 85 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 86 roles: 87 - { role: kubespray-defaults } 88 - { role: kubernetes/node, tags: node } 89 90# 此阶段部署配置kube_control_plane机器，先进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact)、 91# kubernetes/control-plane(删除control-plane静态文件，删除旧的master容器、下载好kubectl命令行工具、配置kubectl命令行工具自动补全、在kubeadm-setup.yml初始化Initialize first master，创建kubeadm的24h token，然后include_tasks: kubeadm-secondary.yml添加其他的master到集群中、检查etcd证书过期时间等后续检查、更新apiserver客户端的连接地址为fix后的api负载均衡地址、renew集群的证书们, 使用kubeadm renew的方式) 92# kubernetes/client(建立/etc/kubernetes架构目录，拷贝kubeconfig到node并配置好ansible执行机上面的k8s client环境) 93# kubernetes-apps/cluster_roles(通过配置好的kubectl执行，Apply workaround to allow all nodes with cert O=system:nodes to register, 这样之后的所有node加入申请都会自动审批通过...) 94- hosts: kube_control_plane 95 gather_facts: False 96 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 97 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 98 roles: 99 - { role: kubespray-defaults } 100 - { role: kubernetes/control-plane, tags: master } 101 - { role: kubernetes/client, tags: client } 102 - { role: kubernetes-apps/cluster_roles, tags: cluster-roles } 103 104# 此阶段部署配置cluster里面的其他普通node节点，先进行kubespray-defaults(设置一些fallback_ip、noproxy的set_fact)、 105# 之后kubernetes/kubeadm(检查kubelet配置文件是否存在、检查kubelet的ca.crt证书是否存在、创建kubeadm join的token、更新kubelet中的地址为负载均衡的apiserver地址、重启kube-proxy的pods)、 106# kubernetes/node-label(根据变量中的{{ role_node_labels + inventory_node_labels }}给node打上对应的标签，通过kubectl label nodes) 107# network_plugin(根据变量决定要部署哪种网络插件，举例cilium的话就是check.yml检查cilium参数，install.yml渲染安装cilium需要的yaml文件到node、apply.yml执行kubectl部署网络插件到集群中) 108- hosts: k8s_cluster 109 gather_facts: False 110 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 111 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 112 roles: 113 - { role: kubespray-defaults } 114 - { role: kubernetes/kubeadm, tags: kubeadm} 115 - { role: kubernetes/node-label, tags: node-label } 116 - { role: network_plugin, tags: network } 117 118# 如果网络插件部署的是calico，还需要到宿主机上面执行一些操作，这里我们选择cilium就跳过了 119- hosts: calico_rr 120 gather_facts: False 121 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 122 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 123 roles: 124 - { role: kubespray-defaults } 125 - { role: network_plugin/calico/rr, tags: [\u0026#39;network\u0026#39;, \u0026#39;calico_rr\u0026#39;] } 126 127# windows master的额外配置，这里跳过, 一般不用 128- hosts: kube_control_plane[0] 129 gather_facts: False 130 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 131 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 132 roles: 133 - { role: kubespray-defaults } 134 - { role: win_nodes/kubernetes_patch, tags: [\u0026#34;master\u0026#34;, \u0026#34;win_nodes\u0026#34;] } 135 136# 这阶段就是在kube_control_plane也就是有权限kubectl的机器上面安装后续应用了，不是每个role都需要走，比如是否部署ingress_controller就由\u0026#34;ingress_nginx_enabled\u0026#34;管理，kubernetes-apps下有个meta/main.yml文件，根据参数选择安装不同的app，流程无非就是下载包，或者传输yaml文件之后kubectl apply 137- hosts: kube_control_plane 138 gather_facts: False 139 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 140 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 141 roles: 142 - { role: kubespray-defaults } 143 - { role: kubernetes-apps/external_cloud_controller, tags: external-cloud-controller } 144 - { role: kubernetes-apps/network_plugin, tags: network } 145 - { role: kubernetes-apps/policy_controller, tags: policy-controller } 146 - { role: kubernetes-apps/ingress_controller, tags: ingress-controller } 147 - { role: kubernetes-apps/external_provisioner, tags: external-provisioner } 148 - { role: kubernetes-apps, tags: apps } 149 150# 这阶段是最后收尾阶段完善集群的dns，host文件，resolv文件里面的格式化对应项等, 至此kubernetes集群通过ansible kubespray安装完毕 151- hosts: k8s_cluster 152 gather_facts: False 153 any_errors_fatal: \u0026#34;{{ any_errors_fatal | default(true) }}\u0026#34; 154 environment: \u0026#34;{{ proxy_disable_env }}\u0026#34; 155 roles: 156 - { role: kubespray-defaults } 157 - { role: kubernetes/preinstall, when: \u0026#34;dns_mode != \u0026#39;none\u0026#39; and resolvconf_mode == \u0026#39;host_resolvconf\u0026#39;\u0026#34;, tags: resolvconf, dns_late: true } 1.2 实际操作使用 ansible-playbook 部署单节点集群 部署参考文档：https://kubespray.io/#/、https://kubespray.io/#/docs/downloads\n1$ sudo apt-get install python3-pip 2$ cd kubespray 3$ sudo pip3 install -r requirements.txt 4# 看下面两个文件有没有要删除的东西 5$ vim inventory/mycluster/group_vars/all/all.yml 6$ vim inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 7# download缓存相关配置可以查看链接：https://kubespray.io/#/docs/downloads 8# 配置免密sudo，配置免密ssh节点 9$ vim /etc/sudoers 10vagrant ALL=NOPASSWD:ALL 11 12# 开始部署集群 13$ ansible-playbook -i inventory/k8sdemo/inventory.ini --become --become-user=root cluster.yml 14# 部署结果无报错 15... 16PLAY RECAP ******************************************************************************************************************************************************* 17localhost : ok=4 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 18node1 : ok=650 changed=177 unreachable=0 failed=0 skipped=1031 rescued=0 ignored=2 19... 20# 查看集群状态 21$ kubectl get nodes 22NAME STATUS ROLES AGE VERSION 23node1 Ready control-plane,master 3m49s v1.22.2 24$ kubectl get cs 25Warning: v1 ComponentStatus is deprecated in v1.19+ 26NAME STATUS MESSAGE ERROR 27scheduler Healthy ok 28controller-manager Healthy ok 29etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;} 30$ kubectl get pods -A 31NAMESPACE NAME READY STATUS RESTARTS AGE 32kube-system cilium-dtgnn 1/1 Running 0 3m16s 33kube-system cilium-operator-66576fd87-bklpc 1/1 Running 0 3m15s 34kube-system coredns-8474476ff8-85qkx 1/1 Running 0 3m9s 35kube-system coredns-8474476ff8-xtmst 0/1 Pending 0 2m45s 36kube-system dns-autoscaler-7df78bfcfb-gsqjb 1/1 Running 0 3m5s 37kube-system kube-apiserver-node1 1/1 Running 0 4m 38kube-system kube-controller-manager-node1 1/1 Running 1 4m 39kube-system kube-proxy-h2lgj 1/1 Running 0 3m16s 40kube-system kube-scheduler-node1 1/1 Running 1 4m 41kube-system nodelocaldns-xnvv7 1/1 Running 0 3m4s 参考链接：\nansible 变量详解\nansible 变量优先级官方原文\n","link":"https://zhangsiming-blyq.github.io/post/linux/ansible-playbook/","section":"post","tags":["ansible","linux","中文"],"title":"ansible-playbook 详解"},{"body":"Requirements Dog and cat have implemented the Pet interface, you can use getPetType() to view the corresponding animal type; NewDog(), NewCat() can create new dog and cat objects respectively.\n1type Pet interface { 2\tgetPetType() string 3} 4 5type fatherPet struct { 6\tType string 7} 8 9func (fp *fatherPet) getPetType() string { 10\treturn fp.Type 11} 12 13type Dog struct { 14\tfatherPet 15} 16 17func NewDog() *Dog { 18\tfmt.Println(\u0026#34;new dog\u0026#34;) 19\treturn \u0026amp;Dog{fatherPet{Type: \u0026#34;dog\u0026#34;}} 20} 21 22func (dog *Dog) getPetType() string { 23\treturn dog.fatherPet.Type 24} 25 26type Cat struct { 27\tfatherPet 28} 29 30func NewCat() *Cat { 31\tfmt.Println(\u0026#34;new cat\u0026#34;) 32\treturn \u0026amp;Cat{fatherPet{Type: \u0026#34;cat\u0026#34;}} 33} 34 35func (cat *Cat) getPetType() string { 36\treturn cat.fatherPet.Type 37} You need to implement a dog-cat queue structure with the following requirements:\nthe user can call the add method to place instances of the cat class or the dog class into the queue; the user can call the pollAll method to pop all the instances in the queue in the order of the queue; the user can call the pollDog method to pop the instances of the dog class in the queue in the order in which they entered the queue; the user may call the pollCat method to populate the queue with instances of the cat class in the order in which they entered the queue; the user can call the isEmpty method to check if there are still instances of dog or cat in the queue the user can call the isDogEmpty method to check if there are instances of the dog class in the queue the user can call the isCatEmpty method to check if there is an instance of the cat class in the queue. Solution According to the question, you need to determine the queue may have dog or cat, with two queues to store dog and cat instances; as for how to determine whether the elements of the dog queue is earlier into the queue or the elements of the cat queue is earlier into the queue need to have a field to store the incoming queue time (globally unique), here you can package a struct to save pet and time;\nThen if you want to look at dog, look at dogqueue, if you want to look at cat, look at catqueue; if you want to see the order of the total queue, take the time of the latest element of both dogqueue and catqueue to compare the order of the total queue.\nGolang Implementation Create a new struct ready to be placed in the queue, including the Pet object and the Time field:\n1type TimePet struct { 2\tPet Pet 3\tTime int 4} 5 6func NewTimePet(pet Pet, time int) *TimePet { 7\treturn \u0026amp;TimePet{ 8\tPet: pet, 9\tTime: time, 10\t} 11} 12 13func (tp *TimePet) getPet() Pet { 14\treturn tp.Pet 15} 16 17func (tp *TimePet) getTime() int { 18\treturn tp.Time 19} Then the dogcatqueue body includes the following logic:\n1type DogCatQueue struct { 2\tDogQueue *customQueue 3\tCatQueue *customQueue 4\tTime int 5} 6 7func NewDogCatQueue() *DogCatQueue { 8\treturn \u0026amp;DogCatQueue{ 9\tDogQueue: newCustomQueue(), 10\tCatQueue: newCustomQueue(), 11\t// Globally unique Time, used to identify the total order 12\tTime: 0, 13\t} 14} 15 16// Adding is relatively simple, dogs into the dog queue, cats into the cat queue 17func (dcqueue *DogCatQueue) add(pet Pet) { 18\tif pet.getPetType() == \u0026#34;dog\u0026#34; { 19\tdcqueue.Time++ 20\tdcqueue.DogQueue.Enqueue(NewTimePet(pet, dcqueue.Time)) 21\t} else if pet.getPetType() == \u0026#34;cat\u0026#34; { 22\tdcqueue.Time++ 23\tdcqueue.CatQueue.Enqueue(NewTimePet(pet, dcqueue.Time)) 24\t} else { 25\tfmt.Errorf(\u0026#34;err, not dog or cat\u0026#34;) 26\t} 27} 28 29// When pollAll, you need to compare the Time of the latest element of the dog queue and the cat queue who is smaller, who is smaller means who is the first queue 30func (dcqueue *DogCatQueue) pollAll() Pet { 31\tif !dcqueue.isDogQueueEmpty() \u0026amp;\u0026amp; !dcqueue.isCatQueueEmpty() { 32\tif dcqueue.DogQueue.Front().(*TimePet).getTime() \u0026lt; dcqueue.CatQueue.Front().(*TimePet).getTime() { 33\treturn dcqueue.DogQueue.Dequeue().(*TimePet).getPet() 34\t} else { 35\treturn dcqueue.CatQueue.Dequeue().(*TimePet).getPet() 36\t} 37\t} else if !dcqueue.isDogQueueEmpty() { 38\treturn dcqueue.DogQueue.Dequeue().(*TimePet).getPet() 39\t} else if !dcqueue.isCatQueueEmpty() { 40\treturn dcqueue.CatQueue.Dequeue().(*TimePet).getPet() 41\t} else { 42\tfmt.Errorf(\u0026#34;err, dogcatqueue is empty\u0026#34;) 43\treturn nil 44\t} 45} 46 47// pollDog can be deleted directly from the dog queue 48func (dcqueue *DogCatQueue) pollDog() Pet { 49\tif !dcqueue.isDogQueueEmpty() { 50\tfmt.Println(\u0026#34;delete latest dog\u0026#34;) 51\treturn dcqueue.DogQueue.Dequeue().(*TimePet).getPet() 52\t} else { 53\tfmt.Errorf(\u0026#34;err, dogcatqueue don\u0026#39;t have dog\u0026#34;) 54\treturn nil 55\t} 56} 57 58// vice versa 59func (dcqueue *DogCatQueue) pollCat() Pet { 60\tif !dcqueue.isCatQueueEmpty() { 61\tfmt.Println(\u0026#34;delete latest cat\u0026#34;) 62\treturn dcqueue.CatQueue.Dequeue().(*TimePet).getPet() 63\t} else { 64\tfmt.Errorf(\u0026#34;err, dogcatqueue don\u0026#39;t have cat\u0026#34;) 65\treturn nil 66\t} 67} 68 69func (dcqueue *DogCatQueue) isEmpty() bool { 70\treturn dcqueue.DogQueue.Empty() \u0026amp;\u0026amp; dcqueue.CatQueue.Empty() 71} 72 73func (dcqueue *DogCatQueue) isDogQueueEmpty() bool { 74\treturn dcqueue.DogQueue.Empty() 75} 76 77func (dcqueue *DogCatQueue) isCatQueueEmpty() bool { 78\treturn dcqueue.CatQueue.Empty() 79} Test Cases 1package main 2 3import ( 4\t\u0026#34;testing\u0026#34; 5 6\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 7) 8 9func TestDogCatQueue(t *testing.T) { 10\t// define a getmin stack 11\ttests := []struct { 12\tname string 13 14\tval func(tq *DogCatQueue) []bool 15 16\twantRes []bool 17\t}{ 18\t{ 19\tname: \u0026#34;operate1\u0026#34;, 20\tval: operate1, 21\twantRes: []bool{true, false, false}, 22\t}, 23\t{ 24\tname: \u0026#34;operate2\u0026#34;, 25\tval: operate2, 26\twantRes: []bool{true, false, false}, 27\t}, 28\t{ 29\tname: \u0026#34;operate3\u0026#34;, 30\tval: operate3, 31\twantRes: []bool{true, true, true}, 32\t}, 33\t{ 34\tname: \u0026#34;operate4\u0026#34;, 35\tval: operate4, 36\twantRes: []bool{true, true, true}, 37\t}, 38\t{ 39\tname: \u0026#34;operate5\u0026#34;, 40\tval: operate5, 41\twantRes: []bool{true, true, true}, 42\t}, 43\t} 44\tfor _, tt := range tests { 45\t// new TwoStackQueue 46\ttq := NewDogCatQueue() 47\t// add test cases 48\tadddogcat(tq) 49\tt.Run(tt.name, func(t *testing.T) { 50\tres := tt.val(tq) 51\tassert.Equal(t, tt.wantRes, res) 52\t}) 53\t} 54} 55 56func adddogcat(tq *DogCatQueue) { 57\ttq.add(NewDog()) 58\ttq.add(NewCat()) 59\ttq.add(NewCat()) 60\ttq.add(NewCat()) 61\ttq.add(NewDog()) 62} 63 64func operate1(tq *DogCatQueue) (queStatus []bool) { 65\ttq.pollAll() 66\ttq.pollAll() 67\ttq.pollCat() 68\ttq.pollCat() 69\tqueStatus = []bool{tq.isCatQueueEmpty(), tq.isDogQueueEmpty(), tq.isEmpty()} 70\treturn queStatus 71} 72 73func operate2(tq *DogCatQueue) (queStatus []bool) { 74\ttq.pollAll() 75\ttq.pollAll() 76\ttq.pollCat() 77\ttq.pollCat() 78\ttq.pollCat() 79\tqueStatus = []bool{tq.isCatQueueEmpty(), tq.isDogQueueEmpty(), tq.isEmpty()} 80\treturn queStatus 81} 82 83func operate3(tq *DogCatQueue) (queStatus []bool) { 84\ttq.pollAll() 85\ttq.pollAll() 86\ttq.pollCat() 87\ttq.pollCat() 88\ttq.pollDog() 89\tqueStatus = []bool{tq.isCatQueueEmpty(), tq.isDogQueueEmpty(), tq.isEmpty()} 90\treturn queStatus 91} 92 93func operate4(tq *DogCatQueue) (queStatus []bool) { 94\ttq.pollAll() 95\ttq.pollAll() 96\ttq.pollCat() 97\ttq.pollCat() 98\ttq.pollAll() 99\tqueStatus = []bool{tq.isCatQueueEmpty(), tq.isDogQueueEmpty(), tq.isEmpty()} 100\treturn queStatus 101} 102 103func operate5(tq *DogCatQueue) (queStatus []bool) { 104\ttq.pollCat() 105\ttq.pollCat() 106\ttq.pollCat() 107\ttq.pollDog() 108\ttq.pollDog() 109\tqueStatus = []bool{tq.isCatQueueEmpty(), tq.isDogQueueEmpty(), tq.isEmpty()} 110\treturn queStatus 111} Result:\n1$ go test -run ^TestDogCatQueue$ . -v 2=== RUN TestDogCatQueue 3=== RUN TestDogCatQueue/operate1 4=== RUN TestDogCatQueue/operate2 5=== RUN TestDogCatQueue/operate3 6=== RUN TestDogCatQueue/operate4 7=== RUN TestDogCatQueue/operate5 8--- PASS: TestDogCatQueue (0.00s) 9 --- PASS: TestDogCatQueue/operate1 (0.00s) 10 --- PASS: TestDogCatQueue/operate2 (0.00s) 11 --- PASS: TestDogCatQueue/operate3 (0.00s) 12 --- PASS: TestDogCatQueue/operate4 (0.00s) 13 --- PASS: TestDogCatQueue/operate5 (0.00s) 14PASS 15ok dogcatqueue 0.008s The length is not short, but the difficulty is very low, note that the topic requires not to modify the original data structure, so define a new structure including Time.\nWhat's More: Use Golang Chain Table To Implement Queue In fact, using slice can also implemente Chain Table, but if the slice is full, the underlying array will be copied once. Using a chain table does not have this problem, the implementation is as follows (accept interface{} as queue elements):\n1package main 2 3import ( 4\t\u0026#34;container/list\u0026#34; 5) 6 7type customQueue struct { 8\tqueue *list.List 9} 10 11func newCustomQueue() *customQueue { 12\treturn \u0026amp;customQueue{queue: list.New()} 13} 14 15func (c *customQueue) Enqueue(value interface{}) { 16\tc.queue.PushBack(value) 17} 18 19func (c *customQueue) Dequeue() interface{} { 20\tif c.queue.Len() \u0026gt; 0 { 21\tele := c.queue.Front() 22\tc.queue.Remove(ele) 23\treturn ele.Value 24\t} 25\treturn nil 26} 27 28func (c *customQueue) Front() interface{} { 29\tif c.queue.Len() \u0026gt; 0 { 30\treturn c.queue.Front().Value 31\t} 32\treturn nil 33} 34 35func (c *customQueue) Size() int { 36\treturn c.queue.Len() 37} 38 39func (c *customQueue) Empty() bool { 40\treturn c.queue.Len() == 0 41} Reference:\nhttps://www.delftstack.com/zh/howto/go/queue-implementation-in-golang/\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/4/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | Dog-Cat Queue"},{"body":"Requirements A stack is pressed into 1, 2, 3, 4, 5, then from the top of the stack to the bottom of the stack is 5, 4, 3, 2, 1. After transposing this stack, from the top of the stack to the bottom of the stack is 1, 2, 3, 4, 5, that is, to achieve the reverse order of the stack elements, but only with recursive functions to achieve, can not use other data structures.\nSolution a function to implement the return of the data on the stack, used to return the bottom element of the stack, stop when the stack is empty another function accepts the bottom element of the stack and represses the data of each one onto the stack to achieve reverse order Golang Implementation 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func getAndRemoveLastElement(stack *Stack) int { 6\tresult := stack.Pop() 7\tif stack.Len() == 0 { 8\treturn result.(int) 9\t} else { 10\tlast := getAndRemoveLastElement(stack) 11\tstack.Push(result) 12\treturn last 13\t} 14} 15 16func reverse(stack *Stack) { 17\tif stack.Len() == 0 { 18\treturn 19\t} else { 20\tgarFuncReturn := getAndRemoveLastElement(stack) 21\treverse(stack) 22\tstack.Push(garFuncReturn) 23\t} 24} Test Cases 1package main 2 3import ( 4\t\u0026#34;testing\u0026#34; 5 6\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 7) 8 9func TestReverseStack(t *testing.T) { 10\t// define a getmin stack 11\ttests := []struct { 12\tname string 13 14\tval func(stk *Stack) 15 16\twantRes []any 17\t}{ 18\t{ 19\tname: \u0026#34;push\u0026#34;, 20\tval: push, 21\t// transpose once, then return to the original order of last-in first-out 22\twantRes: []any{1, 2, 3, 4, 5}, 23\t}, 24\t} 25\tfor _, tt := range tests { 26\t// new TwoStackQueue 27\tstk := NewStack() 28\tt.Run(tt.name, func(t *testing.T) { 29\ttt.val(stk) 30\treverse(stk) 31\tres := popall(stk) 32\tassert.Equal(t, tt.wantRes, res) 33\t}) 34\t} 35} 36 37func push(stk *Stack) { 38\tfor i := 1; i \u0026lt;= 5; i++ { 39\tstk.Push(i) 40\t} 41} 42 43func popall(stk *Stack) (resultList []any) { 44\tfor { 45\tif stk.length == 0 { 46\tbreak 47\t} 48\tresultList = append(resultList, stk.Pop()) 49\t} 50\treturn resultList 51} Result:\n1$ go test -run ^TestReverseStack$ . -v 2=== RUN TestReverseStack 3=== RUN TestReverseStack/push 4--- PASS: TestReverseStack (0.00s) 5 --- PASS: TestReverseStack/push (0.00s) 6PASS 7ok starkreverse 0.008s Implementation is relatively simple, the focus is the need to draw the call-stack diagram, each layer of the variable is what value sorted out, when to pop up, this is much easier to use a pen to draw.\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/3/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | How To Inverse Order A Stack Using Only Recursive Functions And Stack"},{"body":"Requirements Write a class that implements a queue with two stacks and supports the basic operations of a queue: add, poll, peek\nSolving Ideas stacks are characterized by last-in-first-out, queues are characterized by first-in-first-out one stack as a press-in stack, the other stack as a pop-up stack, as long as the data pressed into the press-in stack and then pressed into the pop-up stack order will be restored Golang Implementation Note that since the data from stackPush to stackPop is only guaranteed to be coherent each time, stackPush has to press all the data into stackPop at once, and only when stackPop is empty.\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5type TwoStackQueue struct { 6\tstackPush *Stack 7\tstackPop *Stack 8} 9 10func NewTwoStackQueue() *TwoStackQueue { 11\treturn \u0026amp;TwoStackQueue{ 12\tstackPush: NewStack(), 13\tstackPop: NewStack(), 14\t} 15} 16 17func (tsq *TwoStackQueue) add(data interface{}) { 18\ttsq.stackPush.Push(data) 19} 20 21func (tsq *TwoStackQueue) poll() interface{} { 22\tif tsq.stackPop.Len() == 0 \u0026amp;\u0026amp; tsq.stackPush.Len() == 0 { 23\tfmt.Errorf(\u0026#34;TwoStackQueue is empty\u0026#34;) 24\t} else if tsq.stackPop.Len() == 0 { 25\tfor tsq.stackPush.Len() != 0 { 26\ttsq.stackPop.Push(tsq.stackPush.Pop()) 27\t} 28\t} 29\tvalue := tsq.stackPop.Pop() 30\treturn value 31} 32 33func (tsq *TwoStackQueue) peek() interface{} { 34\tif tsq.stackPop.Len() == 0 \u0026amp;\u0026amp; tsq.stackPush.Len() == 0 { 35\tfmt.Errorf(\u0026#34;TwoStackQueue is empty\u0026#34;) 36\t} else if tsq.stackPop.Len() == 0 { 37\tfor tsq.stackPush.Len() != 0 { 38\ttsq.stackPop.Push(tsq.stackPush.Pop()) 39\t} 40\t} 41\tvalue := tsq.stackPop.Peek() 42\treturn value 43} Test Cases 1package main 2 3import ( 4\t\u0026#34;testing\u0026#34; 5 6\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 7) 8 9func TestTwoStackQueue(t *testing.T) { 10\t// define a getmin stack 11\ttests := []struct { 12\tname string 13 14\tval func(tsq *TwoStackQueue) 15 16\twantRes interface{} 17\t}{ 18\t{ 19\tname: \u0026#34;push\u0026#34;, 20\tval: push, 21\twantRes: 1, 22\t}, 23\t{ 24\tname: \u0026#34;push and poll1\u0026#34;, 25\tval: pushpoll1, 26\twantRes: 3, 27\t}, 28\t{ 29\tname: \u0026#34;push and poll2\u0026#34;, 30\tval: pushpoll2, 31\twantRes: 2, 32\t}, 33\t{ 34\tname: \u0026#34;push and poll3\u0026#34;, 35\tval: pushpoll3, 36\twantRes: nil, 37\t}, 38\t} 39\tfor _, tt := range tests { 40\t// new TwoStackQueue 41\ttsq := NewTwoStackQueue() 42\tt.Run(tt.name, func(t *testing.T) { 43\ttt.val(tsq) 44\tres := tsq.peek() 45\tassert.Equal(t, tt.wantRes, res) 46\t}) 47\t} 48} 49 50func push(tsq *TwoStackQueue) { 51\ttsq.add(1) 52\ttsq.add(2) 53\ttsq.add(3) 54} 55 56func pushpoll1(tsq *TwoStackQueue) { 57\ttsq.add(1) 58\ttsq.add(2) 59\ttsq.add(3) 60\ttsq.poll() 61\ttsq.poll() 62} 63 64func pushpoll2(tsq *TwoStackQueue) { 65\ttsq.add(1) 66\ttsq.poll() 67\ttsq.add(2) 68\ttsq.add(3) 69} 70 71func pushpoll3(tsq *TwoStackQueue) { 72\ttsq.add(1) 73\ttsq.add(2) 74\ttsq.poll() 75\ttsq.add(3) 76\ttsq.poll() 77\ttsq.poll() 78} Result:\n1$ go test -run ^TestTwoStackQueue$ . -v 2=== RUN TestTwoStackQueue 3=== RUN TestTwoStackQueue/push 4=== RUN TestTwoStackQueue/push_and_poll1 5=== RUN TestTwoStackQueue/push_and_poll2 6=== RUN TestTwoStackQueue/push_and_poll3 7--- PASS: TestTwoStackQueue (0.00s) 8 --- PASS: TestTwoStackQueue/push (0.00s) 9 --- PASS: TestTwoStackQueue/push_and_poll1 (0.00s) 10 --- PASS: TestTwoStackQueue/push_and_poll2 (0.00s) 11 --- PASS: TestTwoStackQueue/push_and_poll3 (0.00s) 12PASS The test scenario matches the queue's characteristics well. As you can see, a peek operation, add(1), add(2), and add(3) always return 1. In addition, you can only see 2 if you delete 1. so forth.\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/2/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | Queue Composed Of Two Stacks"},{"body":"Requirements the time complexity of pop, push, getMin operations are O(1) the design of the stack type can use the ready-made stack structure Solving Ideas use two stacks, starkData and stackMin compare the size of the top data of stackMin with that of starkData each time it is pressed in, and press the new minimum value onto the stack if it is smaller than the top data of stackMin Golang Implementation Golang built-in data structure does not include a stack, define a stack.\nsupport for NewStack() to create support Push(), Pop(), Peek(), Len(), Push supports any type (use assertion) 1package main 2 3import \u0026#34;sync\u0026#34; 4 5type ( 6\tStack struct { 7\ttop *node 8\tlength int 9\tlock *sync.RWMutex 10\t} 11\tnode struct { 12\tvalue interface{} 13\tprev *node 14\t} 15) 16 17// NewStack Create a new stack 18func NewStack() *Stack { 19\treturn \u0026amp;Stack{nil, 0, \u0026amp;sync.RWMutex{}} 20} 21 22// Len Return the number of items in the stack 23func (s *Stack) Len() int { 24\treturn s.length 25} 26 27// Peek View the top item on the stack 28func (s *Stack) Peek() interface{} { 29\tif s.length == 0 { 30\treturn nil 31\t} 32\treturn s.top.value 33} 34 35// Pop the top item of the stack and return it 36func (s *Stack) Pop() interface{} { 37\ts.lock.Lock() 38\tdefer s.lock.Unlock() 39\tif s.length == 0 { 40\treturn nil 41\t} 42\tn := s.top 43\ts.top = n.prev 44\ts.length-- 45\treturn n.value 46} 47 48// Push a value onto the top of the stack 49func (s *Stack) Push(value interface{}) { 50\ts.lock.Lock() 51\tdefer s.lock.Unlock() 52\tn := \u0026amp;node{value, s.top} 53\ts.top = n 54\ts.length++ 55} Stack code implementation with GetMin() method:\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5) 6 7type GetMinStack struct { 8\tstackData *Stack 9\tstackMin *Stack 10} 11 12func NewGetMinStack() *GetMinStack { 13\treturn \u0026amp;GetMinStack{ 14\tstackData: NewStack(), 15\tstackMin: NewStack(), 16\t} 17} 18 19func (gms *GetMinStack) Push(newNumber int) { 20\tif gms.stackMin.length == 0 { 21\tgms.stackMin.Push(newNumber) 22\t} else if newNumber \u0026lt;= gms.GetMin().(int) { 23\tgms.stackMin.Push(newNumber) 24\t} 25\tgms.stackData.Push(newNumber) 26} 27 28func (gms *GetMinStack) Pop() int { 29\tif gms.stackMin.length == 0 { 30\t_ = fmt.Errorf(\u0026#34;your stack is empty\u0026#34;) 31\treturn 0 32\t} 33\tvalue := gms.stackData.Pop() 34\tif value == gms.GetMin() { 35\tgms.stackMin.Pop() 36\t} 37\treturn value.(int) 38} 39 40func (gms *GetMinStack) GetMin() interface{} { 41\tif gms.stackMin.length == 0 { 42\t_ = fmt.Errorf(\u0026#34;your stack is empty\u0026#34;) 43\treturn 0 44\t} else { 45\treturn gms.stackMin.Peek() 46\t} 47} Test Cases 1package main 2 3import ( 4\t\u0026#34;testing\u0026#34; 5 6\t\u0026#34;github.com/stretchr/testify/assert\u0026#34; 7) 8 9// TDD 10func TestGetMinStack_GetMin(t *testing.T) { 11\t// define a getmin stack 12\ttests := []struct { 13\t// name 14\tname string 15 16\t// input section 17\tval func(gms *GetMinStack) 18 19\t// output section 20\twantRes interface{} 21\t}{ 22\t{ 23\tname: \u0026#34;getmin after push\u0026#34;, 24\tval: push, 25\twantRes: 1, 26\t}, 27\t{ 28\tname: \u0026#34;getmin after push and pop\u0026#34;, 29\tval: pushpop, 30\twantRes: 3, 31\t}, 32\t{ 33\tname: \u0026#34;getmin for empty GetMinStack\u0026#34;, 34\tval: empty, 35\t// default return 0 36\twantRes: 0, 37\t}, 38\t} 39\tfor _, tt := range tests { 40\tgms := NewGetMinStack() 41\tt.Run(tt.name, func(t *testing.T) { 42\ttt.val(gms) 43\tres := gms.GetMin() 44\tassert.Equal(t, tt.wantRes, res) 45\t}) 46\t} 47} 48 49func push(gms *GetMinStack) { 50\tgms.Push(5) 51\tgms.Push(3) 52\tgms.Push(1) 53\tgms.Push(8) 54} 55 56func pushpop(gms *GetMinStack) { 57\tgms.Push(5) 58\tgms.Push(3) 59\tgms.Push(1) 60\tgms.Push(8) 61\tgms.Pop() 62\tgms.Pop() 63} 64 65func empty(gms *GetMinStack) { 66} Result:\n1$ go test -run ^TestGetMinStack_GetMin$ -v . 2=== RUN TestGetMinStack_GetMin 3=== RUN TestGetMinStack_GetMin/getmin_after_push 4=== RUN TestGetMinStack_GetMin/getmin_after_push_and_pop 5=== RUN TestGetMinStack_GetMin/getmin_for_empty_GetMinStack 62022/08/30 15:14:48 your stack is empty 7--- PASS: TestGetMinStack_GetMin (0.00s) 8 --- PASS: TestGetMinStack_GetMin/getmin_after_push (0.00s) 9 --- PASS: TestGetMinStack_GetMin/getmin_after_push_and_pop (0.00s) 10 --- PASS: TestGetMinStack_GetMin/getmin_for_empty_GetMinStack (0.00s) 11PASS 12ok command-line-arguments 0.008s No matter how much data is in the stack, each time it is pressed in and popped out, it is compared with the data at the top of stackMin once, and the minimum value is always at the top of stackMin, so the time complexity is O(1), which satisfies the requirements of this question.\n","link":"https://zhangsiming-blyq.github.io/post/algorithm/1/","section":"post","tags":["algorithm","English"],"title":"ALGORITHM SERIES | Designing A Stack With 'getMin' Function"},{"body":" 在使用client-go的watch接口时候碰到异常退出问题，查了一下google没有多少信息，于是扒了一下代码，把自己踩的坑记录下来方便以后自查自纠。\n使用client-go watch接口 💡 全局的mycluster都等于*kubernetes.Clientset 1. 如何watch 由于kubernetes整合了etcd的watch功能，我们可以通过watch操作去建立一个长连接，不断的接收数据；这种方式要优于普通的反复轮询请求，降低server端的压力;\n使用client-go调用对应对象的Watch()方法之后，会返回一个watch.Event对象，可以对其使用ResultChan()接受watch到的对象。\n1pod, err := mycluster.Clusterclientset.CoreV1().Pods(appNamespace).Watch(context.TODO(), metav1.ListOptions{LabelSelector: label}) 2if err != nil { 3 log.Error(err) 4} 5... 6event, ok := \u0026lt;-pod.ResultChan() 7if !ok { 8 log.Error(err) 9} 异常：watch接口自动断开 1. 现象 在使用过程中，watch操作持续一段时间就会自动断开\n2. 排查 我们进入watch包里面找到streamwatcher.go，其中节选了一些重要片段：\n1type StreamWatcher struct { 2\tsync.Mutex 3\tsource Decoder 4\treporter Reporter 5\tresult chan Event 6\tstopped bool 7} 8... 9func NewStreamWatcher(d Decoder, r Reporter) *StreamWatcher { 10\tsw := \u0026amp;StreamWatcher{ 11\tsource: d, 12\treporter: r, 13\t// It\u0026#39;s easy for a consumer to add buffering via an extra 14\t// goroutine/channel, but impossible for them to remove it, 15\t// so nonbuffered is better. 16\tresult: make(chan Event), 17\t} 18\tgo sw.receive() 19\treturn sw 20} 21... 22func (sw *StreamWatcher) receive() { 23\tdefer close(sw.result) 24\tdefer sw.Stop() 25\tdefer utilruntime.HandleCrash() 26\tfor { 27\taction, obj, err := sw.source.Decode() 28\tif err != nil { 29\t// Ignore expected error. 30\tif sw.stopping() { 31\treturn 32\t} 33\tswitch err { 34\tcase io.EOF: 35\t// watch closed normally 36\tcase io.ErrUnexpectedEOF: 37\tklog.V(1).Infof(\u0026#34;Unexpected EOF during watch stream event decoding: %v\u0026#34;, err) 38\tdefault: 39\tif net.IsProbableEOF(err) || net.IsTimeout(err) { 40\tklog.V(5).Infof(\u0026#34;Unable to decode an event from the watch stream: %v\u0026#34;, err) 41\t} else { 42\tsw.result \u0026lt;- Event{ 43\tType: Error, 44\tObject: sw.reporter.AsObject(fmt.Errorf(\u0026#34;unable to decode an event from the watch stream: %v\u0026#34;, err)), 45\t} 46\t} 47\t} 48\treturn 49\t} 50\tsw.result \u0026lt;- Event{ 51\tType: action, 52\tObject: obj, 53\t} 54\t} 55} 3. 原因 结合代码看一下，StreamWatcher实现了Watch()方法，我们上述调用ResultChan()的时候，实际上返回的是这里的sw.result;\n再往下看新建StreamWatcher的时候，有一个”go sw.receive()”, 也就是几乎在新建对象的同步就开始接受处理数据了，最后看到sw的receive()方法可以看到，在处理数据的时候(sw.source.Decode()), 如果err不为nil, 会switch集中error情况，最后会直接return，然后defer sw.Stop()；\n也就是说如果接受数据解码的时候(sw.source.Decode()), 如果解码失败，那么StreamWatcher就被关闭了，那自然数据通道也就关闭了，造成”watch一段时间之后自动关闭的现象”。\n解决办法(1)：forinfor 那么既然是这种情况会导致watch断开，那么我们首先想到的就是暴力恢复这个StreamWatcher，代码实现如下：\n1for { 2\tpod, err := mycluster.Clusterclientset.CoreV1().Pods(appNamespace).Watch(context.TODO(), metav1.ListOptions{LabelSelector: label}) 3\tif err != nil { 4\tlog.Error(err) 5\t} 6loopier: 7\tfor { 8\tevent, ok := \u0026lt;-pod.ResultChan() 9\tif !ok { 10\ttime.Sleep(time.Second * 5) 11\tlog.Info(\u0026#34;Restarting watcher...\u0026#34;) 12\tbreak loopier 13\t} 14\t// your process logic 15\t} 16} 我们定义一层for嵌套，因为在上述退出的时候会先defer close(sw.result)，所以我们接受数据的通道也就是上面代码里的pod.ResultChan()就会关闭，然后我们加一个错误处理，等待5s之后，break掉这个loopier循环，让外层的for循环继续新建StreamWatcher继续监听数据。以此达到持续监听的效果，好处是实现简单，坏处是缺少错误判断，不能针对错误类型分别处理，对于一直出错的场景也只是无脑重启。\n解决办法(2)：retrywatcher 在官方代码下client-go/tools/watch/retrywatcher.go中其实官方给了一个标准解法，用于解决watch异常退出的问题，下面我们看下这种实现方式：\n1type RetryWatcher struct { 2\tlastResourceVersion string 3\twatcherClient cache.Watcher 4\tresultChan chan watch.Event 5\tstopChan chan struct{} 6\tdoneChan chan struct{} 7\tminRestartDelay time.Duration 8} 9... 10func newRetryWatcher(initialResourceVersion string, watcherClient cache.Watcher, minRestartDelay time.Duration) (*RetryWatcher, error) { 11\tswitch initialResourceVersion { 12\tcase \u0026#34;\u0026#34;, \u0026#34;0\u0026#34;: 13\t// TODO: revisit this if we ever get WATCH v2 where it means start \u0026#34;now\u0026#34; 14\t// without doing the synthetic list of objects at the beginning (see #74022) 15\treturn nil, fmt.Errorf(\u0026#34;initial RV %q is not supported due to issues with underlying WATCH\u0026#34;, initialResourceVersion) 16\tdefault: 17\tbreak 18\t} 19 20\trw := \u0026amp;RetryWatcher{ 21\tlastResourceVersion: initialResourceVersion, 22\twatcherClient: watcherClient, 23\tstopChan: make(chan struct{}), 24\tdoneChan: make(chan struct{}), 25\tresultChan: make(chan watch.Event, 0), 26\tminRestartDelay: minRestartDelay, 27\t} 28 29\tgo rw.receive() 30\treturn rw, nil 31} 和普通的StreamWatcher很类似，这里面RetryWatcher多了一些结构体字段；lastResourceVersion、minRestartDelay用于出错之后重启Watcher的RV保存，以及重试时间；传入initialResourceVersion和watcherClient(cache.Watcher)即可创建一个RetryWatcher;\n同理，RetryWatcher也是在创建对象的同时就开始go rw.receive()接受数据。\n1func (rw *RetryWatcher) receive() { 2\tdefer close(rw.doneChan) 3\tdefer close(rw.resultChan) 4 5\tklog.V(4).Info(\u0026#34;Starting RetryWatcher.\u0026#34;) 6\tdefer klog.V(4).Info(\u0026#34;Stopping RetryWatcher.\u0026#34;) 7 8\tctx, cancel := context.WithCancel(context.Background()) 9\tdefer cancel() 10\tgo func() { 11\tselect { 12\tcase \u0026lt;-rw.stopChan: 13\tcancel() 14\treturn 15\tcase \u0026lt;-ctx.Done(): 16\treturn 17\t} 18\t}() 19 20\t// We use non sliding until so we don\u0026#39;t introduce delays on happy path when WATCH call 21\t// timeouts or gets closed and we need to reestablish it while also avoiding hot loops. 22\twait.NonSlidingUntilWithContext(ctx, func(ctx context.Context) { 23\tdone, retryAfter := rw.doReceive() 24\tif done { 25\tcancel() 26\treturn 27\t} 28 29\ttime.Sleep(retryAfter) 30 31\tklog.V(4).Infof(\u0026#34;Restarting RetryWatcher at RV=%q\u0026#34;, rw.lastResourceVersion) 32\t}, rw.minRestartDelay) 33} 34... 35func (rw *RetryWatcher) Stop() { 36\tclose(rw.stopChan) 37} 上面代码的receive()函数中，wait包起到核心重试逻辑作用，他会循环执行里面的函数，直到收到context Done 的信号才会往下走；而上面代码的ctx只有两种情况才会被关闭：\n有人调用了RetryWatcher的Stop()； 另外就是rw.doReceive()中返回了done, 也会直接调用cancel()结束wait部分。 而如果接受的done为false，则会正常等待time.Sleep(retryAfter)之后，进行重试，实现RetryWatcher！\n接下来就看下这个rw.doReceive()，也就是RetryWatcher的接收处理数据部分, 同时会根据err类型判断是否应该重试：\n1func (rw *RetryWatcher) doReceive() (bool, time.Duration) { 2\twatcher, err := rw.watcherClient.Watch(metav1.ListOptions{ 3\tResourceVersion: rw.lastResourceVersion, 4\tAllowWatchBookmarks: true, 5\t}) 6\t// We are very unlikely to hit EOF here since we are just establishing the call, 7\t// but it may happen that the apiserver is just shutting down (e.g. being restarted) 8\t// This is consistent with how it is handled for informers 9\tswitch err { 10... 11// 省略watch的一些错误处理，都会返回false，也就是继续wait重试 12... 13\t} 14 15\tif watcher == nil { 16\tklog.Error(\u0026#34;Watch returned nil watcher\u0026#34;) 17\t// Retry 18\treturn false, 0 19\t} 20 21\tch := watcher.ResultChan() 22\tdefer watcher.Stop() 23 24\tfor { 25\tselect { 26\tcase \u0026lt;-rw.stopChan: 27\tklog.V(4).Info(\u0026#34;Stopping RetryWatcher.\u0026#34;) 28\treturn true, 0 29\tcase event, ok := \u0026lt;-ch: 30\tif !ok { 31\tklog.V(4).Infof(\u0026#34;Failed to get event! Re-creating the watcher. Last RV: %s\u0026#34;, rw.lastResourceVersion) 32\treturn false, 0 33\t} 34 35\t// We need to inspect the event and get ResourceVersion out of it 36\tswitch event.Type { 37\tcase watch.Added, watch.Modified, watch.Deleted, watch.Bookmark: 38\tmetaObject, ok := event.Object.(resourceVersionGetter) 39\t... 40\tresourceVersion := metaObject.GetResourceVersion() 41\t... 42 // All is fine; send the non-bookmark events and update resource version. 43\tif event.Type != watch.Bookmark { 44\tok = rw.send(event) 45\tif !ok { 46\treturn true, 0 47\t} 48\t} 49\trw.lastResourceVersion = resourceVersion 50 51\tcontinue 52 53\tcase watch.Error: 54\t... 55\t} 56\t} 57\t} 58} 59... 60func (rw *RetryWatcher) send(event watch.Event) bool { 61\t// Writing to an unbuffered channel is blocking operation 62\t// and we need to check if stop wasn\u0026#39;t requested while doing so. 63\tselect { 64\tcase rw.resultChan \u0026lt;- event: 65\treturn true 66\tcase \u0026lt;-rw.stopChan: 67\treturn false 68\t} 69} 上面代码我已经非常清晰的展示出了doReceive()的处理逻辑，第一步会按照rw中定义的watcher开始真实的监听对应资源对象，这里返回错误的话也会进行rw的重试逻辑；然后会获取真实的watcher.ResultChan()也就是可以获取到真实对象的通道，套用for select模式，循环接受数据，如果数据一直是正常的，那么会通过rw.send(event)发送给rw.ResultChan，然后记录保存rw.lastResourceVersion然后继续接收，实现watch的功能；\n这里多说一句，由于rw.lastResourceVersion是保存在rw的，也就是及时重启(对应上面的任意一个case返回的是true)，会从rw.lastResourceVersion也就是最新的RV开始监听，这样实现根据特定原因重启故障的watcher，比较合理，也很巧妙，是官方的标准答案。\n个人版RetryWatcher代码实现： 说了那么多，那么具体要怎么使用这个RetryWatcher呢？我个人做了一个妥协方案可以参考：\n还记得RetryWatcher中定义的watcherClient类型吗，需要是cache.Watcher，然后我们看client-go/tools/cache里面定义的cache.Watcher接口，定义如下：\n1type Watcher interface { 2\t// Watch should begin a watch at the specified version. 3\tWatch(options metav1.ListOptions) (watch.Interface, error) 4} 也就是实现了Watch(xxxx)这个方法的就是符合的cache.Watcher; 而最开始我们代码正好是通过MyCluster.Clusterclientset.CoreV1().Pods()返回的接口v1.PodInterface中调用的Watch(xxxxx), 那么直接用“MyCluster.Clusterclientset.CoreV1().Pods()”来生成RetryWatcher是不是就行了！\n我们来看一下这个接口类型：\n1type PodInterface interface { 2\t... 3\tWatch(ctx context.Context, opts metav1.ListOptions) (watch.Interface, error) 4\t... 5} 答案是不行… 下面这个多了一个ctx参数 🥶，但是我们就是想从Clientset这里用怎么办，自己实现一个符合的结构吧：\n1type PodListWatch struct { 2\tMyCluster *initk8s.MyCluster 3\tAppNamespace string 4} 5// watch指定命名空间下的Pod例子 6func (p PodListWatch) Watch(options metav1.ListOptions) (watch.Interface, error) { 7\treturn p.MyCluster.Clusterclientset.CoreV1().Pods(p.AppNamespace).Watch(context.TODO(), options) 8} 这个PodListWatch的Watch(xxxx)方法正好满足cache.Watcher, 单后watch的方式还是按照我们原先Clientset的，然后生成RetryWatcher的方式如下：\n1func ResourceWatcher(mycluster *initk8s.MyCluster, appNamespace string) { 2\tpodWatcher := PodListWatch{MyCluster: mycluster, AppNamespace: appNamespace} 3\t// generate new retrywatcher, use podRetryWatcher.ResultChan() to keep a chronic watch operation 4\tpodRetryWatcher, err := retrywatcher.NewRetryWatcher(label, podWatcher) 5\tif err != nil { 6\tlog.Error(err) 7\t} 8FORWATCHER: 9\tfor { 10\tselect { 11\tcase \u0026lt;-podRetryWatcher.Done(): 12\tlog.Info(\u0026#34;Retrywatcher is exiting, please check...\u0026#34;) 13\tbreak FORWATCHER 14\tcase event, ok := \u0026lt;-podRetryWatcher.ResultChan(): 15\tif !ok { 16\tlog.Warn(\u0026#34;Retrywatcher is not open, please check...\u0026#34;) 17\tcontinue 18\t} 19\t... 上述只是一种思路提供，希望能够帮到使用client-go进行watch的同学；官方的实现RetryWatcher确实更加合理，还可以进行改造加减不同情况是否重试的策略。另外watch方法毕竟是直接和kubernetes中的apiserver沟通，如果想要减轻apiserver的压力kubernetes提供了更加常用的informer机制(sharedinformer也是众多controller使用的，同时也是我认为kubernetes最核心的功能)，至于使用informer就又有很多要说的了，以后有时间可能会更新~\n","link":"https://zhangsiming-blyq.github.io/post/golang/retrywatcher/","section":"post","tags":["golang","kubernetes","中文"],"title":"client-go watch接口隔一段时间自动退出怎么办？"},{"body":" Explain the common usage scenarios of iterators, generators, and yield fields in Python.\nIterators Python object implements iter() and next() methods, we become iterable objects (iterables), through iter() can return an iterator object (iterators).\n__iter__() method: return the iterator object itself __next__() method: returns the next element of the container, and raises a StopIteration Exception at the end to terminate the iterator 1lst = [1, 2, 3] 2print(type(lst)) 3new_iter = lst.__iter__() 4print(type(new_iter)) 5 6# Output 7\u0026lt;class \u0026#39;list\u0026#39;\u0026gt; 8\u0026lt;class \u0026#39;list_iterator\u0026#39;\u0026gt; The for loop actually gets iterators by iter() and then does next() to fetch until StopIteration.\nGenerators\u0026amp;yield Generators are a special kind of iterators. If a field exists anywhere in the function, when you call the function, the function will not execute directly, but will return a generator. In addition generators also support generator expressions (similar to lists, except that [] is replaced with ()).\n1def test(): 2 print(\u0026#34;for test\u0026#34;) 3 yield 0 4gen1 = test() 5print(type(gen1)) 6gen2 = (x*x for x in range(0, 3)) 7print(type(gen2)) 8 9# Output 10\u0026lt;class \u0026#39;generator\u0026#39;\u0026gt; 11\u0026lt;class \u0026#39;generator\u0026#39;\u0026gt; yield Unlike iterators, which store all of their content in memory, generators allocate memory as next() is called over and over again.\nEach time generators will run to the yield field, then save the generator state and return; the next call to next() will continue from the current position to the next yield field. This continues until StopIteration stops. Take a look at the following example:\n1def test(): 2 print(\u0026#34;start\u0026#34;) 3 yield 0 4 print(\u0026#34;end\u0026#34;) 5 yield 1 6 7gen1 = test() 8print(gen1.__next__()) 9print(gen1.__next__()) 10 11print(\u0026#34;\u0026#34;) 12gen2 = (x*x for x in range(0, 3)) 13print(gen2.__next__()) 14print(gen2.__next__()) 15print(gen2.__next__()) 16print(gen2.__next__()) 17 18# Output 19start 200 21end 221 23 240 251 264 27Traceback (most recent call last): 28 File \u0026#34;/home/vagrant/aa.py\u0026#34;, line 16, in \u0026lt;module\u0026gt; 29 print(gen2.__next__()) 30StopIteration Yield In Action We have a batch of 100 pieces of data in a list and want to divide it into 10 groups of 10 and process them separately:\n1def chunks(lst, n): 2 \u0026#34;\u0026#34;\u0026#34;Yield successive n-sized chunks from lst.\u0026#34;\u0026#34;\u0026#34; 3 for i in range(0, len(lst), n): 4 yield lst[i:i + n] 5 6origin_lst = list(range(0, 100)) 7for i in chunks(origin_lst, 10): 8 print(i) 9 10# Output 11[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 12[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] 13[20, 21, 22, 23, 24, 25, 26, 27, 28, 29] 14[30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 15[40, 41, 42, 43, 44, 45, 46, 47, 48, 49] 16[50, 51, 52, 53, 54, 55, 56, 57, 58, 59] 17[60, 61, 62, 63, 64, 65, 66, 67, 68, 69] 18[70, 71, 72, 73, 74, 75, 76, 77, 78, 79] 19[80, 81, 82, 83, 84, 85, 86, 87, 88, 89] 20[90, 91, 92, 93, 94, 95, 96, 97, 98, 99] Reference Links:\nhttps://blog.csdn.net/Yuyh131/article/details/83310486 https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do ","link":"https://zhangsiming-blyq.github.io/post/python/python-yield/","section":"post","tags":["python","English"],"title":"Python Yield"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/apiserver/","section":"tags","tags":null,"title":"apiserver"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/controller-manager/","section":"tags","tags":null,"title":"controller-manager"},{"body":" 对于 kubernetes 集群的控制平面组件，监控是必要的, 他可以帮助我们获取到集群的整体负载压力，并在核心组件出问题的时候配合告警让管理员及时发现问题，及时处理，更稳定的保证集群的生命周期。\n一、Prometheus 如何自动发现 Kubernetes Metrics 接口? prometheus 收集 kubernetes 集群中的指标有两种方式，一种是使用 crd(servicemonitors.monitoring.coreos.com)的方式，主要通过标签匹配；另一种是通过 scrape_config，支持根据配置好的\u0026quot;relabel_configs\u0026quot;中的具体目标, 进行不断拉取(拉取间隔为\u0026quot;scrape_interval\u0026quot;)\n配置权限： k8s 中 RBAC 支持授权资源对象的权限，比如可以 get、list、watch 集群中的 pod，还支持直接赋予对象访问 api 路径的权限，比如获取/healthz, /api 等, 官方对于 non_resource_urls 的解释如下：\nnon_resource_urls - (Optional) NonResourceURLs is a set of partial urls that a user should have access to. *s are allowed, but only as the full, final step in the path Since non-resource URLs are not namespaced, this field is only applicable for ClusterRoles referenced from a ClusterRoleBinding. Rules can either apply to API resources (such as \u0026quot;pods\u0026quot; or \u0026quot;secrets\u0026quot;) or non-resource URL paths (such as \u0026quot;/api\u0026quot;), but not both.\n既然 prometheus 要主动抓取指标，就必须对他使用的 serviceaccount 提前进行 RBAC 授权：\n1# clusterrole.yaml 2apiVersion: rbac.authorization.k8s.io/v1 3kind: ClusterRole 4metadata: 5 name: monitor 6rules: 7- apiGroups: [\u0026#34;\u0026#34;] 8 resources: 9 - nodes 10 - pods 11 - endpoints 12 - services 13 verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] 14- nonResourceURLs: [\u0026#34;/metrics\u0026#34;] 15 verbs: [\u0026#34;get\u0026#34;] 16 17# clusterrolebinding 18apiVersion: rbac.authorization.k8s.io/v1 19kind: ClusterRoleBinding 20metadata: 21 name: prometheus-api-monitor 22roleRef: 23 apiGroup: rbac.authorization.k8s.io 24 kind: ClusterRole 25 name: monitor 26subjects: 27- kind: ServiceAccount 28 name: prometheus-operator-nx-prometheus 29 namespace: monitor 获取 apiserver 自身的 metric 信息： prometheus 中配置\u0026quot;scrape_config\u0026quot;, 或者 prometheus-operator 中配置\u0026quot;additionalScrapeConfigs\u0026quot;, 配置获取 default 命名空间下的 kubernetes endpoints\n1- job_name: \u0026#39;kubernetes-apiservers\u0026#39; 2 kubernetes_sd_configs: 3 - role: endpoints 4 scheme: https 5 tls_config: 6 ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt 7 bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token 8 relabel_configs: 9 - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] 10 action: keep 11 regex: default;kubernetes;https 获取 controller-manager、scheduler 的 metric 信息： controller-manager 和 scheduler 因为自身暴露 metric 接口，需要修改对应 manifests 下的静态 pod 文件，添加匹配的 annotations 即可完成抓取：\n1# prometheus端配置 2kubernetes_sd_configs: 3 - role: pod 4 relabel_configs: 5 - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] 6 action: \u0026#34;keep\u0026#34; 7 regex: \u0026#34;true\u0026#34; 8 - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] 9 action: replace 10 regex: ([^:]+)(?::\\d+)?;(\\d+) 11 replacement: $1:$2 12 target_label: __address__ 13 - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] 14 action: replace 15 target_label: __metrics_path__ 16 regex: \u0026#34;(.+)\u0026#34; 17 - action: labelmap 18 regex: __meta_kubernetes_pod_label_(.+) 19 - source_labels: [__meta_kubernetes_namespace] 20 action: replace 21 target_label: kubernetes_namespace 22 - source_labels: [__meta_kubernetes_pod_name] 23 action: replace 24 target_label: kubernetes_pod_name 25 26# controller-manager配置: 27metadata: 28 annotations: 29 prometheus_io_scrape: \u0026#34;true\u0026#34; 30 prometheus.io/port: \u0026#34;10252\u0026#34; 31 32# scheduler配置： 33metadata: 34 annotations: 35 prometheus_io_scrape: \u0026#34;true\u0026#34; 36 prometheus.io/port: \u0026#34;10251\u0026#34; 获取 etcd 的 metric 信息： etcd 是跑在物理机上的，所以我们先创建对应的 endpoints 绑定好 service，然后采用 servicemonitor 的方式去匹配获取 etcd 的监控指标：\n1# service.yaml 2apiVersion: v1 3kind: Service 4metadata: 5 name: etcd-k8s 6 namespace: kube-system 7 labels: 8 k8s-app: etcd 9spec: 10 type: ClusterIP 11 clusterIP: None 12 ports: 13 - name: port 14 port: 2379 15 protocol: TCP 16 17# endpoint.yaml 18apiVersion: v1 19kind: Endpoints 20metadata: 21 name: etcd-k8s 22 namespace: kube-system 23 labels: 24 k8s-app: etcd 25subsets: 26- addresses: 27 - ip: xx.xx.xx.xx 28 - ip: xx.xx.xx.xx 29 - ip: xx.xx.xx.xx 30 ports: 31 - name: port 32 port: 2379 33 protocol: TCP 34 35# servicemonitor.yaml(需要配置好相关的证书) 36apiVersion: monitoring.coreos.com/v1 37kind: ServiceMonitor 38metadata: 39 name: etcd-k8s 40 namespace: monitor 41 labels: 42 k8s-app: etcd-k8s 43 release: prometheus-operator-nx 44spec: 45 jobLabel: k8s-app 46 endpoints: 47 - port: port 48 interval: 30s 49 scheme: https 50 tlsConfig: 51 caFile: /ca.pem 52 certFile: /server.pem 53 keyFile: /server-key.pem 54 insecureSkipVerify: true 55 selector: 56 matchLabels: 57 k8s-app: etcd 58 namespaceSelector: 59 matchNames: 60 - kube-system 61 62# 最后附上etcd secret的创建方法，将etcd证书挂载进入提供连接使用 63apiVersion: v1 64data: 65 ca.pem: xx 66 server.pem: xx 67 server-key.pem: xx 68kind: Secret 69metadata: 70 name: etcd-certs 71 namespace: monitor 72type: Opaque 二、我该重点关注哪些 control plane 指标？ apiserver: 其中计算延迟可以采用\u0026quot;percentiles\u0026quot;而不是平均数去更好的展示延迟出现情况 apiserver_request_duration_seconds: 计算读(Non-LIST)请求，读(LIST)请求，写请求的平均处理时间\napiserver_request_total: 计算 apiserver 的 QPS、计算读请求、写请求的成功率; 还可以计算请求错误数量以及错误码\napiserver_current_inflight_requests: 计算正在处理的读、写请求\napiserver_dropped_requests_total: 计算失败的请求\ncontroller-manager: leader_election_master_status: 关注是否有 leader\nxxx_depth: 关注正在调和的控制队列深度\nscheduler: leader_election_master_status: 关注是否有 leader\nscheduler_schedule_attempts_total: 帮助查看是否调度器不能正常工作; Number of attempts to schedule pods, by the result. 'unschedulable' means a pod could not be scheduled, while 'error' means an internal scheduler problem\nscheduler_e2e_scheduling_duration_seconds_sum: scheduler 调度延迟(参数弃用)\nrest_client_requests_total: client 请求次数(次重要); Number of HTTP requests, partitioned by status code, method, and host\netcd: etcd_server_has_leader: etcd 是否有 leader\netcd_server_leader_changes_seen_total: etcd leader 切换的次数，如果太频繁可能是一些连接不稳定现象或者 etcd 集群负载过大\netcd_server_proposals_failed_total: 一个提议请求是需要完整走过 raft protocol 的，这个指标帮助我们提供请求出错次数，大多数情况是 etcd 选举 leader 失败或者集群缺乏选举的候选人\netcd_disk_wal_fsync_duration_seconds_sum/etcd_disk_backend_commit_duration_seconds_sum: etcd 磁盘存储了 kubernetes 的所有重要信息，如果磁盘同步有很大延迟会影响 kubernetes 集群的操作, 此指标提供了 etcd 磁盘同步的平均延迟\netcd_debugging_mvcc_db_total_size_in_bytes: etcd 各节点容量\netcd_network_peer_sent_bytes_total/etcd_network_peer_received_bytes_total: 可以计算 etcd 节点的发送/接收数据速率\ngrpc_server_started_total: 可以用于计算 etcd 各个方法的调用速率\n最后采用的 kubernetes 维护界面由：apiserver 专用仪表盘、etcd 仪表盘、综合控制平面仪表盘和证书监控组成；并且在维护使用过程中根据不同参数，不断调整, 够用就行。\n参考链接: https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/cluster_role\nhttps://prometheus.io/docs/prometheus/latest/configuration/configuration/\nhttps://www.datadoghq.com/blog/kubernetes-control-plane-monitoring/\nhttps://sysdig.com/blog/monitor-kubernetes-api-server/\nhttps://sysdig.com/blog/monitor-etcd/\n","link":"https://zhangsiming-blyq.github.io/post/kubernetes/monitor-control-plane/","section":"post","tags":["kubernetes","apiserver","etcd","controller-manager","scheduler","中文"],"title":"prometheus 监测 kubernetes 控制平面"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/scheduler/","section":"tags","tags":null,"title":"scheduler"},{"body":"+++ title = \u0026quot;Search\u0026quot; searchPage = true type = \u0026quot;search\u0026quot; +++\n","link":"https://zhangsiming-blyq.github.io/search/","section":"","tags":null,"title":""},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/about/","section":"tags","tags":null,"title":"about"},{"body":"Embrace the IT World: A Guide to Kubernetes, Go Language, Python, Shell, and Linux\nIntroduction NOTE: 1-2 articles are updated per week on average.\nDear readers,\nI'm excited to announce that I'll be writing blog posts in both English and Chinese moving forward! I understand that some of you may prefer reading in English while others prefer reading in Chinese, so I want to cater to both audiences.\nTo make it easy for you to find the posts you're interested in, I'll be using tags to separate the English posts from the Chinese ones. English posts will be tagged as \u0026quot;English\u0026quot; and Chinese posts will be tagged as \u0026quot;中文\u0026quot;. That way, you can easily find the posts that are written in your preferred language.\nThank you for your continued support, and I hope you enjoy reading my bilingual blog!\nFocus On The world of information technology is rapidly evolving, and it can be challenging to keep up with the latest developments. However, with the right mindset, tools, and resources, you can not only keep up but also excel in this field. In this blog post, we will explore some of the most important topics in the IT world, including Kubernetes, Golang, Python, Shell, and Linux. Whether you are a beginner or an experienced IT professional, this guide will provide you with valuable insights and practical tips to help you succeed in your career.\nLife Advices Don't stop learning; continually acquire new knowledge and skills to help you improve your work and boost your confidence.\nBuild strong relationships: Focus on building strong relationships with your family, friends and colleagues. Surround yourself with positive and supportive people who will inspire and motivate you to be your best self.\nTake risks: Don't be afraid to take risks and try new things. Failure is often the best teacher and it can help you learn and grow as a person. Taking calculated risks will help you step out of your comfort zone and gain valuable experience.\nLearn to manage your finances wisely, including budgeting, saving, and investing. This will provide financial stability and security for your future.\nWork-life balance is crucial. You should also schedule time for your favorite hobbies and allocated some personal leisure.\nStay healthy: Take care of your physical and mental health. Get enough sleep, eat a balanced diet, exercise regularly and take time to de-stress. This will help you maintain a positive outlook on life and enjoy it to the fullest.\nLearn from your mistakes: Nobody is perfect, and we all make mistakes. Instead of dwelling on your mistakes, focus on learning from them and growing as a person.\nPursue your passions: Pursue what makes you happy, whether it's a hobby(money, healthy, creative, knowledge, mindset) or a career. Finding meaning and purpose in your life will give you a sense of fulfillment and happiness.\nTime is your most valuable resource. Use it wisely and prioritize the things that matter most to you.\nSet goals and create a plan to achieve them. This will give you direction and purpose in life.\nConclusion By mastering Kubernetes, Golang, Python, Shell, and Linux, you can become a well-rounded IT professional with a diverse set of skills and knowledge. These technologies are not only useful for building cutting-edge software and systems but also for improving your productivity, efficiency, and problem-solving abilities. Remember, it's never too late to start studying and making progress. Stay focused, stay motivated, and do your best.\nAs a reminder, all content on this website is based on the principles of spreading positive energy and promoting mutual learning. We may reference some publicly available content on the internet. If there is any copyright infringement, please contact us at zhangsiming10307@gmail.com to request removal. Thank you for your understanding and support.\n","link":"https://zhangsiming-blyq.github.io/about/","section":"","tags":["about","bailiyingqi","English"],"title":"About me"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/bailiyingqi/","section":"tags","tags":null,"title":"bailiyingqi"},{"body":"","link":"https://zhangsiming-blyq.github.io/tags/containerd/","section":"tags","tags":null,"title":"containerd"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/containerd/","section":"categories","tags":null,"title":"containerd"},{"body":"","link":"https://zhangsiming-blyq.github.io/categories/docker/","section":"categories","tags":null,"title":"docker"},{"body":" 伴随着kubernetes对docker的弃用，containerd开始进入大众视野；相比于kubelet中集成docker-shim连接docker，docker再次条用containerd去管理容器，直接使用containerd可以通过原生CRI接口的调用实现容器runtime，简化了调用链路，更加的灵活可靠。\n一、安装使用 ctr 管理 containerd 1# Install Dependent Libraries 2$ sudo apt-get update 3$ sudo apt-get install libseccomp2 4 5# 下载 6# 目前是下载的1.5.2 7$ wget https://github.com/containerd/containerd/releases/download/v${VERSION}/cri-containerd-cni-${VERSION}-linux-amd64.tar.gz 8 9# 安装 10$ sudo tar --no-overwrite-dir -C / -xzf cri-containerd-cni-${VERSION}-linux-amd64.tar.gz 11# 初始化containerd配置 12$ containerd config default \u0026gt; /etc/containerd/config.toml 13# 修改默认的sandbox_image 14$ vim /etc/containerd/config.toml 15... 16sandbox_image = \u0026#34;registry.cn-beijing.aliyuncs.com/shannonai-k8s/pause:3.1\u0026#34; 17... 18 19# 启动服务 20sudo systemctl daemon-reload 21sudo systemctl start containerd 22 23# 查看版本 24$ ctr version 25Client: 26 Version: 1.4.3 27 Revision: 269548fa27e0089a8b8278fc4fc781d7f65a939b 28 Go version: go1.13.15 29 30Server: 31 Version: 1.4.3 32 Revision: 269548fa27e0089a8b8278fc4fc781d7f65a939b 33 UUID: b7e3b0e7-8a36-4105-a198-470da2be02f2 二、containerd 使用 2.1 运行一个 busybox 镜像： demo: 1# 拉取镜像 2$ ctr -n k8s.io i pull docker.io/library/busybox:latest 3# 创建一个container(此时还未运行) 4$ ctr -n k8s.io container create docker.io/library/busybox:latest busybox 5# 创建一个task 6$ ctr -n k8s.io task start -d busybox 7 8# 上述步骤也可以简写成如下 9$ ctr -n k8s.io run -d docker.io/library/busybox:latest busybox 查看容器在宿主机的 pid，及状态:\n1$ ctr -n k8s.io task ls 2TASK PID STATUS 3busybox 2356 RUNNING 进入容器：\n1$ ctr -n k8s.io t exec --exec-id $RANDOM -t busybox sh 杀死移除容器：\n1$ ctr -n k8s.io t kill -s SIGKILL busybox 2$ ctr -n k8s.io t rm busybox 3WARN[0000] task busybox exit with non-zero exit code 137 2.2 其他 ctr 命令 镜像标记:\n1$ ctr -n k8s.io i tag A B 2# 若新镜像reference 已存在, 需要先删除新reference, 或者如下方式强制替换 3$ ctr -n k8s.io i tag --force A B 删除镜像:\n1$ ctr -n k8s.io i rm A 拉取镜像:\n1$ ctr -n k8s.io i pull -k A 查看镜像:\n1$ ctr -n k8s.io i ls 推送镜像:\n1$ ctr -n k8s.io i push -k A 导出镜像:\n1$ ctr -n k8s.io i export A.tar A 导入镜像:\n1$ ctr -n k8s.io i import A.tar 读取日志: 导出到文件中进行读取:\n1$ ctr -n k8s.io run --log-uri file:///var/log/xx.log 三、containerd + docker 安装新版本的 docker-ce 默认，采用 containerd(--containerd=/run/containerd/containerd.sock)\n1$ systemctl status docker 2● docker.service - Docker Application Container Engine 3 Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) 4 Active: active (running) since 四 2021-06-10 15:46:44 CST; 1h 46min ago 5 Docs: https://docs.docker.com 6 Main PID: 4965 (dockerd) 7 CGroup: /system.slice/docker.service 8 ├─1830 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/e0a50564d9a23a85240f54f3bf 9 ├─4965 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 10 ├─5402 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8082 -container-ip 172.17.0.2 -container-port 80 11 └─5417 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 8082 -container-ip 172.17.0.2 -container-port 80 注意： ctr 直接跑起来一个容器只有 lo 网卡，也就是无法与外网通信；如果想连接外网，请参考 其他参考链接:\nhttps://mp.weixin.qq.com/s/A9zU7gZH0liLjc-e-dhk8A\nhttps://blog.csdn.net/tongzidane/article/details/114587138\nhttps://github.com/containerd/containerd/blob/master/docs/cri/installation.md\n","link":"https://zhangsiming-blyq.github.io/post/kubernetes/containerd/","section":"post","tags":["kubernetes","containerd","中文"],"title":"浅谈 containerd"},{"body":"","link":"https://zhangsiming-blyq.github.io/series/","section":"series","tags":null,"title":"Series"}]
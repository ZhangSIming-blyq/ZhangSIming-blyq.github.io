<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>https://zhangsiming-blyq.github.io/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright>
    <lastBuildDate>Tue, 08 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://zhangsiming-blyq.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes 存储管理</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/storage/</link>
      <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/storage/</guid>
      <description>
        
          
            1. Dynamic Provisioner 例子与完整流程介绍 原理概述 在 Kubernetes 中，动态 provisioner 是一个实现了 Provisioner 接口的控制器，用于自动化存储卷的创建。当用户提交 PVC (PersistentVolumeClaim) 时，provisioner 根据定义的 StorageClass，自动创建相应的 PV (PersistentVolume)。这种自动化存储管理机制大大简化了卷的生命周期管理，减少了手动操作的复杂性。
流程概述 自定义动态 provisioner 的流程包括以下几个步骤：
创建自定义的 Provisioner 逻辑，负责监听 PVC 的创建事件，并生成 PV。 编写自定义的 StorageClass，使用该 Provisioner 动态创建卷。 编写控制器代码，处理卷的创建与删除。 部署自定义 provisioner 到 Kubernetes 集群中，并验证其功能。 步骤 1: 自定义 Provisioner 代码实现 https://github.com/ZhangSIming-blyq/custom-provisioner
首先，我们通过 Go 语言编写一个简单的自定义 provisioner，模拟卷的创建和删除过程。核心是自定义Provisioner结构体，实现Provision和Delete方法。Provision方法用于创建卷，Delete方法用于删除卷。
1package main 2 3import ( 4	&amp;#34;context&amp;#34; 5	&amp;#34;fmt&amp;#34; 6	corev1 &amp;#34;k8s.io/api/core/v1&amp;#34; 7	metav1 &amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34; 8	&amp;#34;k8s.io/client-go/kubernetes&amp;#34; 9	&amp;#34;k8s.io/client-go/rest&amp;#34; 10	&amp;#34;k8s.io/klog&amp;#34; 11	&amp;#34;os&amp;#34; 12	&amp;#34;sigs.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Golang 核心知识点详解文档</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/core/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/core/</guid>
      <description>
        
          
            1. GMP 调度模型 1.1 GMP 概述 Go 语言中的 GMP 模型是 Goroutine 的调度机制，通过三个核心概念实现并发任务的高效调度：
G（Goroutine）：轻量级线程，每个 G 代表一个独立的任务。 M（Machine）：代表操作系统的线程，负责执行 G。 P（Processor）：逻辑处理器，管理 G 的队列，绑定 M 来调度 G。 1.2 调度模型的原理 工作窃取（Work Stealing）：当一个 P 没有要执行的 Goroutine 时，它会从其他 P 中窃取任务执行，以保持负载平衡。 Hand-off（任务交接）：Hand Off 是 Go 调度系统中的优化机制。当一个 M（Machine）由于执行系统调用、I/O 或锁等待等操作被阻塞时，P（Processor）会与 M 解除绑定，将 M 上的 Goroutine 放回全局队列或等待队列中，以便其他空闲的 M 或 P 能继续执行这些任务。通过这种任务交接的方式，Go 可以避免 Goroutine 长时间停留在阻塞的 M 上，保持高效的调度，确保系统资源得到充分利用。 抢占式调度：从 Go 1.14 开始，长时间占用 CPU 的 Goroutine 会被强制中断，允许其他 Goroutine 执行，避免单个 Goroutine 独占 CPU。 代码示例：Goroutine 调度 1package main 2 3import ( 4 &amp;#34;fmt&amp;#34; 5 &amp;#34;time&amp;#34; 6) 7 8func worker(id int) { 9 fmt.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes 中 GPU 虚拟化与 NVIDIA GPU Operator 管理概述</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/gpu-operator/</link>
      <pubDate>Sat, 21 Sep 2024 18:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/gpu-operator/</guid>
      <description>
        
          
            在 Kubernetes 集群中，通过 NVIDIA GPU Operator 管理 GPU 资源，实现 GPU 虚拟化和显卡的分配。NVIDIA GPU Operator 通过协调 GPU 相关组件，确保 GPU 能够被 Kubernetes 中的 Pod 正常使用，并且能够动态申请显卡和显存资源。这一切通过容器化的方式进行封装和管理，使得 GPU 能够无缝融入 Kubernetes 的计算资源池中。
1. GPU Operator 组件职能 NVIDIA GPU Operator 是一个 Kubernetes Operator，用来自动化 GPU 资源的管理。它通过以下四个主要组件实现 GPU 的启用、监控和分配：
NVIDIA Driver Manager：此组件负责安装和管理 Kubernetes 节点上所需的 NVIDIA 驱动程序。通过安装 NVIDIA 驱动，使得 GPU 可以被宿主机和容器识别和使用。每个 Kubernetes 节点必须具备正确的 NVIDIA 驱动，确保 GPU 能够被 Kubernetes 节点访问。
NVIDIA Container Toolkit (nvidia-docker)：负责将 GPU 能力暴露给容器。它为容器提供了一种与宿主机 GPU 通信的机制，使得容器内部的进程能够访问 GPU。这个组件还包括 nvidia-smi 工具的集成，使容器内部能够执行 GPU 状态检查（如显存使用情况、温度等）。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes 中 Cilium 网络架构详解与流量处理流程</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/cilium/</link>
      <pubDate>Sat, 21 Sep 2024 16:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/cilium/</guid>
      <description>
        
          
            1. Cilium 和 Cilium-Operator 的网络架构 在 Kubernetes 集群中，我们使用 Cilium 作为网络插件，基于 eBPF 提供高效的网络功能，如流量控制、负载均衡、网络安全策略等。同时，Cilium-Operator 负责管理集群范围的 Cilium 操作，包括 IP 地址管理、服务发现、BGP 宣告和配置同步等。
2. IP 分配与 Cilium-Host 的作用 2.1 Cilium 如何分配 IP 地址 Pod 创建时的 IP 分配：当 Kubernetes 中创建一个新的 Pod 时，Cilium 的 CNI 插件 负责为该 Pod 分配 IP 地址。这与 Kubernetes Controller Manager 协同完成。在我们公司的场景中，Cilium 使用的是公司内部的物理 IP 地址，这些地址是从公司内部的一个专门的 IP 地址池中分配的，以确保 Pod 在公司内部的网络中能够被识别和访问。
通过 Cilium CNI 插件将 IP 分配到 Pod：Cilium 作为 Kubernetes 的 CNI 插件，负责为新创建的 Pod 分配 IP 地址，并将该 IP 绑定到 Pod 的虚拟网络接口（veth）。Cilium 通过 CNI 接口向 Kubernetes 报告这些信息，确保 Kubernetes 的网络配置与 Cilium 的 eBPF 配置一致。
          
          
        
      </description>
    </item>
    
    <item>
      <title>两个有序集合的合并</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/mergeset/</link>
      <pubDate>Sat, 21 Sep 2024 15:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/mergeset/</guid>
      <description>
        
          
            双指针法的解决思路： 初始化两个指针：分别指向两个有序集合的起始位置。 比较当前指针指向的元素： 如果集合1的元素小于集合2的元素，将集合1的元素放入结果集中，并将集合1的指针向后移动。 如果集合2的元素小于集合1的元素，将集合2的元素放入结果集中，并将集合2的指针向后移动。 如果两个集合的元素相等，则可以选择将其中一个元素加入结果集，然后两个指针都向后移动。 处理剩余元素：当其中一个集合的所有元素都已合并到结果集中，另一集合可能还有剩余元素。此时直接将剩余元素加入结果集中。 返回结果集：所有元素被合并后返回结果。 代码： 1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func mergeSet(set1, set2 []int) []int { 6 result := []int{} 7 8 i, j := 0, 0 9 10 for i &amp;lt; len(set1) &amp;amp;&amp;amp; j &amp;lt; len(set2) { 11 // 1. 比较大小，小的先走 12 if set1[i] &amp;lt; set2[j] { 13 result = append(result, set1[i]) 14 i++ 15 } else if set1[i] &amp;gt; set2[j] { 16 // 2.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Go `map` 底层实现与冲突处理</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/map/</link>
      <pubDate>Sat, 21 Sep 2024 10:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/map/</guid>
      <description>
        
          
            Go语言中的map是一种哈希表（hash table）数据结构，支持键值对的高效存取。通过键（key）计算哈希值并将其映射到对应的存储桶（bucket）中，map可以在平均O(1)的时间复杂度下进行插入、查找和删除操作。Go的map底层实现非常精巧，结合了哈希表的基本思想，同时针对冲突和内存管理做了很多优化。
1. Go map 的基本结构 在Go中，map通过哈希表实现，其底层结构主要由以下几个部分组成：
1.1 Bucket（存储桶） 1Bucket 2+--------------------+---------------------+---------------------+ 3| keys (k1, k2, ...) | values (v1, v2, ...) | overflow bucket ptr | 4+--------------------+---------------------+---------------------+ 存储桶: 是一个固定长度的数组，用于存储键值对。每个桶中包含了多个键（key）和值（value）对，以及一个指向溢出桶（overflow bucket）的指针。 存储桶：map中的数据被存储在 bucket（存储桶） 中，Go的map默认使用2^B个桶（B是map的大小参数），每个桶可以存储多个键值对。 每个 bucket 是一个存储单元，可以存放多个键值对。多个 bucket 组成了整个哈希表的存储空间。bucket 是哈希表的基本存储单位 每个桶包含若干个键值对和一个溢出链表（overflow bucket），用于解决哈希冲突。桶中的元素通过链表或线性探测等方式处理冲突。 1.2 哈希函数 map通过哈希函数将键映射到一个哈希值，然后通过哈希值找到对应的bucket。 哈希值的前几位决定了元素应该放入的桶。 1.3 扩容机制 当map中的桶负载因子超过一定阈值时，Go会触发扩容（rehash），扩展哈希表的大小。扩容过程中会将旧桶中的数据重新分配到新的桶中，以减少哈希冲突。 Go map 存储和查找的完整流程（结合 bucket 结构） Go 中的 map 是通过哈希表实现的，使用 bucket（桶） 作为核心数据结构存储键值对。以下是 map 在存储和查找一个 key 时的完整流程，以及如何处理哈希冲突。
2. Go map 查找和存储流程 Go map 的核心结构包含：
          
          
        
      </description>
    </item>
    
    <item>
      <title>Go Channel 是线程安全的吗？</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/channel/</link>
      <pubDate>Sat, 21 Sep 2024 09:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/channel/</guid>
      <description>
        
          
            是的，Go的channel是线程安全的。
Go中的channel是一种用于不同goroutine之间通信的原语，它可以在多个goroutine之间安全地传递数据，而不需要显式地使用锁机制（如mutex）来同步访问。Go语言的设计确保了channel在并发场景下是安全的，这使得它非常适合在多goroutine环境中用于数据传递和同步。
Go Channel 的底层实现 Go语言的channel底层实现非常精巧，通过Go runtime（运行时）和调度器（scheduler）来保证其线程安全性。其主要的实现机制依赖于goroutine调度、队列和锁来保证数据的安全传递。下面我们详细解析channel的底层实现：
1. Channel 的数据结构与机制 Go 的 channel 本质上是一个复杂的结构，主要由几个部分组成：
发送队列（sendq）：用于存放等待发送数据的 goroutine。 接收队列（recvq）：用于存放等待接收数据的 goroutine。 缓冲区（buf）：如果是有缓冲的 channel，缓冲区用于存放已发送但还未被接收的数据。 锁（mutex）：每个 channel 都有一个锁，用于保护其状态，防止多个 goroutine 并发访问时发生数据竞争。 1type hchan struct { 2 qcount uint // 缓冲区中数据个数 3 dataqsiz uint // 缓冲区大小 4 buf unsafe.Pointer // 缓冲区的指针（有缓冲channel） 5 sendx uint // 下一个发送位置 6 recvx uint // 下一个接收位置 7 sendq waitq // 发送goroutine的等待队列 8 recvq waitq // 接收goroutine的等待队列 9 lock mutex // 保证线程安全的锁 10 closed uint32 // channel是否关闭 11} 2.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Go内存逃逸与内存泄露详解</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</link>
      <pubDate>Sat, 21 Sep 2024 08:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</guid>
      <description>
        
          
            1. 栈与堆内存分配 在Go语言中，栈和堆是两种主要的内存分配区域。理解它们的区别和作用，是理解内存逃逸的关键。
栈（Stack）： 作用：栈是一种连续的内存区域，主要用于存储函数调用中的局部变量。栈的特点是后进先出（LIFO），当函数执行时，局部变量在栈上分配，函数执行结束后，栈上的内存会自动回收。 特点：栈上的内存分配非常快，分配和释放都是由系统自动完成的，空间占用小，适合短生命周期的局部变量。 局限：栈的大小是有限的，当变量的生命周期超出栈帧，或变量的大小超过栈的限制时，栈上的变量就会转移到堆上，这就是内存逃逸。 堆（Heap）： 作用：堆是一个动态内存区域，大小不受限制。Go的**垃圾回收器（GC）**负责自动管理堆内存，分配和释放变量。 特点：堆上的变量可以在程序的不同部分间共享，适用于生命周期较长的对象。 局限：堆的内存分配和释放开销较大。由于堆上的变量需要通过GC回收，因此频繁的堆分配会增加垃圾回收器的负担，影响性能。 总结：
栈和堆因为内存管理方式不同，堆需要垃圾回收等机制，所以堆的分配和释放速度较慢。栈就是单纯的指针移动，速度快。 栈内存适合短期的、局部的变量，分配速度快，但容量有限。 堆内存适合长期存在的对象，尽管容量大，但垃圾回收的代价较高。 2. Go内存逃逸 内存逃逸是指Go语言中的局部变量从栈转移到堆的现象。当编译器发现某个变量的生命周期超出了当前函数的作用域时，它会将变量从栈转移到堆上分配。
内存逃逸分析工具： 使用Go语言编译器的逃逸分析工具，可以检测代码中哪些变量发生了内存逃逸。
1go build -gcflags=&amp;#34;-m&amp;#34; 该命令会在编译时显示哪些变量发生了内存逃逸。
常见的内存逃逸场景： 简单来说，逃逸发生的原因是：数据在函数结束后还需要存在，无法继续保存在栈中，所以必须移到堆里去。
2.1 闭包逃逸： 当变量被闭包捕获并在函数结束后继续使用时，编译器会将该变量分配到堆中，因为它的生命周期超出了函数的范围。
1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func closureEscape() func() int { 6 x := 10 7 return func() int { 8 return x // x 逃逸到堆中 9 } 10} 11 12func main() { 13 f := closureEscape() 14 fmt.Println(f()) // 输出 10 15} 在这个例子中，变量x被闭包捕获，虽然x是局部变量，但由于闭包需要在函数返回后继续使用x，所以x被分配到堆中。
          
          
        
      </description>
    </item>
    
    <item>
      <title>基于Prometheus、Thanos与Grafana的监控体系详解</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/prometheus/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/prometheus/</guid>
      <description>
        
          
            Grafana通过Thanos Query从所有Prometheus实例中获取数据。 Thanos Query聚合来自两个集群（每个集群包含4个Prometheus实例）的监控数据。 每个Prometheus实例都有一个与之相连的Thanos Sidecar，Thanos Sidecar将Prometheus数据暴露给Thanos Query。 两个Thanos Sidecar组件分别处理不同集群中的Prometheus实例。 1 +-------------+ 2 | Grafana | 3 +------+------+ 4 | 5 v 6 +-------------+ 7 | Thanos Query| 8 +------+------+ 9 | 10 +----------------+----------------+ 11 | | 12 +-------+-------+ +-------+-------+ 13 | Thanos Sidecar| | Thanos Sidecar| 14 +-------+-------+ +-------+-------+ 15 | | 16+---------------+---------------+ +-------------+-------------+ 17| | | | 18v v v v 19Prometheus1 Prometheus2 Prometheus3 Prometheus4 (Cluster 1) 20 21+---------------+---------------+ +-------------+-------------+ 22| | | | 23v v v v 24Prometheus5 Prometheus6 Prometheus7 Prometheus8 (Cluster 2) 1.
          
          
        
      </description>
    </item>
    
    <item>
      <title>树形结构详解及实际用途</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/tree/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/tree/</guid>
      <description>
        
          
            树形结构是计算机科学中重要的数据结构，广泛用于存储、检索和排序数据。以下是常见的树结构：二叉树、红黑树、AVL树、B树和B+树。
1. 二叉树（Binary Tree） 定义： 二叉树是每个节点最多有两个子节点的树结构，通常称为左子树和右子树。
插入、查询和删除的操作逻辑： 插入：从根节点开始，按照二叉搜索树的性质，插入较小的值到左子树，较大的值到右子树，递归进行。 查询：按照与插入相同的逻辑，递归查找对应的值。 删除：删除时有三种情况：删除叶子节点、删除有一个子节点的节点、删除有两个子节点的节点。对于有两个子节点的情况，需找到右子树中的最小值来替代被删除的节点。 形态图示： 1 10 2 / \ 3 5 15 4 / \ \ 5 2 7 20 应用场景： 表达式树：在编译器或解释器中，二叉树常用于解析复杂的算术表达式。每个操作符（如 +, *）是树中的内部节点，而操作数（如 3, 5）是叶子节点。编译器利用表达式树来解析并执行复杂表达式。例如表达式 (3 + (5 * 2)) 会被解析成一棵树，先执行乘法，再执行加法。通过二叉树，编译器能够确保按照正确的优先级顺序执行运算，方便表达式的解析与求值。
决策树：在机器学习中，决策树用于分类和回归模型。每个内部节点表示一个决策条件（如 &amp;quot;是否年龄&amp;gt;30&amp;quot;），叶子节点表示决策的结果（如 &amp;quot;是&amp;quot; 或 &amp;quot;否&amp;quot;）。通过这种结构，机器学习模型能够递归地通过多个决策条件，得出最终分类或预测结果。
2. 红黑树（Red-Black Tree） 定义： 红黑树是一种自平衡二叉搜索树，通过颜色（红色和黑色）标记来保持平衡。
插入、查询和删除的操作逻辑： 插入：红黑树首先按二叉搜索树的方式插入节点，之后会根据颜色调整和旋转操作来维持树的平衡。红色节点不能连续存在，且路径中的黑色节点数量相同。 查询：与普通二叉树一样，根据值递归查找左右子树。 删除：删除后根据颜色规则调整，通过旋转和重新着色确保红黑树保持平衡。 形态图示： 1 10(B) 2 / \ 3 5(R) 15(B) 4 / \ 5 12(R) 20(R) 应用场景： 操作系统调度器（CFS）：在 Linux 操作系统中，完全公平调度器（CFS）是调度器子系统，用来管理多个正在运行的任务。CFS 使用红黑树存储所有等待运行的任务，以任务的虚拟运行时间为关键字。调度器每次会选择虚拟运行时间最短的任务来执行，并且在执行过程中，会定期更新任务的运行时间。红黑树通过自平衡保证在众多任务中高效查找和调度任务。通过红黑树，CFS 能够在 O(log n) 时间内找到虚拟运行时间最短的任务，确保多任务系统中的公平调度和高效运行。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Operator 新手开发一文入门</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/operator/</link>
      <pubDate>Sun, 15 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/operator/</guid>
      <description>
        
          
            概述 Kubernetes Operator 简介 Kubernetes Operator 是一类 Kubernetes 控制器，它能够自动化管理复杂的应用程序和其生命周期，通常被用来管理有状态应用（如数据库、缓存等）。通过扩展 Kubernetes API，Operator 可以将日常操作流程（如安装、升级、扩展、备份等）转换为 Kubernetes 原生对象，从而实现自动化和声明式管理。
为什么使用 Operator Operator 通过将 DevOps 团队日常管理应用的运维知识和流程编码化，使复杂的应用程序管理变得简单和自动化。在 Kubernetes 中，Operator 可以持续监控自定义资源，并自动进行相应操作，确保应用程序的状态与用户期望一致。
Operator 与 Controller 的关系 Operator 实际上是一个高级 Controller，它不仅负责监控和管理 Kubernetes 中的自定义资源 (CR)，还可以执行特定的业务逻辑。Controller 是 Kubernetes 架构中管理资源状态的核心组件，Operator 是对 Controller 的封装和扩展，专门用于复杂应用的生命周期管理。
核心概念 自定义资源 (CR) 和自定义资源定义 (CRD) 什么是 CR 自定义资源 (Custom Resource, CR) 是 Kubernetes 用户可以定义的扩展对象，用于描述某个具体的应用或资源的期望状态。每个 CR 对象的结构基于其相应的 CRD (Custom Resource Definition)，通过 CR，用户可以声明他们希望 Kubernetes 管理的特定应用或服务。
什么是 CRD CRD（自定义资源定义）是 Kubernetes 的一种扩展机制，允许用户向 Kubernetes API 添加新的对象类型。通过 CRD，用户可以定义新的资源种类（类似于内置的 Pod、Service 等），并指定这些资源的结构和行为。
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第9天 151. 反转字符串中的单词, 55. 右旋字符串, 459. 重复的子字符串</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day9/</link>
      <pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day9/</guid>
      <description>
        
          
            学习内容 学习文档 字符串总结：这篇文档总结了字符串相关的常用操作和处理方法。特别是如何高效地使用 substr、split、reverse 等库函数处理字符串问题。它还包含了各种算法的讨论，例如 KMP 算法如何处理字符串匹配问题，具体可以参考 KMP 模式匹配的高效实现。
双指针总结：双指针是一种常见且高效的算法思路，尤其在处理字符串和链表问题时特别有效。文档详细介绍了双指针在解决问题中的应用场景，如链表反转、寻找和计算字符串中的特定内容、左右边界的处理等。这个方法也经常用于简化两个嵌套的循环，使时间复杂度从 O(n^2) 降到 O(n)。
收获总结 字符串是一种特殊的数组，有限字符序列： 字符串本质上就是一系列字符的集合，因此在很多算法问题中，可以将字符串当作数组来处理。字符串相关的操作，如查找、分割、拼接等，本质上与数组操作有相似之处。学会理解这一点，可以让我们在处理字符串问题时更加灵活和高效。
substr、split、reverse 等库函数在 Golang 里的简单使用：
substr 用于提取字符串的子串。 split 用于将字符串按照指定的分隔符进行切分。 reverse 用于将字符串或字符数组进行反转。掌握这些函数能够帮助我们处理很多字符串问题，尤其是在需要对字符串进行拆分、拼接或翻转操作时，简化代码的编写。 双指针在处理字符串问题时的应用： 双指针技术经常用于字符串处理问题，如字符串的反转、查找重复字符、判断回文串等。通过设置两个指针从字符串的不同端开始遍历，可以有效减少遍历次数并提升效率。双指针的典型应用包括：
字符串反转 为例：我们可以定义两个指针，分别指向字符串的第一个和最后一个字符。在循环中，交换这两个位置的字符，然后同时移动两个指针，一个向右，一个向左，直到它们相遇或交错为止。这个方法能在 O(n) 的时间内完成反转。 字符串填充 问题。如果需要在字符串中插入填充内容，比如插入空格或其他字符，我们可以先根据填充后的最终长度对数组进行扩容，然后使用双指针从末尾向前操作。一个指针从原字符串的最后一个字符开始，另一个指针从扩容后的新位置开始，逐步进行字符的移动和填充，这样避免了额外的多次遍历。 反转链表，我们使用两个指针，prev 和 curr，分别指向当前节点和前一个节点。通过将当前节点的 next 指针指向前一个节点，实现局部反转。然后依次更新指针，直到遍历完整个链表，从而在一次遍历中完成链表的反转。 n 数之和（如 Two Sum 问题）同样可以通过双指针技术来解决。首先将数组排序，然后定义两个指针，分别指向数组的首尾。通过计算这两个指针所指元素的和，根据结果移动指针：如果和小于目标值，则移动左指针以增大和；如果和大于目标值，则移动右指针以减小和。这样可以在 O(n) 的时间内找到所有满足条件的组合。 反转系列问题：先局部后整体或先整体后局部的应用： 字符串或数组的反转问题通常可以分为两类：
先局部反转再整体反转：这种方法适用于需要反转某个特定区间的内容，然后对整体内容进行反转的情况。 先整体反转再局部反转：用于整体反转之后需要再对局部的特定段进行细化处理。比如字符串旋转的操作可以通过这种方式来实现。 KMP 算法的学习与理解： KMP 算法是一种用于解决字符串匹配问题的高效算法。KMP 的核心思想在于避免重复匹配，通过构建 next 数组，预处理模式串来记录前缀与后缀的匹配情况，使得在遇到不匹配时可以通过 next 数组快速跳过不必要的字符，减少回溯次数。掌握 KMP 算法不仅能够提升匹配效率，而且对于理解复杂字符串问题具有重要意义。
1// 计算next数组 2func computeNext(pattern string) []int { 3 m := len(pattern) 4 next := make([]int, m) 5 j := 0 6 7 next[0] = 0 // 修改为0 8 9 for i := 1; i &amp;lt; m; i++ { 10 // 如果不匹配，回退到上一个可能的匹配点 11 for j &amp;gt; 0 &amp;amp;&amp;amp; pattern[i] !
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deploy Kubernetes cluster via kubeadm</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/kubeadm/</link>
      <pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/kubeadm/</guid>
      <description>
        
          
            1. Install kubeadm(kubelet kubectl) and docker https://docs.docker.com/engine/install/ubuntu/
Set up docker apt repository:
1# Add Docker&amp;#39;s official GPG key: 2sudo apt-get update 3sudo apt-get install ca-certificates curl 4sudo install -m 0755 -d /etc/apt/keyrings 5sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc 6sudo chmod a+r /etc/apt/keyrings/docker.asc 7 8# Add the repository to Apt sources: 9echo \ 10 &amp;#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \ 11 $(. /etc/os-release &amp;amp;&amp;amp; echo &amp;#34;$VERSION_CODENAME&amp;#34;) stable&amp;#34; | \ 12 sudo tee /etc/apt/sources.
          
          
        
      </description>
    </item>
    
    <item>
      <title>如何加节点到Kubernetes集群</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/addnode/</link>
      <pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/addnode/</guid>
      <description>
        
          
            方法一：基于 Bootstrap Token 的加入方式 原理 Bootstrap Token 是一种临时的令牌，用于新节点在加入集群时进行身份验证。 新节点使用 kubeadm join 命令，提供 --token 和 --discovery-token-ca-cert-hash 参数，与控制平面 API 服务器建立安全连接。 控制平面验证 token 的有效性，并向新节点提供所需的证书和配置文件，使其能够加入集群。 具体步骤 1. 在控制平面节点上生成 Bootstrap Token 使用以下命令生成新的引导令牌：
1kubeadm token create --print-join-command 输出示例：
1kubeadm join 10.0.24.14:6443 --token abcdef.0123456789abcdef \ 2 --discovery-token-ca-cert-hash sha256:430cb53669a7fde6e44338968458d47f3fcdbeda4d73bda7435df34ed20ad5be --print-join-command 参数会直接输出用于加入集群的完整命令，包括 token 和 discovery-token-ca-cert-hash。 2. 在新节点上执行加入命令 在新节点上，以 root 或具有相应权限的用户身份执行上述输出的命令：
1kubeadm join 10.0.24.14:6443 --token abcdef.0123456789abcdef \ 2 --discovery-token-ca-cert-hash sha256:430cb53669a7fde6e44338968458d47f3fcdbeda4d73bda7435df34ed20ad5be 3. 加入过程解析 身份验证：新节点使用 token 与控制平面 API 服务器进行身份验证。 证书验证：使用 --discovery-token-ca-cert-hash 提供的哈希值，确保连接的 API 服务器是可信的。 获取配置：验证通过后，新节点从控制平面获取 kubelet 所需的配置文件和证书。 节点注册：kubelet 启动并与控制平面通信，节点被注册到集群中。 注意事项 Token 有效期：默认情况下，token 有效期为 24 小时。可以使用 --ttl 参数调整有效期。 Token 管理：使用 kubeadm token list 查看现有 token，kubeadm token delete &amp;lt;token-id&amp;gt; 删除 token。 方法二：使用 静态 Kubeconfig 文件 的方式(这种是最常规的, 最正确的) 原理 预先在控制平面节点上为新节点生成 kubeconfig 文件，包含必要的证书和配置信息。 将 kubeconfig 文件安全地传输到新节点。 新节点的 kubelet 使用该 kubeconfig 文件与控制平面通信，完成加入过程。 具体步骤 1.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第8天 344. 反转字符串, 541. 反转字符串 II, 54. 替换数字（第八期模拟笔试）</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day8/</link>
      <pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day8/</guid>
      <description>
        
          
            学习内容 收获总结 字符串和字节数组的转换：在 Go 语言中，字符串是不可变的。对于需要修改字符串的操作，如反转、替换等，我们通常会先将字符串转换为 []byte 类型。这是因为 []byte 是可变的，可以通过索引操作直接修改其内容。在许多字符串操作中，将字符串转换为字节数组是一个有效的优化策略，尤其是在需要大量的字符替换和处理时，这种转换能够提高性能和代码的可读性。
unicode.IsDigit 和 rune 的用法：在处理字符串中数字字符时，使用 unicode.IsDigit 函数来判断字符是否为数字非常便捷。unicode.IsDigit 适用于所有 Unicode 字符，能够处理多字节字符，如中文或特殊字符。而 rune 是 Go 语言中用于表示 Unicode 码点的类型，它可以存储多字节字符。因此，在处理包含不同字符集的字符串时，理解 rune 和 unicode.IsDigit 的作用，可以让我们编写的代码更具通用性和健壮性。
从后向前替换字符的技巧：当处理需要对字符进行替换且替换后长度不同的情况时（例如将单个数字字符替换为多个字符），先扩展数组的长度，然后从后向前进行替换操作。这种方式能够有效避免字符替换过程中覆盖未处理的部分，保证替换操作的正确性。在替换操作时，提前计算所需的最终数组长度，并从末尾倒序进行填充，能够让操作更为高效，也避免了不必要的内存分配。
题目解析 题目1：344. 反转字符串 题目描述：
给定一个字符数组 s，请你将该字符数组原地反转。要求算法的空间复杂度为 O(1)，也就是说必须在原数组上进行修改，而不借助额外的空间。
示例：
输入：[&amp;quot;h&amp;quot;, &amp;quot;e&amp;quot;, &amp;quot;l&amp;quot;, &amp;quot;l&amp;quot;, &amp;quot;o&amp;quot;] 输出：[&amp;quot;o&amp;quot;, &amp;quot;l&amp;quot;, &amp;quot;l&amp;quot;, &amp;quot;e&amp;quot;, &amp;quot;h&amp;quot;] 解法说明：
本题的最佳解决方法是使用双指针法。我们从数组的头尾两端分别设立两个指针，一个指向数组的第一个元素（left），另一个指向最后一个元素（right）。然后通过不断交换 left 和 right 所指向的元素，left 逐渐向右移动，right 逐渐向左移动，直到两个指针相遇或交错。这样便完成了原地反转操作，且没有额外的空间开销。
这种方法非常简洁，且利用了数组的特性，使得反转操作只需遍历一遍数组即可完成，非常高效。
代码实现:
1func reverseString(s []byte) { 2	// 对撞双指针反转法 3	left := 0 4	right := len(s) - 1 5 6	for left &amp;lt; right { 7	s[left], s[right] = s[right], s[left] 8	left++ 9	right-- 10	} 11} 复杂度说明：
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第7天 第454题.四数相加II, 383. 赎金信, 第15题. 三数之和，第18题. 四数之和</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day7/</link>
      <pubDate>Fri, 23 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day7/</guid>
      <description>
        
          
            学习内容 学习文档： 哈希表理论基础 收获总结 哈希表的基本应用: 哈希表是一种通过键值对存储数据的数据结构，具有O(1)的平均查找时间复杂度。其优势在于能够快速判断一个元素是否存在于集合中。通过哈希函数将键映射到存储位置，我们可以在常数时间内完成插入、删除和查找操作。这在需要频繁查找或去重的算法问题中非常有用。
哈希函数的理解与设计: 哈希函数是哈希表的核心，负责将输入（键）映射到特定的存储桶位置。一个好的哈希函数应当能够均匀地分布输入数据，避免哈希碰撞的发生。哈希碰撞是指不同的输入映射到了同一存储桶，这会导致性能下降。常用的哈希函数设计包括除留余数法、乘积法和平方取中法等。
哈希碰撞及其处理策略: 哈希碰撞是无法完全避免的，因此需要设计合理的碰撞处理策略。常见的方法有链地址法（即使用链表处理同一存储桶中的多个元素）和开放地址法（即在发生碰撞时寻找下一个可用位置存储）。链地址法的优点是简单易实现，且能处理多种数据类型；而开放地址法则可以更好地利用空间，但在负载因子较高时性能下降明显。
数组作为特殊的哈希表: 在某些特定的算法问题中，我们可以使用数组来模拟哈希表。特别是当键值范围固定且有限时（如小写字母a-z），数组能够提供与哈希表类似的功能，但由于数组的访问速度更快且无哈希碰撞，因此在特定场景下表现更佳。例如，在统计字符频次的题目中，使用固定大小的数组可以大幅提升性能。
set数据结构的应用: 在某些问题中，需要频繁检查某个元素是否已经存在，或需要确保数据不重复。此时，集合（set）是一种理想的数据结构。Go语言中没有原生的set结构，但可以通过map[T]struct{}来模拟实现，其中T是元素类型。由于struct{}{}在Go语言中不占用额外空间，因此这种方法既节省内存，又能够实现集合所需的所有操作（如插入、删除、查找）。
map作为哈希表的高级应用: Go语言中的map不仅可以用来模拟集合，还能够用于更复杂的场景，如计数器、查找表等。在处理组合问题时，map常用于记录不同组合出现的次数，并通过查找实现快速匹配。例如在&amp;quot;四数相加II&amp;quot;问题中，使用两个map分别记录前两组数的和与后两组数的和，从而在O(1)时间内完成匹配，大大提升了算法效率。
拓展理解：哈希表在实际问题中的应用: 在实际开发中，哈希表广泛应用于缓存（如LRU缓存）、数据库索引、计数器统计等场景。学习哈希表的基础知识并理解其实现细节，能够帮助我们更好地应对这些实际问题。通过这次学习，我们不仅掌握了哈希表的理论知识，还在实践中理解了如何通过优化哈希函数、处理哈希碰撞等方法，提升算法的效率和可靠性。
题目解析 题目1：第454题.四数相加II 题目描述: 给定四个整数数组nums1、nums2、nums3和nums4，统计有多少个四元组(i, j, k, l)使得nums1[i] + nums2[j] + nums3[k] + nums4[l] = 0。为了简化问题，假设所有的四个数组长度相同，且长度不超过500。
示例:
1输入: nums1 = [1, 2], nums2 = [-2,-1], nums3 = [-1, 2], nums4 = [0, 2] 2输出: 2 3解释: 两个符合条件的四元组为: 4(0, 0, 0, 1) -&amp;gt; nums1[0] + nums2[0] + nums3[0] + nums4[1] = 1 + (-2) + (-1) + 2 = 0 5(1, 1, 0, 0) -&amp;gt; nums1[1] + nums2[1] + nums3[0] + nums4[0] = 2 + (-1) + (-1) + 0 = 0 解法总结: 该题目要求我们找到所有满足条件的四元组。直接暴力枚举四个数组中的元素组合会导致O(n^4)的时间复杂度，无法在合理时间内解决问题。因此，利用哈希表的快速查找特性可以将问题转化为两两分组求和。首先，我们遍历nums1和nums2，计算每对元素的和，并将其存储在哈希表中，键为和，值为出现的次数。然后遍历nums3和nums4，计算它们的和并检查哈希表中是否存在该和的相反数，如果存在则说明找到了符合条件的四元组，结果增加该和的出现次数。通过这种方法，时间复杂度降低到了O(n^2)。
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第6天 242. 有效的字母异位词, 349. 两个数组的交集, 202. 快乐数, 1. 两数之和</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day6/</link>
      <pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day6/</guid>
      <description>
        
          
            学习内容 学习文档：
哈希表理论基础
收获总结 Go中的rune类型: 在Go语言中，rune是一种别名类型，它表示一个Unicode码点，即一个整数，通常用于表示字符。Go的字符串是以字节数组的形式存储的，因此在处理多字节字符（如汉字、表情符号等）时，直接使用索引访问可能会得到不完整的字符。rune类型解决了这个问题，它能够正确处理和表示多字节的Unicode字符。这对于处理包含非ASCII字符的字符串时非常重要，尤其在国际化或多语言支持的应用中。通过这次学习，我们掌握了如何使用rune遍历字符串，确保对每个字符进行准确的操作。
数组作为简单高效的哈希表: 在解决某些特定范围的哈希问题时，数组可以作为一种极为简单和高效的哈希表实现方式。特别是在字符计数和映射问题中，如果字符集固定（例如，字母a到z），我们可以使用一个固定长度的整数数组（如[26]int）来记录每个字符的出现次数。数组的索引直接对应字符的ASCII值减去偏移量，这使得字符查找和更新操作都可以在常数时间内完成。学习这部分内容让我们理解了如何在时间复杂度和空间复杂度上进行权衡，选择最合适的数据结构。
Go中使用map实现set: 在Go语言中，集合(set)这一数据结构并没有直接实现，但我们可以通过map来间接实现。使用map[T]struct{}这种方式来模拟集合，其中T是元素类型，struct{}是一种不占用内存的零大小结构体。通过map键的唯一性，保证集合中的元素不重复，同时由于值类型为空结构体，节省了内存空间。我们还学习了如何利用delete函数从map中删除元素，进而动态地管理集合内容。这种技巧在需要高效去重和查找操作的场景中非常有用。
Go中struct{}{}占用空间最小: 在Go语言中，struct{}{}是一个空的结构体类型，占用空间为零。在使用map实现集合时，我们可以将map的值类型定义为struct{}{}，这样可以在实现集合功能的同时，极大地节省内存空间。与其他语言的集合实现相比，这种方式更为轻量级，适合内存受限的场景。通过这种学习，我们进一步理解了Go语言在性能优化方面的设计思想，以及如何在日常编程中应用这些知识提高程序的效率。
两数之和的双指针与哈希表解法: 对于两数之和问题，如果数组是有序的，我们可以利用双指针（也称为对撞指针）策略，从数组两端同时向中间移动，根据当前和与目标值的比较结果决定指针的移动方向，从而在O(n)时间复杂度内找到解。如果数组是无序的，则可以使用哈希表来记录已遍历过的数值及其索引。在遍历数组时，通过查找哈希表，快速判断是否存在与当前元素互补的数值，并在常数时间内找到目标组合。这些方法各有优劣，双指针法简单直观但只能用于有序数组，而哈希表法适用于无序数组且查找效率更高。通过学习这两种解法，我们理解了不同场景下算法选择的依据。
扩展知识: 在这次学习中，还扩展了关于哈希表、双指针法在不同算法问题中的广泛应用。深入理解了哈希表在解决查找问题中的效率优势，以及双指针在排序数组中优化搜索过程的应用场景。这些知识不仅在理论层面增强了我们的算法理解，也为我们实际解决编程问题提供了多种思路和工具。
题目解析 题目1：242. 有效的字母异位词 题目描述: 给定两个字符串 s 和 t，编写一个函数来判断 t 是否是 s 的字母异位词。字母异位词是指由相同的字母组成，但排列顺序不同的字符串。注意，字符串中的字母全部为小写字母。
示例:
1输入: s = &amp;#34;anagram&amp;#34;, t = &amp;#34;nagaram&amp;#34; 2输出: true 3 4输入: s = &amp;#34;rat&amp;#34;, t = &amp;#34;car&amp;#34; 5输出: false 解法总结: 该题目要求判断两个字符串是否为字母异位词，核心在于统计两个字符串中各字符的出现次数。如果两个字符串中各字符出现的次数完全相同，那么这两个字符串就是字母异位词。解法采用了固定长度的整数数组来记录字符的频次，其中每个字符的频次通过其ASCII码的偏移计算得出。在遍历第一个字符串时，对应字符的计数器加一；在遍历第二个字符串时，对应字符的计数器减一。最后，如果数组中的所有值都为零，则说明两个字符串是字母异位词。这个方法利用了数组的高效查找特性，使得整个过程的时间复杂度保持在O(n)。
1func isAnagram(s string, t string) bool { 2	var tmp [26]int 3	// 1. 映射s到数组+1(数组是简单高效的哈希表) 4	for _, c := range s { 5	tmp[c-rune(&amp;#39;a&amp;#39;)]++ 6	} 7	// 2.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第4天 24. 两两交换链表中的节点, 19. 删除链表的倒数第 N 个结点, 面试题 02.07. 链表相交, 142. 环形链表 II</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day4/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day4/</guid>
      <description>
        
          
            收获总结 虚拟头节点的使用：虚拟头节点（Dummy Head）是处理链表问题的一大利器，尤其在增删节点操作中。通过引入虚拟头节点，可以避免处理链表头部时遇到的特殊情况，如删除第一个节点或在第一个节点前插入新节点。这不仅简化了代码，还减少了需要额外考虑的边界条件。例如，在处理 19. 删除链表的倒数第 N 个结点 时，虚拟头节点能够让双指针操作统一化，避免对头节点的单独处理。
双指针技术：双指针技术是链表问题中的核心工具，特别是在处理链表长度不一致、链表中查找特定节点、或检测链表是否存在环时。双指针通常有两种应用方式：
快慢指针：通过让一个指针每次走两步（快指针），另一个指针每次走一步（慢指针），这种方法能有效检测链表中的环（如 142. 环形链表 II）。当快慢指针相遇时，表明链表中存在环。随后，通过调整指针，可以精确找到环的起点。 同步指针：在链表相交问题中（如 面试题 02.07. 链表相交），同步指针的应用非常巧妙。让两个指针分别从两个链表的头开始遍历，当其中一个指针走到链表末尾时切换到另一个链表的头部，最终两个指针会在相交点相遇。这种方法的妙处在于，它平衡了链表长度的差异，使得指针在正确的位置相遇。 内置数据结构的应用：在处理链表问题时，合理使用内置的数据结构（如 map）可以大大提高解决问题的效率。例如，在检测链表是否有环时，使用哈希表可以记录已经访问过的节点，一旦再次访问到相同的节点，就可以立即判定链表中存在环，并找到环的入口。这种方法尽管增加了空间复杂度，但通常能够显著降低时间复杂度，是时间换空间的一种常见手段。
画图和理清思路：链表操作往往涉及多步节点指针的调整，容易出现操作顺序错误导致链表断裂或死循环的问题。因此，在进行复杂链表操作之前，通过画图来理清每一步的指针变动，明确节点间的连接关系，是非常必要的。比如在解决 24. 两两交换链表中的节点 问题时，通过画图可以清晰地看到每次交换后的链表结构，有助于正确实现节点交换。
操作的标准化和优化：在链表操作中，保持节点连接的正确性是最重要的。在实现代码时，应尽量避免无效或重复的操作。例如，在删除节点时，应确保先处理前驱节点的 next 指针，再释放目标节点的内存。同时，在实际开发中，掌握一些标准化的代码模板（如增删节点的通用代码框架）能够帮助减少错误，提高代码的复用性和开发效率。
题目解析 题目1：24. 两两交换链表中的节点 题目描述: 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯地改变节点内部的值，而是需要实际进行节点交换。
示例:
1输入: head = [1,2,3,4] 2输出: [2,1,4,3] 解法总结: 这个问题要求我们在链表中两两交换相邻的节点。为了简化操作，可以引入一个虚拟头节点（dummy head），它指向原链表的头节点，这样可以统一对头节点和后续节点的处理。然后使用双指针遍历链表，分别指向当前待交换的两个节点及其前驱节点。关键在于每次交换时，需要提前保存第二个节点的下一个节点，以防止链表断裂。假设1-&amp;gt;2-&amp;gt;3-&amp;gt;4是待交换的两个节点，交换过程如下：
将pre指向2 将2指向1 将1指向3 将pre指向1 将cur指向3 重复上述步骤，直到cur或cur.Next为空 代码实现:
1/** 2 * Definition for singly-linked list. 3 * type ListNode struct { 4 * Val int 5 * Next *ListNode 6 * } 7 */ 8func swapPairs(head *ListNode) *ListNode { 9	// 1.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第3天 203.移除链表元素, 707.设计链表, 206.反转链表</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day3/</link>
      <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day3/</guid>
      <description>
        
          
            学习内容 学习文档：
链表讲解
收获总结 链表概述 链表是一种基础的数据结构，由一系列节点组成，每个节点包含数据部分和指向下一个节点的指针（或引用）。链表的最后一个节点指向 null，表示链表的末尾。链表动态扩展性强，适合频繁插入和删除操作。
链表的定义 链表有多种类型，最常见的是单链表和双链表。
单链表：每个节点包含数据和指向下一个节点的指针 next。链表的头节点指向第一个节点，最后一个节点的 next 指向 null。
Golang 单链表定义：
1type ListNode struct { 2 Val int 3 Next *ListNode 4} 双链表：每个节点包含数据、指向下一个节点的指针 next 和指向前一个节点的指针 prev，允许双向遍历。
Golang 双链表定义：
1type ListNode struct { 2 Val int 3 Next *ListNode 4 Prev *ListNode 5} 注意事项 循环的时候参考数组，初始条件是i,j; 链表就是cur, cur.Next 链表的第一个节点比较特殊，处理的时候需要特殊处理；引入一个空的头节点dummyHead，可以简化很多操作(一视同仁) 链表的指针就是ListNode本身，因为任何一个ListNode都可以根据Next进行移动; 双指针解法的时候每一个指针都应该是一个ListNode 链表元素的内存分布 链表节点的内存分布不连续，节点在内存中的位置是随机分配的。这使得链表可以灵活地增长或缩小，但查找元素的时间复杂度较高，因为需要从头节点开始逐一遍历。
节点的插入与删除 插入节点：
头部插入：新节点的 next 指向当前头节点，并将链表头节点更新为新节点，时间复杂度为 O(1)。 尾部插入：单链表需要遍历链表找到最后一个节点，时间复杂度为 O(n)，双链表则直接访问尾节点，时间复杂度为 O(1)。 删除节点：
删除头节点：将头节点更新为下一个节点，时间复杂度为 O(1)。 删除指定节点：需要遍历链表找到待删除节点，时间复杂度为 O(n)。 题目解析 题目1：203.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第2天 209. 长度最小的子数组, 59. 螺旋矩阵 II</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day2/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day2/</guid>
      <description>
        
          
            学习内容 学习文档：
长度最小子数组讲解
螺旋矩阵II讲解
收获总结 滑动窗口： 在某些情况下，滑动窗口可以看作是一种特殊的双指针技术，其中两个指针 i 和 j（即左指针和右指针）从同一端开始，但移动的条件有所不同。滑动窗口的核心思想是通过右指针 j 不断向右扩展窗口，同时左指针 i 尽量向右收缩窗口，以找到满足特定条件的最小或最大窗口。
举例来说，假设你想找到数组 arr 中两个元素之间的差值等于 diff 的一对元素索引，这可以视为滑动窗口问题，右指针 j 用来扩展窗口，左指针 i 用来收缩窗口，直到找到满足条件的子数组。初始化时可以根据具体问题选择 i, j 都从 0, 0 开始，也可以 0, 1 这种情况。
题目解析 题目1：209. 长度最小的子数组 题目描述: 给定一个含有 n 个正整数的数组 nums 和一个正整数 target ，找出该数组中满足其和 ≥ target 的长度最小的连续子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。
示例:
1输入: target = 7, nums = [2,3,1,2,4,3] 2输出: 2 3解释: 子数组 [4,3] 是该条件下的长度最小的子数组。 解法总结: 该题可以通过滑动窗口技术来解决。我们使用两个指针 i 和 j，分别代表窗口的左右边界。首先，右指针 j 向右移动，扩展窗口，累加窗口内的元素和 sum。当 sum 大于或等于 target 时，开始收缩窗口（移动左指针 i），同时记录当前窗口的最小长度。通过这种方式，可以高效地找到满足条件的最短子数组长度。 这里需要注意的是，因为有可能第一个数就等于target，所以j也要从0开始，同时内侧判断条件也是for!
          
          
        
      </description>
    </item>
    
    <item>
      <title>【算法刷题系列】第1天 704. 二分查找，27. 移除元素, 977.有序数组的平方</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day1/</link>
      <pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/programmercarl/day1/</guid>
      <description>
        
          
            学习内容 学习文档：数组理论基础
收获总结 快速排序：
快速排序是一种基于分治法的排序算法。首先，选择一个基准元素，然后通过分区操作将数组划分为两部分，一部分元素小于基准值，另一部分元素大于基准值。递归地对这两部分进行排序，最终将数组排序完成。
1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func quickSort(arr []int, low, high int) { 6 if low &amp;lt; high { 7 pi := partition(arr, low, high) 8 quickSort(arr, low, pi-1) 9 quickSort(arr, pi+1, high) 10 } 11} 12 13func partition(arr []int, low, high int) int { 14 pivot := arr[high] 15 i := low - 1 16 for j := low; j &amp;lt; high; j++ { 17 if arr[j] &amp;lt; pivot { 18 i++ 19 arr[i], arr[j] = arr[j], arr[i] 20 } 21 } 22 arr[i+1], arr[high] = arr[high], arr[i+1] 23 return i + 1 24} 二分查找：
          
          
        
      </description>
    </item>
    
    <item>
      <title>Etcd Tutorial</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/etcd-tutorial/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/etcd-tutorial/</guid>
      <description>
        
          
            Preface: This tutorial focuses exclusively on the Etcd v3 protocol. Throughout Etcd&#39;s history, two protocols have been employed: v2 and v3. However, v2 is considered outdated and not recommended for production environments. Furthermore, Etcd v2 and v3 have distinct data storage structures. As a result, you cannot use Etcd v2 to read data from Etcd v3 or use an Etcd v2 snapshot to restore data in Etcd v3. This document is tailored for Etcd instances containing v3 data.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【Java入门系列】Java基础入门 --- 安装，数据类型，类</title>
      <link>https://zhangsiming-blyq.github.io/post/java/java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF1/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/java/java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF1/</guid>
      <description>
        
          
            一、Java环境安装 Java是一门强大的编程语言，首先需要在您的计算机上安装Java开发环境。以下是安装Java环境的步骤：
1. 选择Java版本 对于初学者，建议选择Java 8或Java 11版本。您可以从Oracle官方网站下载这些版本。
Java 8下载链接：https://www.oracle.com/java/technologies/javase/jdk8-archive-downloads.html Java 11下载链接：https://www.oracle.com/java/technologies/javase/jdk11-archive-downloads.html 2. 下载示例代码 您可以下载示例代码，以便学习和实践Java编程。示例代码通常包含了一些基础的Java程序，可以帮助您快速入门。
示例代码下载链接（以wget为例）：
1$ wget https://horstmann.com/corejava/corejava11.zip 3. 配置环境变量 将Java主目录添加到系统的PATH环境变量中，这样您就可以在任何位置运行Java命令。您可以使用以下命令来编辑配置文件：
1$ vim ~/.zshrc 在配置文件中添加以下行：
1export PATH=/your/java/installation/path/bin:$PATH 确保将/your/java/installation/path替换为您的Java安装路径, 比如&amp;quot;/Users/simingzhang/siming/jdk-11.0.17/bin&amp;quot;。
4. 验证安装 corejava实例代码和javasrc内置库代码都放到java主目录下：
1$ tree -L 1 2. 3├── README.html 4├── bin 5├── conf 6├── corejava 7├── include 8├── javasrc 9├── jmods 10├── legal 11├── lib 12├── man 13└── release 使用以下命令验证您的Java安装是否成功：
1$ javac --version 2javac 11.0.17 3 4$ java --version 5java 11.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Comprehensive Guide to Neovim</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/neovim/</link>
      <pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/neovim/</guid>
      <description>
        
          
            Neovim, a powerful editor often hailed as a third-party extension for Vim, boasts an impressive 70k stars on GitHub. This robust tool makes for an excellent default editor choice. This guide will take you through the installation process and equip you with effective typing techniques.
Installation GitHub Link
Neovim Installation On MacOS 1$ brew install neovim 2 3$ which nvim 4/usr/local/bin/nvim 5 6$ vim ~/.zshrc 7alias vim=&amp;#39;nvim&amp;#39; 8alias old_vim=&amp;#39;vim&amp;#39; 9 10# replace the normal vim with nvim 11$ which vim 12vim: aliased to nvim 13 14$ vim --version 15NVIM v0.
          
          
        
      </description>
    </item>
    
    <item>
      <title>git的cherry-pick操作</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/git%E7%9A%84cherry-pick%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/git%E7%9A%84cherry-pick%E6%93%8D%E4%BD%9C/</guid>
      <description>
        
          
             参考链接: https://www.atlassian.com/git/tutorials/cherry-pick/ git 的 cherry-pick 操作简单来讲就是可以把具体的commit从一个分支，直接嫁接(复制)到另一个分支, 下面看一个例子: 1$ git branch 2* feat/siming 3 master 4$ git log 5commit 1d7df64add47be9891efa6469f663e78acf3982f (HEAD -&amp;gt; feat/siming, origin/feat/siming) 6Author: zhangsiming &amp;lt;zhangsiming@360.cn&amp;gt; 7Date: Fri Feb 10 20:18:59 2023 +0800 8 9 test2 10 11commit a272f807df9f22c58aa2a970ff26a13a66abec4d 12Author: zhangsiming &amp;lt;zhangsiming@360.cn&amp;gt; 13Date: Fri Feb 10 19:59:06 2023 +0800 14 15 test 16... 17 18# 可以看到feat/siming分支最近两个commit一个是test，一个是test2，我们现在记录一下test的commitId，然后把他cherry-pick到master分支 19$ git checkout master 20$ git cherry-pick a272f807df9f22c58aa2a970ff26a13a66abec4d 21 22# 大功告成，test部分的变更已经追加到了master分支，我们看一下git log graph(注意看HEAD指针位置) 23$ git log --pretty=oneline --graph --decorate --all 24 25* 1d7df64add47be9891efa6469f663e78acf3982f (origin/feat/siming, feat/siming) test2 26* a272f807df9f22c58aa2a970ff26a13a66abec4d test 27* 627f296be9f64418d4f6dfe99d2fcf6881196f30 (HEAD -&amp;gt; master, origin/master, origin/HEAD) Merge branch &amp;#39;feat/siming&amp;#39; into &amp;#39;master&amp;#39; 28|\ 29| * 3a64ef1e9c78dba97b775ac6fcf3a1ecf0c7e925 fix: 优化gpu-alarmer 30| * 08358da0a98490e9e87a990342d13dbeffb7758f add: k8s-weekly-report 31| * 7231fc0a739fae55a5800e883d2e811b6c58e7f3 fix: 修改eventsinformer时间展示 32 33# 如果不想要这个commit了，可以reset回退(HEAD后面有几个^就回退几个commit，或者采用HEAD~n) 34$ git reset --hard HEAD^ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>kubernetes常规问题</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes%E5%B8%B8%E8%A7%84%E9%97%AE%E9%A2%98/</guid>
      <description>
        
          
             kubernetes的cordon打上的SchedulingDisabled仅仅影响调度，也就是直接打上nodeName不会受到该参数的影响 kubernetes的QosClass判断pod内的全部container，包括init-container，也就是如果init-container不进行限制，其他container无论怎么配置仍然不是Guaranteed kubernetes集群新版本如果cordon打上unschedule，会默认追加Taint；旧版本不会 kubernetes集群对于unschedule的节点不会走入调度环节，只有可以正常调度的节点才会走到后面判断Toleration，label等；特别地，对于daemonset的pod，schedulingDisable无效，但是tolerance等有效(v1.17版本中，Damoneset 的 pod 的调度从 daemonset controller 迁移到 kube-scheduler 来做调度，从而支持 PodAffnity、PodAntiAffinity 等能力) Error(不再重启)，Completed状态的podip会显示，但是实际不占用podip，真实podip已经分配给其他服务使用 kubernetes中，kubelet限制的max-pod数量是限制的具体的pod数量，超出会报错Outofpods 每次pod重启，kubelet会给他分配新的cgroup目录路径，而不会使用原来的；新的pod启动之后间隔一小段时间会删除旧的cgroup路径 kubernetes 推荐使用 systemd 来代替 cgroupfs; 因为systemd是kubernetes自带的cgroup管理器, 负责为每个进程分配cgroups; 但docker的cgroup driver默认是cgroupfs,这样就同时运行有两个cgroup控制管理器；可以使用docker info查看docker使用的cgroup driver，然后从&amp;quot;/etc/docker/daemon.json&amp;quot;中修改成systemd 
          
          
        
      </description>
    </item>
    
    <item>
      <title>中断绑定cpu核心问题</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/%E4%B8%AD%E6%96%AD%E7%BB%91%E5%AE%9Acpu%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/%E4%B8%AD%E6%96%AD%E7%BB%91%E5%AE%9Acpu%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98/</guid>
      <description>
        
          
             中断是什么？中断是一种电信号，由硬件产生并直接送到中断控制器上，再由中断控制器向CPU发送中断信号，CPU检测到信号后，中断当前工作转而处理中断信号；其实准确的说这种算硬中断 如果不像让这种中断，或者系统中断和网络中断和一些业务的中断在同一个cpu上面互相影响；可以把某个中断绑定到某几个特定的cpu核心，来达到目的 默认情况systemctl status irqbalance服务会平衡所有中断均衡地是用cpu 可以用echo cpu号 &amp;gt; /proc/irq/中断号/smp_affinity或者使用taskset来绑定中断到具体的cpu核心 ethtool -l eth0可以看到，一些通道信息(这个通道是可以触发网络中断的队列数量), 设置多了会影响内存等资源，设置小了可能会称为高流量瓶颈 参考链接：https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/interrupt_and_process_binding 
          
          
        
      </description>
    </item>
    
    <item>
      <title>在default命名空间下的svc, kubernetes</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-default-svc/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-default-svc/</guid>
      <description>
        
          
            
该svc作为集群内部服务连接api-server的媒介(这三个信息会被注入到每个集群内部的pod中: KUBERNETES_SERVICE_HOST=10.96.0.1、KUBERNETES_SERVICE_PORT=443、KUBERNETES_SERVICE_PORT_HTTPS=443) 永远使用&amp;quot;--service-cluster-ip-range&amp;quot;定义的CIDR的第一个ip地址 svc以及对应的endpoints都是由master controller(api-server二进制文件在最开始启动的controller之一)管控 RunKubernetesService()是一个循环，里面的逻辑包含支持UpdateKubernetesService()更新这个svc信息，ReconcileEndpoints(...endpointPorts []corev1.EndpointPort...)来更新endpoint，也就是一般3个master的信息；不过有时候看到的endpoint可能只有一个ip，这可能是云厂商传入的master lb层 参考链接: https://networkop.co.uk/post/2020-06-kubernetes-default/ 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Closures In Golang And Python</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/closure/</link>
      <pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/closure/</guid>
      <description>
        
          
            For people new to Golang and Python, this article explains what closures are as well as sometips that need to know about when using closures in these two programming languages. To make it easier for you to copy down and run on your own server, the code section would provide the package, import, and other repeated parts. The negative aspect is that this results in some redundancy, so please understand if this causes any inconvenience.
          
          
        
      </description>
    </item>
    
    <item>
      <title>使用zap打造你的golang日志库</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/gozap/</link>
      <pubDate>Fri, 28 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/gozap/</guid>
      <description>
        
          
            近期配置了uber家的zap日志库，觉得性能比较强，展示比较美观，在这里做一个分享，代码在第三部分可以自取。
为什么不选择原生log? 说起golang如何优雅的打印日志，任何一个golang的初学者大概都是用的原生log库，或者直接fmt.Println()...但是这种方式并不优雅，并且有以下缺点：
对于基础日志：不能细粒度区分info和debug级别的日志; 对于错误日志: 不支持除了fatal或者panic的普通error级别告知。 log示例 1package main 2 3import &amp;#34;log&amp;#34; 4 5func main() { 6 log.Print(&amp;#34;info or debug&amp;#34;) 7 log.Fatal(&amp;#34;fatal&amp;#34;) 8 log.Panic(&amp;#34;panic&amp;#34;) 9} 10 11// 输出如下 122022/11/23 22:23:32 info or debug 132022/11/23 22:23:32 fatal 14exit status 1 为什么不选择logrus? logrus也是比较常用的自定义日志库，不过因为Go语言是一门强类型的静态语言，而logrus需要知道数据的类型来打印日志，怎么办呢？实现方案是使用反射，这导致大量分配计数。虽然通常不是一个大问题（取决于代码），但是在大规模、高并发的项目中频繁的反射开销影响很大，所以这里不进行采用。
仓库链接: logrus
logrus示例 1package main 2 3import log &amp;#34;github.com/sirupsen/logrus&amp;#34; 4 5var logger = log.New() 6 7func main() { 8 // 这里可以通过WithFields来附加字段 9 logger.WithFields(log.Fields{&amp;#34;testfield&amp;#34;: &amp;#34;test&amp;#34;}).Info(&amp;#34;test info&amp;#34;) 10 logger.Info(&amp;#34;info&amp;#34;) 11 logger.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | Generate an array of window maximums</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/6/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/6/</guid>
      <description>
        
          
            Requirements There is a integer array arr and a window of size w that slides from the leftmost to the rightmost part of the array, with the window sliding one position at a time to the right. For example, the array is [4,3,5,4,3,3,6,7], and the window size is 3.
If the length of the array is n and the window size is w, then a total of n-w+1 window maxima are generated.
          
          
        
      </description>
    </item>
    
    <item>
      <title>谈谈kubernetes 证书认证那些事儿</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-certificate/</link>
      <pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/kubernetes-certificate/</guid>
      <description>
        
          
            kubernetes各个组件都是加密通信的, 那么都有哪些证书、各个证书怎么交互、这些证书什么时候过期，这个就变得至关重要; 本文引用了一些其他网络内容(均已附上原文链接)，并适当补充完善，用于让新手完善熟悉kubernetes证书体系(如有侵权联系邮箱可以删除)。
一、数字证书原理 1.1 传统非对称加密 1message --&amp;gt; (公钥加密) --&amp;gt; || 传输 || --&amp;gt; (私钥解密) --&amp;gt; message 注意:
1.这里与数字证书认证相反，是公钥加密私钥解密
2.公钥私钥需要是一个秘钥对
1.2 哈希函数 1message --&amp;gt; H(message) --&amp;gt; Hash message 处理加入一个随机数，然后得出结果(加盐); 可以有效缓解在输入值是一个有效的集合，哈希值也是固定长度被别人‘试’出来的几率
1message --&amp;gt; H(R|message) --&amp;gt; Hash message 1.3 数字证书 1.3.1 数字签名 数字签名；把数据根据私钥/哈希进行加密，然后必须要对应的公钥来进行解密认证才能确保数据安全。前半句的加密过程就叫做 &#39;数字签名&#39;
1.3.2 数字证书认证过程 Alice 想要通过证书加密让 Bob 安全读到自己的信息流程如下：
Alice 在本地生成 Private Key 和 CSR（Certificate Signing Request）。CSR 中包含了 Alice 的公钥和姓名，机构、地址等身份信息。 Alice 使用该 CSR 向证书机构发起数字证书申请。 证书机构验证 Alice 的身份后，使用 CSR 中的信息生成数字证书，并使用自己的 CA 根证书对应的私钥对该证书签名。 Alice 使用自己的 Private Key 对合同进行签名，然后将签名后的合同和自己的证书一起并发送给 Bob。 Bob 使用操作系统中自带的证书机构根证书中的公钥来验证 Alice 证书中的签名，以确认 Alice 的身份和公钥。(使用内置根证书确认身份并获取Alice证书) Alice 的证书验证成功后，Bob 使用 Alice 证书中的公钥来验证合同中数字签名。(使用刚刚获取的Alice证书(公钥)解析Alice发送的内容) 合同数字签名通过验证，可以证明该合同为 Alice 本人发送，并且中间未被第三方篡改过。 注意：
          
          
        
      </description>
    </item>
    
    <item>
      <title>浅谈kubernetes ingress机制</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/ingress-mechanism/</link>
      <pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/ingress-mechanism/</guid>
      <description>
        
          
            ingress在将流量发往后端的时候是不经过kube-proxy的，ingress controller会直接和kube-apiserver进行交互，然后获取pod endpoints和service的对应关系，进行轮询，负载均衡到后端节点。
一、验证试验 从集群中删除kube-proxy，查看通过ingress的方式是否可以访问成功?
1# 实验中选择的是&amp;#34;iptables模式的kube-proxy&amp;#34; 2# 首先关闭kube-proxy 3$ sudo systemctl stop kube-proxy 4 5# 查看服务，ClusterIP的端口是8080，NodePort的端口是30948 6$ ks 7NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 8example-test NodePort 10.0.0.226 &amp;lt;none&amp;gt; 8080:30948/TCP 18h 9traefik NodePort 10.0.0.85 &amp;lt;none&amp;gt; 9000:30001/TCP,80:30002/TCP,443:31990/TCP 19h 10 11# 查看与&amp;#34;10.0.0.226&amp;#34;有关的iptables条目，得知访问&amp;#34;10.0.0.226&amp;#34;且目的端口是&amp;#34;8080&amp;#34;的流量会发送给KUBE-SVC-KNYNFDNL67C7KAZZ链 12$ sudo iptables -S -t nat | grep 10.0.0.226 13-A KUBE-SERVICES ! -s 10.0.0.0/24 -d 10.0.0.226/32 -p tcp -m comment --comment &amp;#34;traffic-dispatcher/example-test:port-8080 cluster IP&amp;#34; -m tcp --dport 8080 -j KUBE-MARK-MASQ 14-A KUBE-SERVICES -d 10.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | Use One Stack To Sort Another Stack</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/5/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/5/</guid>
      <description>
        
          
            Requirements A stack whose elements are of type integer now wants to sort the stack from top to bottom in order from smallest to largest, and only one stack is allowed to be requested. Other than that, new variables can be requested, but no additional data structures can be requested. How to complete the sorting?
Solution apply for a new help stack, keep getting data from the original stack, and compare it with the top data of the new help stack; if it meets the sorting requirements, then push it to the help stack if it does not meet the sorting requirements, pop the top data from the help stack and push it to the original stack until it meets the sorting requirements Finally, the original stack is emptied, and the help stack is the stack that is all sorted, so write it back again to complete the stack sorting.
          
          
        
      </description>
    </item>
    
    <item>
      <title>API网关对比</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/apigateway/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/apigateway/</guid>
      <description>
        
          
            kong、apisix是当前比较火的两款开源api网关，本文对比了二者的部署、使用方式；提供一个简单的参考; 对于kong，大家都比较熟悉，但是对于apisix可能熟悉的并不多，那么kong、apisix在使用方式，功能命名上是否有相似，还是理念不同，请看下文。
一、kong 1.1 安装 1# 安装kong 2$ helm repo add kong https://charts.konghq.com 3$ helm repo update 4$ helm fetch kong/kong 5$ tar xf kong-2.5.0.tgz 6$ cd kong 7$ ls 8CHANGELOG.md Chart.yaml FAQs.md README.md UPGRADE.md charts ci crds example-values requirements.lock requirements.yaml templates values.yaml 9...需要配置 101. postgresql作为存储 112. 允许plain text调用admin API 12 13# 安装konga 14$ gc https://github.com/pantsel/konga.git 15$ ls konga 16Chart.yaml templates values.yaml 17...需要配置 181. 获取postgresql的secret写入连接信息 19 20# 部署 21$ helm install kong .
          
          
        
      </description>
    </item>
    
    <item>
      <title>ansible-playbook 详解</title>
      <link>https://zhangsiming-blyq.github.io/post/linux/ansible-playbook/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/linux/ansible-playbook/</guid>
      <description>
        
          
            Ansible 是一个开源的基于 OpenSSH 的自动化配置管理工具。可以用它来配置系统、部署软件和编排更高级的 IT 任务，比如持续部署或零停机更新。
一、ansible 简介 Ansible 的主要目标是简单和易用，并且它还高度关注安全性和可靠性。基于这样的目标，Ansible 适用于开发人员、系统管理员、发布工程师、IT 经理，以及介于两者之间的所有人。Ansible 适合管理几乎所有的环境，从拥有少数实例的小型环境到有数千个实例的企业环境。
1.1 ansible 变量优先级如下 command line values (eg &amp;quot;-u user&amp;quot;) role defaults inventory file or script group vars inventory group_vars/all playbook group_vars/all inventory group_vars/* playbook group_vars/* inventory file or script host vars inventory host_vars/*: inventory 下面的 hosts_vars 目录下的变量优先级大于 group_vars 目录下的 playbook host_vars/* host facts / cached set_facts play vars play vars_prompt play vars_files: vars_files 优先级大于同级别的 vars 字段(play 内定义) role vars (defined in role/vars/main.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | Dog-Cat Queue</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/4/</link>
      <pubDate>Tue, 07 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/4/</guid>
      <description>
        
          
            Requirements Dog and cat have implemented the Pet interface, you can use getPetType() to view the corresponding animal type; NewDog(), NewCat() can create new dog and cat objects respectively.
1type Pet interface { 2	getPetType() string 3} 4 5type fatherPet struct { 6	Type string 7} 8 9func (fp *fatherPet) getPetType() string { 10	return fp.Type 11} 12 13type Dog struct { 14	fatherPet 15} 16 17func NewDog() *Dog { 18	fmt.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | How To Inverse Order A Stack Using Only Recursive Functions And Stack</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/3/</link>
      <pubDate>Sun, 05 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/3/</guid>
      <description>
        
          
            Requirements A stack is pressed into 1, 2, 3, 4, 5, then from the top of the stack to the bottom of the stack is 5, 4, 3, 2, 1. After transposing this stack, from the top of the stack to the bottom of the stack is 1, 2, 3, 4, 5, that is, to achieve the reverse order of the stack elements, but only with recursive functions to achieve, can not use other data structures.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | Queue Composed Of Two Stacks</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/2/</link>
      <pubDate>Sat, 04 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/2/</guid>
      <description>
        
          
            Requirements Write a class that implements a queue with two stacks and supports the basic operations of a queue: add, poll, peek
Solving Ideas stacks are characterized by last-in-first-out, queues are characterized by first-in-first-out one stack as a press-in stack, the other stack as a pop-up stack, as long as the data pressed into the press-in stack and then pressed into the pop-up stack order will be restored Golang Implementation Note that since the data from stackPush to stackPop is only guaranteed to be coherent each time, stackPush has to press all the data into stackPop at once, and only when stackPop is empty.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ALGORITHM SERIES | Designing A Stack With &#39;getMin&#39; Function</title>
      <link>https://zhangsiming-blyq.github.io/post/algorithm/1/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/algorithm/1/</guid>
      <description>
        
          
            Requirements the time complexity of pop, push, getMin operations are O(1) the design of the stack type can use the ready-made stack structure Solving Ideas use two stacks, starkData and stackMin compare the size of the top data of stackMin with that of starkData each time it is pressed in, and press the new minimum value onto the stack if it is smaller than the top data of stackMin Golang Implementation Golang built-in data structure does not include a stack, define a stack.
          
          
        
      </description>
    </item>
    
    <item>
      <title>client-go watch接口隔一段时间自动退出怎么办？</title>
      <link>https://zhangsiming-blyq.github.io/post/golang/retrywatcher/</link>
      <pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/golang/retrywatcher/</guid>
      <description>
        
          
            在使用client-go的watch接口时候碰到异常退出问题，查了一下google没有多少信息，于是扒了一下代码，把自己踩的坑记录下来方便以后自查自纠。
使用client-go watch接口 💡 全局的mycluster都等于*kubernetes.Clientset 1. 如何watch 由于kubernetes整合了etcd的watch功能，我们可以通过watch操作去建立一个长连接，不断的接收数据；这种方式要优于普通的反复轮询请求，降低server端的压力;
使用client-go调用对应对象的Watch()方法之后，会返回一个watch.Event对象，可以对其使用ResultChan()接受watch到的对象。
1pod, err := mycluster.Clusterclientset.CoreV1().Pods(appNamespace).Watch(context.TODO(), metav1.ListOptions{LabelSelector: label}) 2if err != nil { 3 log.Error(err) 4} 5... 6event, ok := &amp;lt;-pod.ResultChan() 7if !ok { 8 log.Error(err) 9} 异常：watch接口自动断开 1. 现象 在使用过程中，watch操作持续一段时间就会自动断开
2. 排查 我们进入watch包里面找到streamwatcher.go，其中节选了一些重要片段：
1type StreamWatcher struct { 2	sync.Mutex 3	source Decoder 4	reporter Reporter 5	result chan Event 6	stopped bool 7} 8... 9func NewStreamWatcher(d Decoder, r Reporter) *StreamWatcher { 10	sw := &amp;amp;StreamWatcher{ 11	source: d, 12	reporter: r, 13	// It&amp;#39;s easy for a consumer to add buffering via an extra 14	// goroutine/channel, but impossible for them to remove it, 15	// so nonbuffered is better.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Python Yield</title>
      <link>https://zhangsiming-blyq.github.io/post/python/python-yield/</link>
      <pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/python/python-yield/</guid>
      <description>
        
          
            Explain the common usage scenarios of iterators, generators, and yield fields in Python.
Iterators Python object implements iter() and next() methods, we become iterable objects (iterables), through iter() can return an iterator object (iterators).
__iter__() method: return the iterator object itself __next__() method: returns the next element of the container, and raises a StopIteration Exception at the end to terminate the iterator 1lst = [1, 2, 3] 2print(type(lst)) 3new_iter = lst.
          
          
        
      </description>
    </item>
    
    <item>
      <title>prometheus 监测 kubernetes 控制平面</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/monitor-control-plane/</link>
      <pubDate>Mon, 11 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/monitor-control-plane/</guid>
      <description>
        
          
            对于 kubernetes 集群的控制平面组件，监控是必要的, 他可以帮助我们获取到集群的整体负载压力，并在核心组件出问题的时候配合告警让管理员及时发现问题，及时处理，更稳定的保证集群的生命周期。
一、Prometheus 如何自动发现 Kubernetes Metrics 接口? prometheus 收集 kubernetes 集群中的指标有两种方式，一种是使用 crd(servicemonitors.monitoring.coreos.com)的方式，主要通过标签匹配；另一种是通过 scrape_config，支持根据配置好的&amp;quot;relabel_configs&amp;quot;中的具体目标, 进行不断拉取(拉取间隔为&amp;quot;scrape_interval&amp;quot;)
配置权限： k8s 中 RBAC 支持授权资源对象的权限，比如可以 get、list、watch 集群中的 pod，还支持直接赋予对象访问 api 路径的权限，比如获取/healthz, /api 等, 官方对于 non_resource_urls 的解释如下：
non_resource_urls - (Optional) NonResourceURLs is a set of partial urls that a user should have access to. *s are allowed, but only as the full, final step in the path Since non-resource URLs are not namespaced, this field is only applicable for ClusterRoles referenced from a ClusterRoleBinding.
          
          
        
      </description>
    </item>
    
    <item>
      <title>浅谈 containerd</title>
      <link>https://zhangsiming-blyq.github.io/post/kubernetes/containerd/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zhangsiming-blyq.github.io/post/kubernetes/containerd/</guid>
      <description>
        
          
            伴随着kubernetes对docker的弃用，containerd开始进入大众视野；相比于kubelet中集成docker-shim连接docker，docker再次条用containerd去管理容器，直接使用containerd可以通过原生CRI接口的调用实现容器runtime，简化了调用链路，更加的灵活可靠。
一、安装使用 ctr 管理 containerd 1# Install Dependent Libraries 2$ sudo apt-get update 3$ sudo apt-get install libseccomp2 4 5# 下载 6# 目前是下载的1.5.2 7$ wget https://github.com/containerd/containerd/releases/download/v${VERSION}/cri-containerd-cni-${VERSION}-linux-amd64.tar.gz 8 9# 安装 10$ sudo tar --no-overwrite-dir -C / -xzf cri-containerd-cni-${VERSION}-linux-amd64.tar.gz 11# 初始化containerd配置 12$ containerd config default &amp;gt; /etc/containerd/config.toml 13# 修改默认的sandbox_image 14$ vim /etc/containerd/config.toml 15... 16sandbox_image = &amp;#34;registry.cn-beijing.aliyuncs.com/shannonai-k8s/pause:3.1&amp;#34; 17... 18 19# 启动服务 20sudo systemctl daemon-reload 21sudo systemctl start containerd 22 23# 查看版本 24$ ctr version 25Client: 26 Version: 1.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
